[
["index.html", "BioSakshat - Free Study Materials Chapter 1 Site navigation", " BioSakshat - Free Study Materials By Priyabrata Panigrahi and Pandurang Kolekar 2019-08-13 Chapter 1 Site navigation This site contains study materials for our(BioSakshat) training programs. The study material is available freely. http://biosakshat.weebly.com/ Courses BRLS Statistics "],
["data-types-and-data-structures.html", "Chapter 2 Data types and Data structures 2.1 Lets Begin 2.2 Expression 2.3 Assignment 2.4 Working directory 2.5 List of objects in workspace/environment 2.6 getting help in R 2.7 Data Types 2.8 Data Structures 2.9 Vector 2.10 Matrix 2.11 Data Frame 2.12 List", " Chapter 2 Data types and Data structures 2.1 Lets Begin We assume that R or Rstudio is installed. R is an integrated suite of software facilities for data manipulation, calculation and graphical display. In all the documents, the R codes written in shaded box are the codes which you can copy and try in R console. The results are shown in unshaded box. Lets first understand the difference between expression and assignment statements in R. 2.2 Expression Expressions are evaluated, results are printed. Results are not stored. Semicolon ‘;’ is optional to end a statement. Its recommended to give ; at the end of each statement. # (Hash), is used to comment single line. # Space around + is optional but code looks clean. So recommended. Statement is not executed. 2 + 5; ## [1] 7 Lets explore some more. You can use R console as calculator. 2 * 3; ## [1] 6 2.3 Assignment An assignment is a statement which is evaluated and result is stored but results of the evaluation are not printed on console. Right hand side is evaluated whose results is stored in left hand side. Either use = or &lt;- as Assignment operator. # In this example value of x will be 2. x=2; # 2 will be assigned to x; Value of x will not be printed on console. x &lt;- 2+5; x; ## [1] 7 2.4 Working directory # Present working directory getwd(); ## [1] &quot;/home/priyabrata/learn/github/bookdown-demo-master&quot; # setwd(): change the working directory by passing path of new directory. # Enclose the path between &quot; &quot; (double quotes) setwd(&quot;/home/user/&quot;) 2.5 List of objects in workspace/environment # Lists all objects/variables created in the workspace/environment ls(); ## [1] &quot;x&quot; # rm():Delete provided object rm(x); 2.6 getting help in R # Access to R documentation help.start() # Help on mean ?mean help(solve) # More depth search ??mean # Explore examples on mean example(mean); 2.6.1 Some things to Remember R is case sensitive ; is ends a statement # is used to comment 2.7 Data Types Every programming language deals with data. It is important to understand what kind of data you are dealing with and how you are going to store this. You can refer these two concepts as Data types and Data structures respectively. First we will start with data types and then move to data structures. Data can be either in the form of integer, numeric, character or logical/boolean (TRUE/FALSE). Thus based on kind of data, data types in R can be broadly categorized into 5 categories Integer (int): Represents integer data such as -2, 0, 2. Numeric (num): Represents integers as well as decimals such as 2, 2.3, -2.3. Logical (logi): Represents boolean values such as TRUE and FALSE. One can also write T and F respectively. It is important to note about the case sensitivity while dealing with logical/boolean data. If you write true/false/True/False/t/f, it will not considered as logical data types (Everything has to be capital T/TRUE/F/FALSE). Character (chr): Represents single character (e.g. ‘M’, ‘F’) or multi-character string (e.g. ‘ABC’,‘DEF’) data. Both single (’) and double quotes (“) can be used to store character data (‘ABC’,”ABC&quot;). Factor: Stores categorical data. We will explain this in detail in later sections. 2.8 Data Structures Depending on the data, it can be stored in different way which defines the data structure. In R, data can be stored in 5 different ways, in the form of vector, matrix, array, data frames and list. Vector (One dimensional, Homogeneous) Matrix (Two dimensional, Homogeneous) Array (Multi dimensional, Homogeneous) Data frames (Two dimensional, Heterogeneous) List (Multi-component, Heterogeneous) Figure 1: Data structures in R 2.9 Vector Figure 1: Vector Vector is one dimensional way of data storage in which sequence of numbers/characters/logical values can be stored. In the above image, example shows measured temperature of a city for 5 days. So we have 5 temperature values and all values are of integer type (25C, 30C etc). These 5 integers are stored in a sequence, which we term as integer vector (A vector storing integers). Therefore a vector can be understood as a single entity/variable/object storing an ordered collection of elements. Similarly, names of each students in a class can be stored in the form of a Character vector. Since all elements stored in a vector are of only one data types, i.e either integer or numeric or character or logical, vector is a homogeneous data structure (integer vector, numeric vector, character vector and logical vector respectively). 2.9.1 Creating a vector In R vectors can be created using Assignment operator (=) Range operator (:) Concatenate function c() Sequence function seq() Repeat function rep() Sample function We will explore these one by one. 2.9.2 Create Vector of one element x1=2; # Integer data type x2=2.3; # Numeric data type x3=&quot;A&quot;; # Single Character. Double quote was used. x4=&quot;ABC&quot;; # Multiple Characters. Double quote was used. x5=&#39;A&#39;; # Single Character. Single quote was used. x6=&#39;ABC&#39;; # Multiple Characters. Single quote was used. x7=TRUE; # Logical. Note the use of TRUE (All capital) x8=FALSE; # Logical. Note the use of FALSE (All capital) #x9=true; # Error since true is written in small. R is case sensitive. In the above examples, x1 is an integer vector of one element having value 2. Similarly x2 is a numeric vector with one element 2.3. The vectors x3, x4, x5 and x6 are character vectors storing character data. Note that the character data can be either single character (“A”) or multiple character (“ABC”). Similarly one can use either single or double quote to assign character data types. The vector x7 and x8 are logical vector storing boolean values (TRUE or FALSE). Note that TRUE/FALSE can be also be written as T/F but everything has to be capital. R is case sensitive i.e. X and x are different. Thus x9=true; will throw error since R will not understand true. The = is assignment operator using which the results from right hand side expression is stored in left hand side variable. When we say x1=2, 2 (right side) is assigned to x1 (left side). Also note semicolon (;) at the end of few statements. Use of ; is optional. However it is recommended that you must end every statement with ; so that R understands it is end of a statement. So far we saw vectors with one element. Now we will explore how to create vectors with more than one element. 2.9.3 Create Vector using Range operator (:) x1=1:5; x1; ## [1] 1 2 3 4 5 x2=5:1; x2; ## [1] 5 4 3 2 1 In the above example x1 stores 5 elements 1, 2, 3, 4 and 5 while x2 stores 5, 4, 3, 2, 1. So using range operator you can assign more than one element incremented/decremented by 1. 2.9.4 Create Vector using c() Range operator (:) is handy when you have sequence of integers incremented or decremented by 1. What if you have random data and there is no pattern. In such case you can use concatenate function c(). # Integer vector with 3 element x1=c(2,10,35); x1; ## [1] 2 10 35 # Character vector with 3 elements x2=c(&quot;Gene&quot;,&quot;Expression&quot;,&#39;Chromosome&#39;); x2; ## [1] &quot;Gene&quot; &quot;Expression&quot; &quot;Chromosome&quot; # Logical vector x3=c(T,F,TRUE,FALSE); x3; ## [1] TRUE FALSE TRUE FALSE x4=c(x1,44,55); # x4 will now contain 2, 10, 35, 44, 55 x4; ## [1] 2 10 35 44 55 In the example x1 is a vector with 3 elements: 2, 10 and 35. Similarly x2 is a character vector and x3 is a logical vector. Note that, since x2 is a character vector and each element are characters, you have to write within either single or double quote (e.g. “Gene”, “Expression”, ‘Chromosome’). In case of x4, first element is x1 vector thus x4 will first store 2, 10, 35 followed by 44 and 55. 2.9.5 seq() function Generate regular sequences using seq() function. # Generate a sequence of number from 0 to 10 incremented by 2 x1=seq(from=0, to=10, by=2) x1; ## [1] 0 2 4 6 8 10 # Generate a sequence of 50 number from 0 to 10 x2=seq(from=0, to=10, length=30) x2; ## [1] 0.0000000 0.3448276 0.6896552 1.0344828 1.3793103 1.7241379 ## [7] 2.0689655 2.4137931 2.7586207 3.1034483 3.4482759 3.7931034 ## [13] 4.1379310 4.4827586 4.8275862 5.1724138 5.5172414 5.8620690 ## [19] 6.2068966 6.5517241 6.8965517 7.2413793 7.5862069 7.9310345 ## [25] 8.2758621 8.6206897 8.9655172 9.3103448 9.6551724 10.0000000 In R there are several inbuilt functions which can be used to do certain tasks. Functions can be called by their name followed by (). Inside () various parameters required to the function can be passed as key=value pair. In the above example to x1 will generate sequence of number from 0 (from=0) to 10 (to=10), incremented by 2 (by=2). Thus x2 will contain 0, 2, 4, 6, 8 and 10. Note that from=0, to=10 and by=2 are 3 parameters which we pass to seq() function and these are separated by comma (,). In case of 2nd example, we just replace by parameter with length=50. So we use same function to generate 50 elements between 0 to 10. 2.9.6 rep() function rep replicates the values in x. # Create a vector x1 with 3 elements x1=c(2,3,5); x1; ## [1] 2 3 5 # Repeat each element of x1, 3 times x2=rep(x1,each=3); x2; ## [1] 2 2 2 3 3 3 5 5 5 # Repeat x1, 3 times. x3=rep(x1, times=3); x3; ## [1] 2 3 5 2 3 5 2 3 5 rep(1:4, each = 2, times = 4); ## [1] 1 1 2 2 3 3 4 4 1 1 2 2 3 3 4 4 1 1 2 2 3 3 4 4 1 1 2 2 3 3 4 4 x1 is a vector with 3 elements (2, 3, 5). Using rep() function, the first argument we pass is a vector, when we specify each=3, rep() function will repeat each element of x1 3 times and store in x2. Thus x2 will store 2, 2, 2, 3, 3, 3, 5, 5, 5. When we specify times=3, rep() function will repeat the x1 vector 3 times. Thus x3 will store 2, 3, 5, 2, 3, 5, 2, 3, 5. 2.9.7 sample() function sample takes a sample of the specified size from the elements of x using either with or without replacement. # Fetch 10 random number from the database 1:50 sample(1:50, 10); ## [1] 23 6 13 14 32 48 30 21 35 44 # Fetch 100 random number from the database 20:30. Since we are fetching more elements than present in database, we need to specify replace=TRUE (Should sampling be with replacement?) sample(20:30, 100, replace = TRUE); ## [1] 23 28 29 26 30 28 20 22 25 22 28 21 23 20 30 29 27 27 20 30 20 27 30 ## [24] 29 28 24 28 29 25 28 30 22 25 22 25 29 27 23 23 27 30 24 25 25 21 23 ## [47] 20 20 24 21 30 24 28 23 22 20 24 28 30 27 21 22 30 29 23 30 20 27 26 ## [70] 30 25 27 27 22 27 30 26 26 23 25 26 27 27 21 29 26 28 25 30 28 23 25 ## [93] 30 30 20 23 22 22 25 24 2.9.8 rnorm() function The Normal Distribution. # Fetch 50 element from a normal distribution rnorm(50); ## [1] 0.1072768 -0.5559458 -0.9473100 0.1231852 -0.4192404 0.6580416 ## [7] 0.2922227 -1.3781758 -0.4989867 -0.3913664 0.4577026 -0.6573956 ## [13] -0.2745708 -1.5240526 -0.1586570 0.7814693 0.2665822 0.6159602 ## [19] -0.7086050 1.4935373 -0.7845990 -0.6681351 0.1259791 -0.7627799 ## [25] -2.3429657 0.4638053 -0.9005353 -0.1291929 1.4176135 -1.6138372 ## [31] 1.9607997 -0.1071785 1.3359480 0.6585954 0.4056754 -1.4911310 ## [37] -0.6782876 -0.9751761 0.4949637 2.0767209 -0.7519678 0.4856761 ## [43] 0.1120740 0.7585012 0.7791965 -0.9262399 -1.4125175 1.0071076 ## [49] -0.2031515 -0.3368814 rnorm(50, mean=5, sd=2); ## [1] 7.625584 8.340640 4.248128 4.073515 6.697424 4.330564 3.905983 ## [8] -3.074845 3.286376 5.482962 6.590412 4.316969 7.530495 4.821459 ## [15] 6.100846 5.019444 4.324496 5.395754 5.443038 5.380750 5.860219 ## [22] 1.380844 5.849956 8.782875 2.359652 6.724360 2.148440 5.552696 ## [29] 5.075265 5.183448 5.150578 4.746253 4.567021 4.905083 6.280027 ## [36] 4.618495 6.076839 3.244405 2.279278 7.211379 6.265323 4.911341 ## [43] 7.447383 7.235156 3.536407 4.521768 3.954108 3.551843 4.229697 ## [50] 6.761596 Task: Now Go to Task page and finish Vector creation 2.9.9 Fetching elements from a vector x=c(10,20,30,40,50,60); length(x); ## [1] 6 x[1]; # 1st element ## [1] 10 x[4]; # 4th element ## [1] 40 x[2:3]; # 2nd to 3rd element ## [1] 20 30 x[c(1,3,5)]; # 1st, 3rd, 4th element ## [1] 10 30 50 x[3:length(x)]; ## [1] 30 40 50 60 x[-1]; # Exclude 1st element ## [1] 20 30 40 50 60 x[-c(1,3)] # Exclude 1st, 3rd element ## [1] 20 40 50 60 x[10]; # NA: Missing value ## [1] NA # x[1, 3, 5] # Error 2.9.10 Delete element(s) from a vector x=10:20; x; ## [1] 10 11 12 13 14 15 16 17 18 19 20 x=x[-3]; x; ## [1] 10 11 13 14 15 16 17 18 19 20 x=x[-c(7,3)]; x; ## [1] 10 11 14 15 16 18 19 20 x=x[-c(2,length(x))]; x; ## [1] 10 14 15 16 18 19 2.9.11 Add element(s) to existing vector x=10:20; x; ## [1] 10 11 12 13 14 15 16 17 18 19 20 x=c(x,55); x; ## [1] 10 11 12 13 14 15 16 17 18 19 20 55 x=c(33,x,77); x; ## [1] 33 10 11 12 13 14 15 16 17 18 19 20 55 77 y=seq(100,110,0.5); y; ## [1] 100.0 100.5 101.0 101.5 102.0 102.5 103.0 103.5 104.0 104.5 105.0 ## [12] 105.5 106.0 106.5 107.0 107.5 108.0 108.5 109.0 109.5 110.0 x=c(x,y); x; ## [1] 33.0 10.0 11.0 12.0 13.0 14.0 15.0 16.0 17.0 18.0 19.0 ## [12] 20.0 55.0 77.0 100.0 100.5 101.0 101.5 102.0 102.5 103.0 103.5 ## [23] 104.0 104.5 105.0 105.5 106.0 106.5 107.0 107.5 108.0 108.5 109.0 ## [34] 109.5 110.0 2.9.12 Replace elements in existing vector x=sample(20:30, 5); x; ## [1] 24 23 29 22 25 x[2]=111111; x; ## [1] 24 111111 29 22 25 x[c(1,3)]=c(555, 777); x; ## [1] 555 111111 777 22 25 Task: Now Go to Task page and finish Fetching vector elements and Vector manipulation section 2.9.13 Inbuilt functions for numeric vector x=seq(4, 8, length=10); x; ## [1] 4.000000 4.444444 4.888889 5.333333 5.777778 6.222222 6.666667 ## [8] 7.111111 7.555556 8.000000 length(x); ## [1] 10 sort(x); ## [1] 4.000000 4.444444 4.888889 5.333333 5.777778 6.222222 6.666667 ## [8] 7.111111 7.555556 8.000000 order(x); ## [1] 1 2 3 4 5 6 7 8 9 10 max(x); ## [1] 8 min(x); ## [1] 4 range(x); ## [1] 4 8 mean(x); ## [1] 6 median(x); ## [1] 6 mode(x); ## [1] &quot;numeric&quot; sd(x); ## [1] 1.345622 var(x); ## [1] 1.8107 quantile(x); ## 0% 25% 50% 75% 100% ## 4 5 6 7 8 summary(x); ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 4 5 6 6 7 8 sin(x); ## [1] -0.75680250 -0.96431712 -0.98446429 -0.81332939 -0.48416406 ## [6] -0.06092533 0.37415123 0.73652996 0.95580043 0.98935825 log(x, base=2); ## [1] 2.000000 2.152003 2.289507 2.415037 2.530515 2.637430 2.736966 ## [8] 2.830075 2.917538 3.000000 log(x, base=10); ## [1] 0.6020600 0.6478175 0.6892102 0.7269987 0.7617608 0.7939455 0.8239087 ## [8] 0.8519375 0.8782664 0.9030900 2.9.14 Correlation using cor() x=sample(1:100,20); y=sample(1:100,20); x; ## [1] 69 75 7 33 53 48 43 76 70 79 34 92 49 95 26 57 21 62 40 60 y; ## [1] 71 92 20 78 6 3 68 2 35 26 8 87 51 91 16 55 84 85 32 38 # Methods: &quot;pearson&quot;, &quot;kendall&quot;, &quot;spearman&quot; cor(x,y, method = &quot;spearman&quot;); ## [1] 0.3022556 cor(x,y, method = &quot;pearson&quot;); ## [1] 0.3083698 2.9.15 Set operations x; ## [1] 69 75 7 33 53 48 43 76 70 79 34 92 49 95 26 57 21 62 40 60 y; ## [1] 71 92 20 78 6 3 68 2 35 26 8 87 51 91 16 55 84 85 32 38 union(x,y); ## [1] 69 75 7 33 53 48 43 76 70 79 34 92 49 95 26 57 21 62 40 60 71 20 78 ## [24] 6 3 68 2 35 8 87 51 91 16 55 84 85 32 38 intersect(x,y); ## [1] 92 26 setdiff(x,y); # x - y ## [1] 69 75 7 33 53 48 43 76 70 79 34 49 95 57 21 62 40 60 setdiff(y,x); # y - x ## [1] 71 20 78 6 3 68 2 35 8 87 51 91 16 55 84 85 32 38 2.9.16 Arithmetic expressions Vector recycling. Shorter vector are recycled to match the length of longest vector. Once length of all vectors are equal, then arithmentic operations are performed. x=c(3,4,5,6); y=c(6,7,8,9); z=c(1,2); p=c(9,10,11); x+y; ## [1] 9 11 13 15 x+z; ## [1] 4 6 6 8 x+p; ## Warning in x + p: longer object length is not a multiple of shorter object ## length ## [1] 12 14 16 15 2.9.17 Arithmetic operations on vector x=1:3; y=6:8; z=10:12; x; ## [1] 1 2 3 y; ## [1] 6 7 8 z; ## [1] 10 11 12 x-y; ## [1] -5 -5 -5 x*4; ## [1] 4 8 12 x*y; ## [1] 6 14 24 y/5; ## [1] 1.2 1.4 1.6 y%%5; ## [1] 1 2 3 y^3; ## [1] 216 343 512 2.9.18 Operator precedence x+2*y+z; ## [1] 23 27 31 x+2*y/z; ## [1] 2.200000 3.272727 4.333333 (x+2)*y+z; ## [1] 28 39 52 (x+2)*(y+z); ## [1] 48 72 100 n=10; 1:n-1; ## [1] 0 1 2 3 4 5 6 7 8 9 1:(n-1); ## [1] 1 2 3 4 5 6 7 8 9 Task: Now Go to Task page and finish Vector arithmetic 2.9.19 Conditional statements x=10:30; x; ## [1] 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 x &gt; 15; ## [1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE ## [12] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE x == 15; ## [1] FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE ## [12] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE x &gt; 15 &amp; x %% 2==0; ## [1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE TRUE FALSE TRUE ## [12] FALSE TRUE FALSE TRUE FALSE TRUE FALSE TRUE FALSE TRUE x[x &gt; 15 &amp; x %% 2==0]; ## [1] 16 18 20 22 24 26 28 30 x &gt; 15 | x %% 2==0; ## [1] TRUE FALSE TRUE FALSE TRUE FALSE TRUE TRUE TRUE TRUE TRUE ## [12] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE x[x &gt; 15 | x %% 2==0]; ## [1] 10 12 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # which() function returns the indices which satisfies the condition to TRUE tempind=which(x &gt; 15 &amp; x %% 2==0); tempind; ## [1] 7 9 11 13 15 17 19 21 x[tempind]; ## [1] 16 18 20 22 24 26 28 30 2.9.20 Check for missing values x=c(1:5,NA,NA,2:3,NA,NA,3); is.na(x); ## [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE FALSE FALSE TRUE TRUE ## [12] FALSE which(is.na(x)); ## [1] 6 7 10 11 2.9.21 Check data types and data structures x1=1:10; str(x1); ## int [1:10] 1 2 3 4 5 6 7 8 9 10 x2=c(1.2, 2.3); str(x2); ## num [1:2] 1.2 2.3 x3=c(&quot;aaa&quot;,&quot;bbb&quot;); str(x3); ## chr [1:2] &quot;aaa&quot; &quot;bbb&quot; x4=c(&#39;ccc&#39;,&#39;ddd&#39;); str(x4); ## chr [1:2] &quot;ccc&quot; &quot;ddd&quot; x5=c(T,F); str(x5); ## logi [1:2] TRUE FALSE str(letters); ## chr [1:26] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;j&quot; &quot;k&quot; &quot;l&quot; &quot;m&quot; &quot;n&quot; ... 2.9.22 Implicit Data type conversion Conversion Order: Logical -&gt; Integer -&gt; Numeric -&gt; character x1=c(1, &quot;abc&quot;, TRUE); str(x1); ## chr [1:3] &quot;1&quot; &quot;abc&quot; &quot;TRUE&quot; x2=c(1,TRUE); str(x2); ## num [1:2] 1 1 2.9.23 Character vector and related functions x=c(&quot;gene1&quot;,&quot;gene2&quot;,&quot;gene3&quot;); y=c(&#39;prot&#39;,&#39;rna&#39;,&#39;lipid&#39;); z=letters; nchar(x); ## [1] 5 5 5 nchar(y); ## [1] 4 3 5 substr(&quot;abcdef&quot;, 2, 4); ## [1] &quot;bcd&quot; substr(c(x,y), 1, 2); ## [1] &quot;ge&quot; &quot;ge&quot; &quot;ge&quot; &quot;pr&quot; &quot;rn&quot; &quot;li&quot; paste(letters, 1:5); ## [1] &quot;a 1&quot; &quot;b 2&quot; &quot;c 3&quot; &quot;d 4&quot; &quot;e 5&quot; &quot;f 1&quot; &quot;g 2&quot; &quot;h 3&quot; &quot;i 4&quot; &quot;j 5&quot; &quot;k 1&quot; ## [12] &quot;l 2&quot; &quot;m 3&quot; &quot;n 4&quot; &quot;o 5&quot; &quot;p 1&quot; &quot;q 2&quot; &quot;r 3&quot; &quot;s 4&quot; &quot;t 5&quot; &quot;u 1&quot; &quot;v 2&quot; ## [23] &quot;w 3&quot; &quot;x 4&quot; &quot;y 5&quot; &quot;z 1&quot; paste(letters, 1:5, sep=&quot;:&quot;); ## [1] &quot;a:1&quot; &quot;b:2&quot; &quot;c:3&quot; &quot;d:4&quot; &quot;e:5&quot; &quot;f:1&quot; &quot;g:2&quot; &quot;h:3&quot; &quot;i:4&quot; &quot;j:5&quot; &quot;k:1&quot; ## [12] &quot;l:2&quot; &quot;m:3&quot; &quot;n:4&quot; &quot;o:5&quot; &quot;p:1&quot; &quot;q:2&quot; &quot;r:3&quot; &quot;s:4&quot; &quot;t:5&quot; &quot;u:1&quot; &quot;v:2&quot; ## [23] &quot;w:3&quot; &quot;x:4&quot; &quot;y:5&quot; &quot;z:1&quot; paste(letters, 1:5, sep=&quot;:&quot;, collapse = &quot;,&quot;); ## [1] &quot;a:1,b:2,c:3,d:4,e:5,f:1,g:2,h:3,i:4,j:5,k:1,l:2,m:3,n:4,o:5,p:1,q:2,r:3,s:4,t:5,u:1,v:2,w:3,x:4,y:5,z:1&quot; 2.9.24 Explicit Data Type Conversion x=c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;); str(x); ## chr [1:3] &quot;1&quot; &quot;2&quot; &quot;3&quot; x=as.numeric(x); str(x); ## num [1:3] 1 2 3 x=1:5; str(x); ## int [1:5] 1 2 3 4 5 x=as.character(x); str(x); ## chr [1:5] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; 2.10 Matrix 2.10.1 Create a matrix from vector using dim attributes x=21:70; dim(x)=c(10,5); # 10 row, 5 col x; ## [,1] [,2] [,3] [,4] [,5] ## [1,] 21 31 41 51 61 ## [2,] 22 32 42 52 62 ## [3,] 23 33 43 53 63 ## [4,] 24 34 44 54 64 ## [5,] 25 35 45 55 65 ## [6,] 26 36 46 56 66 ## [7,] 27 37 47 57 67 ## [8,] 28 38 48 58 68 ## [9,] 29 39 49 59 69 ## [10,] 30 40 50 60 70 2.10.2 Create matrix using matrix() x=21:70; matrix(x, ncol=10); # 10 col ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 21 26 31 36 41 46 51 56 61 66 ## [2,] 22 27 32 37 42 47 52 57 62 67 ## [3,] 23 28 33 38 43 48 53 58 63 68 ## [4,] 24 29 34 39 44 49 54 59 64 69 ## [5,] 25 30 35 40 45 50 55 60 65 70 m=matrix(x, ncol=10, byrow = TRUE); # Fill elements row wise 2.10.3 Functions that can be applied to a matrix # Data structure of m str(m); ## int [1:5, 1:10] 21 31 41 51 61 22 32 42 52 62 ... # Dimension of m dim(m); ## [1] 5 10 # Number of rows nrow(m); ## [1] 5 # Number of columns ncol(m); ## [1] 10 # Column means colMeans(m); ## [1] 41 42 43 44 45 46 47 48 49 50 # Row means rowMeans(m); ## [1] 25.5 35.5 45.5 55.5 65.5 # Transpose t(m); ## [,1] [,2] [,3] [,4] [,5] ## [1,] 21 31 41 51 61 ## [2,] 22 32 42 52 62 ## [3,] 23 33 43 53 63 ## [4,] 24 34 44 54 64 ## [5,] 25 35 45 55 65 ## [6,] 26 36 46 56 66 ## [7,] 27 37 47 57 67 ## [8,] 28 38 48 58 68 ## [9,] 29 39 49 59 69 ## [10,] 30 40 50 60 70 # Fetch column names colnames(m); ## NULL # Fetch row names rownames(m); ## NULL # head head(m); ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 21 22 23 24 25 26 27 28 29 30 ## [2,] 31 32 33 34 35 36 37 38 39 40 ## [3,] 41 42 43 44 45 46 47 48 49 50 ## [4,] 51 52 53 54 55 56 57 58 59 60 ## [5,] 61 62 63 64 65 66 67 68 69 70 2.10.4 Assign column/row names colnames(m)=paste(&quot;C&quot;,1:ncol(m),sep=&quot;&quot;); rownames(m)=paste(&quot;R&quot;,1:nrow(m),sep=&quot;&quot;); m; ## C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 ## R1 21 22 23 24 25 26 27 28 29 30 ## R2 31 32 33 34 35 36 37 38 39 40 ## R3 41 42 43 44 45 46 47 48 49 50 ## R4 51 52 53 54 55 56 57 58 59 60 ## R5 61 62 63 64 65 66 67 68 69 70 2.10.5 Fetch elements from a matrix using indices m; ## C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 ## R1 21 22 23 24 25 26 27 28 29 30 ## R2 31 32 33 34 35 36 37 38 39 40 ## R3 41 42 43 44 45 46 47 48 49 50 ## R4 51 52 53 54 55 56 57 58 59 60 ## R5 61 62 63 64 65 66 67 68 69 70 # 1st row, 3rd column m[1,3]; ## [1] 23 # 1st tp 3rd row and 3rd to 5th column m[c(1:3),c(3:5)]; ## C3 C4 C5 ## R1 23 24 25 ## R2 33 34 35 ## R3 43 44 45 # 1st row m[1,]; ## C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 ## 21 22 23 24 25 26 27 28 29 30 # 3rd column m[,3]; ## R1 R2 R3 R4 R5 ## 23 33 43 53 63 # 3rd element. Here matrix is converted to vector and 3rd element is returned m[3]; ## [1] 41 2.10.6 Fetch element using index matrix m; ## C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 ## R1 21 22 23 24 25 26 27 28 29 30 ## R2 31 32 33 34 35 36 37 38 39 40 ## R3 41 42 43 44 45 46 47 48 49 50 ## R4 51 52 53 54 55 56 57 58 59 60 ## R5 61 62 63 64 65 66 67 68 69 70 index=c(2,3,3,4,4,5); m[index] ## [1] 31 41 41 51 51 61 2.10.7 Fetch elements from a matrix using row and column names m; ## C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 ## R1 21 22 23 24 25 26 27 28 29 30 ## R2 31 32 33 34 35 36 37 38 39 40 ## R3 41 42 43 44 45 46 47 48 49 50 ## R4 51 52 53 54 55 56 57 58 59 60 ## R5 61 62 63 64 65 66 67 68 69 70 m[&quot;R1&quot;,&quot;C3&quot;]; ## [1] 23 2.10.8 Insert rows and columns by rbind() and cbind() m1=matrix(1:10, nrow=5); m1; ## [,1] [,2] ## [1,] 1 6 ## [2,] 2 7 ## [3,] 3 8 ## [4,] 4 9 ## [5,] 5 10 m1=rbind(m1, 999); m1; ## [,1] [,2] ## [1,] 1 6 ## [2,] 2 7 ## [3,] 3 8 ## [4,] 4 9 ## [5,] 5 10 ## [6,] 999 999 m1=rbind(m1, c(2,3)); m1; ## [,1] [,2] ## [1,] 1 6 ## [2,] 2 7 ## [3,] 3 8 ## [4,] 4 9 ## [5,] 5 10 ## [6,] 999 999 ## [7,] 2 3 m1=cbind(m1, 1:5); ## Warning in cbind(m1, 1:5): number of rows of result is not a multiple of ## vector length (arg 2) m1; ## [,1] [,2] [,3] ## [1,] 1 6 1 ## [2,] 2 7 2 ## [3,] 3 8 3 ## [4,] 4 9 4 ## [5,] 5 10 5 ## [6,] 999 999 1 ## [7,] 2 3 2 m1=cbind(m1, 10:20); ## Warning in cbind(m1, 10:20): number of rows of result is not a multiple of ## vector length (arg 2) m1; ## [,1] [,2] [,3] [,4] ## [1,] 1 6 1 10 ## [2,] 2 7 2 11 ## [3,] 3 8 3 12 ## [4,] 4 9 4 13 ## [5,] 5 10 5 14 ## [6,] 999 999 1 15 ## [7,] 2 3 2 16 2.10.9 Create matrix using rbind() and cbind() x=seq(2, 4, length=10); y=1:10; x; ## [1] 2.000000 2.222222 2.444444 2.666667 2.888889 3.111111 3.333333 ## [8] 3.555556 3.777778 4.000000 y; ## [1] 1 2 3 4 5 6 7 8 9 10 cbind(x,y); ## x y ## [1,] 2.000000 1 ## [2,] 2.222222 2 ## [3,] 2.444444 3 ## [4,] 2.666667 4 ## [5,] 2.888889 5 ## [6,] 3.111111 6 ## [7,] 3.333333 7 ## [8,] 3.555556 8 ## [9,] 3.777778 9 ## [10,] 4.000000 10 rbind(x,y); ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## x 2 2.222222 2.444444 2.666667 2.888889 3.111111 3.333333 3.555556 ## y 1 2.000000 3.000000 4.000000 5.000000 6.000000 7.000000 8.000000 ## [,9] [,10] ## x 3.777778 4 ## y 9.000000 10 2.10.10 Delete row(s) and column(s) m; ## C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 ## R1 21 22 23 24 25 26 27 28 29 30 ## R2 31 32 33 34 35 36 37 38 39 40 ## R3 41 42 43 44 45 46 47 48 49 50 ## R4 51 52 53 54 55 56 57 58 59 60 ## R5 61 62 63 64 65 66 67 68 69 70 m=m[-1,]; m; ## C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 ## R2 31 32 33 34 35 36 37 38 39 40 ## R3 41 42 43 44 45 46 47 48 49 50 ## R4 51 52 53 54 55 56 57 58 59 60 ## R5 61 62 63 64 65 66 67 68 69 70 m=m[,-3]; m; ## C1 C2 C4 C5 C6 C7 C8 C9 C10 ## R2 31 32 34 35 36 37 38 39 40 ## R3 41 42 44 45 46 47 48 49 50 ## R4 51 52 54 55 56 57 58 59 60 ## R5 61 62 64 65 66 67 68 69 70 2.10.11 Check for matrix is.matrix(m); ## [1] TRUE 2.10.12 Conditional statements on matrix m; ## C1 C2 C4 C5 C6 C7 C8 C9 C10 ## R2 31 32 34 35 36 37 38 39 40 ## R3 41 42 44 45 46 47 48 49 50 ## R4 51 52 54 55 56 57 58 59 60 ## R5 61 62 64 65 66 67 68 69 70 m%%5==0; ## C1 C2 C4 C5 C6 C7 C8 C9 C10 ## R2 FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE TRUE ## R3 FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE TRUE ## R4 FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE TRUE ## R5 FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE TRUE which(m%%5==0, arr.ind = TRUE); ## row col ## R2 1 4 ## R3 2 4 ## R4 3 4 ## R5 4 4 ## R2 1 9 ## R3 2 9 ## R4 3 9 ## R5 4 9 Task: Now Go to Task page and finish Matrix 2.11 Data Frame 2.11.1 Create a data frame x=1:26; z=letters; y=paste(z, x, sep=&quot;:&quot;); d=data.frame(C1=x, C2=y, C3=z); d; ## C1 C2 C3 ## 1 1 a:1 a ## 2 2 b:2 b ## 3 3 c:3 c ## 4 4 d:4 d ## 5 5 e:5 e ## 6 6 f:6 f ## 7 7 g:7 g ## 8 8 h:8 h ## 9 9 i:9 i ## 10 10 j:10 j ## 11 11 k:11 k ## 12 12 l:12 l ## 13 13 m:13 m ## 14 14 n:14 n ## 15 15 o:15 o ## 16 16 p:16 p ## 17 17 q:17 q ## 18 18 r:18 r ## 19 19 s:19 s ## 20 20 t:20 t ## 21 21 u:21 u ## 22 22 v:22 v ## 23 23 w:23 w ## 24 24 x:24 x ## 25 25 y:25 y ## 26 26 z:26 z str(d); ## &#39;data.frame&#39;: 26 obs. of 3 variables: ## $ C1: int 1 2 3 4 5 6 7 8 9 10 ... ## $ C2: Factor w/ 26 levels &quot;a:1&quot;,&quot;b:2&quot;,&quot;c:3&quot;,..: 1 2 3 4 5 6 7 8 9 10 ... ## $ C3: Factor w/ 26 levels &quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;,..: 1 2 3 4 5 6 7 8 9 10 ... colnames(d); ## [1] &quot;C1&quot; &quot;C2&quot; &quot;C3&quot; rownames(d); ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;10&quot; &quot;11&quot; &quot;12&quot; &quot;13&quot; &quot;14&quot; ## [15] &quot;15&quot; &quot;16&quot; &quot;17&quot; &quot;18&quot; &quot;19&quot; &quot;20&quot; &quot;21&quot; &quot;22&quot; &quot;23&quot; &quot;24&quot; &quot;25&quot; &quot;26&quot; dim(d); ## [1] 26 3 # edit(d); 2.11.2 Fetch values from a data frame d; ## C1 C2 C3 ## 1 1 a:1 a ## 2 2 b:2 b ## 3 3 c:3 c ## 4 4 d:4 d ## 5 5 e:5 e ## 6 6 f:6 f ## 7 7 g:7 g ## 8 8 h:8 h ## 9 9 i:9 i ## 10 10 j:10 j ## 11 11 k:11 k ## 12 12 l:12 l ## 13 13 m:13 m ## 14 14 n:14 n ## 15 15 o:15 o ## 16 16 p:16 p ## 17 17 q:17 q ## 18 18 r:18 r ## 19 19 s:19 s ## 20 20 t:20 t ## 21 21 u:21 u ## 22 22 v:22 v ## 23 23 w:23 w ## 24 24 x:24 x ## 25 25 y:25 y ## 26 26 z:26 z d[,1]; ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ## [24] 24 25 26 d$C1; ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ## [24] 24 25 26 d[3,]; ## C1 C2 C3 ## 3 3 c:3 c d[3,1]; ## [1] 3 d$C1[3]; ## [1] 3 2.11.3 Insert column to data frame d; ## C1 C2 C3 ## 1 1 a:1 a ## 2 2 b:2 b ## 3 3 c:3 c ## 4 4 d:4 d ## 5 5 e:5 e ## 6 6 f:6 f ## 7 7 g:7 g ## 8 8 h:8 h ## 9 9 i:9 i ## 10 10 j:10 j ## 11 11 k:11 k ## 12 12 l:12 l ## 13 13 m:13 m ## 14 14 n:14 n ## 15 15 o:15 o ## 16 16 p:16 p ## 17 17 q:17 q ## 18 18 r:18 r ## 19 19 s:19 s ## 20 20 t:20 t ## 21 21 u:21 u ## 22 22 v:22 v ## 23 23 w:23 w ## 24 24 x:24 x ## 25 25 y:25 y ## 26 26 z:26 z d$C5=1; # d$C6=1:100; #Error d$C6=seq(3, 8, length=26); 2.11.4 Delete column or row from data frame d$C5=NULL; head(d); ## C1 C2 C3 C6 ## 1 1 a:1 a 3.0 ## 2 2 b:2 b 3.2 ## 3 3 c:3 c 3.4 ## 4 4 d:4 d 3.6 ## 5 5 e:5 e 3.8 ## 6 6 f:6 f 4.0 2.11.5 Check for data frame is.data.frame(d); ## [1] TRUE Task: Now Go to Task page and finish Data Frame 2.12 List An R list is an object consisting of an ordered collection of objects known as its components. x1=1:5; # vector x2=matrix(1:20, ncol=5); x3= data.frame(1:5, letters[1:5]); mylist = list(comp1=x1, comp2=x2, comp3=x3); mylist; ## $comp1 ## [1] 1 2 3 4 5 ## ## $comp2 ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 5 9 13 17 ## [2,] 2 6 10 14 18 ## [3,] 3 7 11 15 19 ## [4,] 4 8 12 16 20 ## ## $comp3 ## X1.5 letters.1.5. ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e 2.12.1 Access component of list using $ notation # Access componene1 using $ notation mylist$comp1; ## [1] 1 2 3 4 5 mylist$comp2; ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 5 9 13 17 ## [2,] 2 6 10 14 18 ## [3,] 3 7 11 15 19 ## [4,] 4 8 12 16 20 2.12.2 Access component of list using [] Using [] returns list while using [[]] returns the component. # Fetching 2nd component using []. Returns list m1 = mylist[2]; # Fetching 2nd component using [[]]. Returns matrix m2 = mylist[[2]]; m1; ## $comp2 ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 5 9 13 17 ## [2,] 2 6 10 14 18 ## [3,] 3 7 11 15 19 ## [4,] 4 8 12 16 20 str(m1); ## List of 1 ## $ comp2: int [1:4, 1:5] 1 2 3 4 5 6 7 8 9 10 ... m2; ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 5 9 13 17 ## [2,] 2 6 10 14 18 ## [3,] 3 7 11 15 19 ## [4,] 4 8 12 16 20 str(m2); ## int [1:4, 1:5] 1 2 3 4 5 6 7 8 9 10 ... "],
["ifforfunctionio.html", "Chapter 3 If/For/Function/IO 3.1 Conditional statements 3.2 Repetitive execution using for loop 3.3 Functions 3.4 File IO", " Chapter 3 If/For/Function/IO 3.1 Conditional statements Syntax: if (expr_1) { expr_2 …… …… }else{ expr_3 …… …… } x=sample(1:50,10); sum(x); ## [1] 283 if(sum(x)&gt;500) { print(&quot;Sum of x is greater than 500&quot;); }else{ print(&quot;Sum of x is less than 500&quot;); } ## [1] &quot;Sum of x is less than 500&quot; 3.2 Repetitive execution using for loop for(i in 5:10) { print(i); } ## [1] 5 ## [1] 6 ## [1] 7 ## [1] 8 ## [1] 9 ## [1] 10 for(i in c(10,15,17,16,25)) { print(i); } ## [1] 10 ## [1] 15 ## [1] 17 ## [1] 16 ## [1] 25 x=c(10,15,17,16,25); for(i in x) { print(i); } ## [1] 10 ## [1] 15 ## [1] 17 ## [1] 16 ## [1] 25 x=c(10,15,17,16,25); for(i in 1:length(x)) { print(c(i,x[i])); } ## [1] 1 10 ## [1] 2 15 ## [1] 3 17 ## [1] 4 16 ## [1] 5 25 Store squares of values of above vector in separate vector s using for loop s = NULL; for(i in 1:length(x)) { s[i] = x[i] ^ 2; } x; ## [1] 10 15 17 16 25 s; ## [1] 100 225 289 256 625 Note: Usually we don’t need to use for loop to perform operations on a single vector. The vector s created using above for loop can simply be created using command, s&lt;- x^2. But for loop is very useful to perform operations on multiple columns and rows of a matrix or data frame. 3.2.1 Task Create a matrix of 5 rows for values 1 to 50. Calculate the means of all rows in a matrix and store them in a vector m. mat=matrix(sample(1:50, 50, replace = TRUE), nrow=10); mat; ## [,1] [,2] [,3] [,4] [,5] ## [1,] 44 47 47 15 9 ## [2,] 34 10 45 26 13 ## [3,] 21 5 3 45 40 ## [4,] 11 13 39 5 38 ## [5,] 4 20 46 32 44 ## [6,] 9 38 49 40 5 ## [7,] 31 6 30 5 5 ## [8,] 4 40 13 14 14 ## [9,] 50 23 22 38 17 ## [10,] 45 1 15 29 34 m=NULL; for(i in 1:nrow(mat)) { m[i] = mean(mat[i,]); } m; ## [1] 32.4 25.6 22.8 21.2 29.2 28.2 15.4 17.0 30.0 24.8 3.3 Functions 3.3.1 Define function Define a function to find maximum values of every column of a matrix. getcolmax = function(m) { mx=NULL; for(i in 1:ncol(m)) { mx[i] = max(m[,i]); } return(mx); } 3.3.2 Call function mat=matrix(sample(1:50, 50, replace = TRUE), nrow=10); mat; ## [,1] [,2] [,3] [,4] [,5] ## [1,] 37 26 49 34 41 ## [2,] 49 40 8 37 42 ## [3,] 42 47 13 19 5 ## [4,] 36 13 17 49 21 ## [5,] 16 7 17 22 30 ## [6,] 42 10 5 18 11 ## [7,] 31 22 22 43 27 ## [8,] 35 39 8 33 19 ## [9,] 19 12 31 6 8 ## [10,] 29 11 12 16 46 getcolmax(mat); ## [1] 49 47 49 49 46 3.4 File IO Input_1.txt Input_2.txt Input_3.txt Input_4.txt Input_3.xlsx 1BUW.pdb 3.4.1 The read.table() function If data is well structured in tabular form, we can use read.table() to read the data. 3.4.2 Read data In file Input_1.txt all rows have equal numbers of columns. Each cell is separated by tab. Try ?read.table() to check the default values for arguments. Default: Header=FALSE, sep=&quot; &quot;, stringsAsFactors=T in1 = read.table(&quot;./data/Day1/Input_1.txt&quot;); in1; ## V1 V2 V3 V4 V5 ## 1 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 2 5.1 3.5 1.4 0.2 setosa ## 3 4.9 3 1.4 0.2 setosa ## 4 4.7 3.2 1.3 0.2 setosa ## 5 4.6 3.1 1.5 0.2 setosa ## 6 5 3.6 1.4 0.2 setosa ## 7 5.4 3.9 1.7 0.4 setosa str(in1); ## &#39;data.frame&#39;: 7 obs. of 5 variables: ## $ V1: Factor w/ 7 levels &quot;4.6&quot;,&quot;4.7&quot;,&quot;4.9&quot;,..: 7 5 3 2 1 4 6 ## $ V2: Factor w/ 7 levels &quot;3&quot;,&quot;3.1&quot;,&quot;3.2&quot;,..: 7 4 1 3 2 5 6 ## $ V3: Factor w/ 5 levels &quot;1.3&quot;,&quot;1.4&quot;,&quot;1.5&quot;,..: 5 2 2 1 3 2 4 ## $ V4: Factor w/ 3 levels &quot;0.2&quot;,&quot;0.4&quot;,&quot;Petal.Width&quot;: 3 1 1 1 1 1 2 ## $ V5: Factor w/ 2 levels &quot;setosa&quot;,&quot;Species&quot;: 2 1 1 1 1 1 1 We can see that header is considered as 1st row which is what we dont want. 3.4.3 About header=TRUE parameter in2 = read.table(&quot;./data/Day1/Input_1.txt&quot;, header = TRUE); in2; ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa str(in2); ## &#39;data.frame&#39;: 6 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 ## $ Species : Factor w/ 1 level &quot;setosa&quot;: 1 1 1 1 1 1 Header=T allows to read first row in a file as column names vector. Note the structure of in2. The first four columns are numeric as expected. But Species column has been considered as factors. Species column is considered as factor (categorical variable). If we dont want to read character data type as factor, we can explore stringsAsFactors = FALSE parameter, as shown below. 3.4.4 About stringsAsFactors = FALSE parameter in3 = read.table(&quot;./data/Day1/Input_1.txt&quot;, header = TRUE, stringsAsFactors = FALSE); in3; ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa str(in3); ## &#39;data.frame&#39;: 6 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 ## $ Species : chr &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; ... stringsAsFactors=F disables factor formatting of character columns. Check the data types of Species (chr). The first four columns are numeric. Now Species column has been considered as a character vector. 3.4.5 Other useful parameters: sep = &quot;&quot; comment.char = “#” na.strings = “NA” quote = “&quot;’” row.names col.names blank.lines.skip = TRUE 3.4.6 Read file with unequal columns in first row using read.table. Note that in file Input_2.txt, first row has 5 column fields while remaining rows have 6 fields/values i.e. first row has one column less than other rows. Under such format Header is automatically set to TRUE by read.table(). So in the below code, we didnt specify header=TRUE (optional here). in4 = read.table(&quot;./data/Day1/Input_2.txt&quot;, stringsAsFactors = FALSE); in4; ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa str(in4); ## &#39;data.frame&#39;: 6 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 ## $ Species : chr &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; ... 3.4.7 Read file consisting of comments, blank lines, null values Default arguments: skip=0, comment.char=“#”, na.strings=“NA” Please note that in file Input_3.txt consists of First two lines inserted by author but are not required for processing data. 2 comment lines starting with character “!” 1 blank line Row 3 has one missing value shown by NULL First row has 5 columns while remaining rows havecolumns. Under such input format Header is set to TRUE by read.table(). in5 = read.table(&quot;./data/Day1/Input_3.txt&quot;, stringsAsFactors = FALSE, comment.char = &quot;!&quot;, na.strings = NULL, skip=2); in5; ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 NULL 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa str(in5); ## &#39;data.frame&#39;: 6 obs. of 5 variables: ## $ Sepal.Length: chr &quot;5.1&quot; &quot;4.9&quot; &quot;NULL&quot; &quot;4.6&quot; ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 ## $ Species : chr &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; ... skip=2 removes first two lines not required for processing data by R. comment.char=“!”, instructs R to exclude lines starting with “!”. Default comment.char=“#” na.strings= “NULL” allows R to interpret NULL values as missing or NA characters, which will be helpful to remove such rows by na.omit() function. Default na.strings= “NA”. 3.4.8 Read csv file read.csv() Please note that values in file Input_4.txt are separated by comma, “,” and all rows have equal number of columns. See help for read.csv to check the default values for arguments. Default Header=TRUE, sep=“,” in7= read.csv(&quot;./data/Day1/Input_4.txt&quot;, stringsAsFactors = FALSE, comment.char = &quot;!&quot;, na.strings = NULL, skip=2); in7; ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 NULL setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa str(in7); ## &#39;data.frame&#39;: 6 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 ## $ Petal.Width : chr &quot;0.2&quot; &quot;0.2&quot; &quot;0.2&quot; &quot;NULL&quot; ... ## $ Species : chr &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; ... 3.4.9 Reading data from excel file We need to use gdata package to read excel file. To use, we must have perl installed in the system. library(&quot;gdata&quot;); ## gdata: read.xls support for &#39;XLS&#39; (Excel 97-2004) files ENABLED. ## ## gdata: read.xls support for &#39;XLSX&#39; (Excel 2007+) files ENABLED. ## ## Attaching package: &#39;gdata&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## nobs ## The following object is masked from &#39;package:utils&#39;: ## ## object.size ## The following object is masked from &#39;package:base&#39;: ## ## startsWith xl=read.xls(&quot;./data/Day1/Input_3.xlsx&quot;, sheet=1); xl; ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa str(xl); ## &#39;data.frame&#39;: 6 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 ## $ Species : Factor w/ 1 level &quot;setosa&quot;: 1 1 1 1 1 1 library(gdata) loads the gdata package to access read.xls() function. sheet option allows to choose sheet from input excel file. 3.4.10 Read data using readLines() By default readLines() read all the lines of a file. It returns a character vector. Check the str(ln). n=10 allows to read first 10 lines. pdb=readLines(&quot;./data/Day1/1BUW.pdb&quot;); str(pdb); ## chr [1:5484] &quot;HEADER OXYGEN STORAGE/TRANSPORT 06-SEP-98 1BUW &quot; ... pdb=readLines(&quot;./data/Day1/1BUW.pdb&quot;, n=10); pdb; ## [1] &quot;HEADER OXYGEN STORAGE/TRANSPORT 06-SEP-98 1BUW &quot; ## [2] &quot;TITLE CRYSTAL STRUCTURE OF S-NITROSO-NITROSYL HUMAN HEMOGLOBIN A &quot; ## [3] &quot;COMPND MOL_ID: 1; &quot; ## [4] &quot;COMPND 2 MOLECULE: PROTEIN (HEMOGLOBIN); &quot; ## [5] &quot;COMPND 3 CHAIN: A, C; &quot; ## [6] &quot;COMPND 4 SYNONYM: S-NITROSO-NITROSYLHB; &quot; ## [7] &quot;COMPND 5 OTHER_DETAILS: THE SULFHYDRYL GROUPS OF CYSTEINE 93 OF &quot; ## [8] &quot;COMPND 6 BETA SUBUNITS ARE S-NITROSYLATED. THE HEME GROUPS ARE &quot; ## [9] &quot;COMPND 7 NITROSYLATED.; &quot; ## [10] &quot;COMPND 8 MOL_ID: 2; &quot; 3.4.11 Read data using clipboard feature Read copied text using clipboard data=read.table(&quot;clipboard&quot;); 3.4.12 View data frame using View() View(in1); 3.4.13 Edit data frame using edit() edit(in1); 3.4.14 Write R data frames in a file using write.table() write.table(in1, file=&quot;./data/result.txt&quot;, sep=&quot;\\t&quot;, eol=&quot;\\n&quot;, quote=FALSE, row.names=FALSE, append = FALSE); 3.4.15 Write using cat() cat(&quot;Hello&quot;, file=&quot;./data/result.txt&quot;); "],
["data-manipulation.html", "Chapter 4 Data Manipulation 4.1 The apply() function 4.2 sapply() function 4.3 lapply() function 4.4 dplyr package", " Chapter 4 Data Manipulation 4.1 The apply() function # Consider a hypothetical gene expression dataset # Row: 30 Genes # Coulmn: Gene expression measured for 4 consecutive days. D1 to D4 # Values: between -1, 1 exp= matrix(rnorm(120), nrow=30) rownames(exp)=paste(&quot;G&quot;, 1:nrow(exp),sep=&quot;&quot;); colnames(exp)=paste(&quot;C&quot;, 1:ncol(exp),sep=&quot;&quot;); head(exp); ## C1 C2 C3 C4 ## G1 0.42250697 0.115481240 0.9107405111 -1.31108098 ## G2 1.28910663 2.030066085 -0.0008678641 -0.24143085 ## G3 0.09899481 1.552105828 -0.0230570114 -0.02128885 ## G4 0.64828421 2.265484243 -0.0015995037 -3.13170198 ## G5 0.94493743 -1.163972655 0.2415974990 0.20812871 ## G6 0.26797935 -0.002937112 -1.7066987904 1.41627913 dim(exp); ## [1] 30 4 # apply mean function on every row (margin=1) apply(exp, MARGIN = 1, FUN = mean); ## G1 G2 G3 G4 G5 ## 0.034411933 0.769218501 0.401688697 -0.054883259 0.057672745 ## G6 G7 G8 G9 G10 ## -0.006344355 -0.009252788 -0.375189963 0.220928976 -0.625319411 ## G11 G12 G13 G14 G15 ## 0.413438222 -0.311807452 -0.041655772 -0.607010622 -0.586886949 ## G16 G17 G18 G19 G20 ## -0.211600995 -0.198090278 0.243389875 -0.384356400 -0.856199014 ## G21 G22 G23 G24 G25 ## -0.302081532 -0.094819743 0.420375233 -0.333642706 0.373177273 ## G26 G27 G28 G29 G30 ## 0.483592310 -0.116332531 0.095815040 -0.125571278 -0.782530530 # apply mean function on every column (margin=2) apply(exp, MARGIN = 2, FUN = mean); ## C1 C2 C3 C4 ## -0.08648194 0.08338651 -0.07867099 -0.25288249 # Count how many genes up regulated in each day apply(exp, MARGIN = 2, FUN = function(x){sum(x&gt;0)}); ## C1 C2 C3 C4 ## 19 17 13 13 # Count how many days a gene is down regulated apply(exp, MARGIN = 1, FUN = function(x){sum(x&gt;0)}); ## G1 G2 G3 G4 G5 G6 G7 G8 G9 G10 G11 G12 G13 G14 G15 G16 G17 G18 ## 3 2 2 2 3 2 3 3 2 1 2 1 2 2 1 2 3 3 ## G19 G20 G21 G22 G23 G24 G25 G26 G27 G28 G29 G30 ## 2 1 2 1 2 2 2 3 2 3 2 1 4.2 sapply() function 4.3 lapply() function 4.4 dplyr package 4.4.1 Load dplyr library library(dplyr); ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:gdata&#39;: ## ## combine, first, last ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union 4.4.2 Load Gene Expression Data gen=read.table(&quot;./data/Day2/GenExp_data.txt&quot;, header = TRUE, stringsAsFactors = FALSE); head(gen); ## Gene D1 D2 D3 D4 D5 Path Genetype ## 1 Gene1 0.25 0.90 -0.59 -0.48 0.10 P1 Coding ## 2 Gene2 -0.12 1.66 -1.74 -0.43 -1.31 P1 Coding ## 3 Gene3 -1.34 0.04 -0.86 -0.59 -0.59 P1 Coding ## 4 Gene4 0.43 -1.69 -1.88 -0.39 0.10 P1 Coding ## 5 Gene5 1.04 1.04 -2.00 -2.44 1.07 P1 Coding ## 6 Gene6 -1.83 1.37 -0.01 -0.99 0.04 P1 Coding dim(gen); ## [1] 200 8 4.4.3 Filter rows with filter() filter() allows you to select a subset of rows in a data frame. Filter coding genes. temp=filter(gen, Genetype==&quot;Coding&quot;); head(temp); ## Gene D1 D2 D3 D4 D5 Path Genetype ## 1 Gene1 0.25 0.90 -0.59 -0.48 0.10 P1 Coding ## 2 Gene2 -0.12 1.66 -1.74 -0.43 -1.31 P1 Coding ## 3 Gene3 -1.34 0.04 -0.86 -0.59 -0.59 P1 Coding ## 4 Gene4 0.43 -1.69 -1.88 -0.39 0.10 P1 Coding ## 5 Gene5 1.04 1.04 -2.00 -2.44 1.07 P1 Coding ## 6 Gene6 -1.83 1.37 -0.01 -0.99 0.04 P1 Coding dim(temp); ## [1] 100 8 Q1) Filter only those genes which are in pathway P2. How many such genes are there Filter those genes whose gene expression values on Day1 (D1) &gt; 1.5 (up regulated). filter(gen, D1&gt; 1.5); ## Gene D1 D2 D3 D4 D5 Path Genetype ## 1 Gene18 1.78 -0.07 1.28 0.69 -0.41 P1 Coding ## 2 Gene26 2.12 0.14 0.54 -0.43 1.88 P1 Coding ## 3 Gene30 1.69 -0.26 0.05 -0.29 0.80 P1 Coding ## 4 Gene36 1.83 -0.28 -1.08 -1.08 0.43 P1 Noncoding ## 5 Gene49 1.90 0.67 0.20 0.07 1.17 P1 Noncoding ## 6 Gene66 1.82 -0.08 0.61 1.99 0.17 P1 Noncoding ## 7 Gene106 3.16 0.77 -0.11 0.67 -0.37 P2 Coding ## 8 Gene111 1.99 -0.47 0.36 0.19 -0.83 P2 Coding ## 9 Gene134 1.99 -0.83 0.08 -0.31 1.92 P3 Coding ## 10 Gene135 1.66 -1.58 0.43 0.22 -0.91 P3 Coding ## 11 Gene145 2.24 -1.69 0.70 -0.94 1.63 P3 Coding ## 12 Gene173 1.63 -0.89 0.59 2.56 -0.41 P4 Coding ## 13 Gene185 1.75 -0.20 -0.96 -0.40 -0.40 P4 Noncoding ## 14 Gene199 1.76 1.02 0.06 -0.79 0.69 P4 Noncoding Filter those genes whose gene expression values on Day1 (D1) &gt; 1.5 and Day2 (D2) &gt; 1. filter(gen, D1&gt; 1.5, D2&gt;1); ## Gene D1 D2 D3 D4 D5 Path Genetype ## 1 Gene199 1.76 1.02 0.06 -0.79 0.69 P4 Noncoding Q2) Filter those genes whose expression on Day1 &gt; 1.5 and belong to Pathway P2. Filter genes whose D1 or D2 expression is &gt; 1.5 # Using OR condition: | temp=filter(gen, D1 &gt; 1.5 | D2 &gt; 1.5); head(temp); ## Gene D1 D2 D3 D4 D5 Path Genetype ## 1 Gene2 -0.12 1.66 -1.74 -0.43 -1.31 P1 Coding ## 2 Gene18 1.78 -0.07 1.28 0.69 -0.41 P1 Coding ## 3 Gene25 -2.09 2.12 0.11 -0.72 -0.17 P1 Coding ## 4 Gene26 2.12 0.14 0.54 -0.43 1.88 P1 Coding ## 5 Gene30 1.69 -0.26 0.05 -0.29 0.80 P1 Coding ## 6 Gene36 1.83 -0.28 -1.08 -1.08 0.43 P1 Noncoding dim(temp); ## [1] 27 8 Filter genes from pathway P2 whose D1 or D2 expression is &gt; 1.5 filter(gen, D1 &gt; 1.5 | D2 &gt; 1.5, Path==&quot;P2&quot;) ## Gene D1 D2 D3 D4 D5 Path Genetype ## 1 Gene75 0.05 2.33 1.25 0.79 1.75 P2 Noncoding ## 2 Gene81 -1.90 1.57 -1.05 -0.63 -0.26 P2 Noncoding ## 3 Gene106 3.16 0.77 -0.11 0.67 -0.37 P2 Coding ## 4 Gene109 0.55 1.65 -0.49 0.56 -0.66 P2 Coding ## 5 Gene111 1.99 -0.47 0.36 0.19 -0.83 P2 Coding 4.4.4 Piping using %&gt;% Piping minimizes the use of variables. It cleans the code. Results from left hand site is piped to right hand side. How many genes are there in Pathway P2 filter(gen, Path==&quot;P2&quot;) %&gt;% nrow ## [1] 60 Filter those genes which below to pathway P2. For the filtered genes, filter further whose D1 expression are &gt; 1 filter(gen, Path==&quot;P2&quot;) %&gt;% filter(., D1 &gt; 1) %&gt;% nrow ## [1] 6 # . is optional if used as 1st argument filter(gen, Path==&quot;P2&quot;) %&gt;% filter(D1 &gt; 1) %&gt;% nrow ## [1] 6 4.4.5 Arrange rows with arrange() # Arrange genes first as per Pathway followed by expression values on D1 arrange(gen, Path, D1) %&gt;% head ## Gene D1 D2 D3 D4 D5 Path Genetype ## 1 Gene25 -2.09 2.12 0.11 -0.72 -0.17 P1 Coding ## 2 Gene6 -1.83 1.37 -0.01 -0.99 0.04 P1 Coding ## 3 Gene35 -1.62 0.44 2.04 3.35 -0.58 P1 Noncoding ## 4 Gene20 -1.57 -1.12 1.08 0.60 -0.64 P1 Coding ## 5 Gene3 -1.34 0.04 -0.86 -0.59 -0.59 P1 Coding ## 6 Gene68 -1.32 0.37 1.50 -0.08 1.04 P1 Noncoding # Arrange genes first as per Pathway followed by expression values on D1 in descending order arrange(gen, Path, desc(D1)) %&gt;% head ## Gene D1 D2 D3 D4 D5 Path Genetype ## 1 Gene26 2.12 0.14 0.54 -0.43 1.88 P1 Coding ## 2 Gene49 1.90 0.67 0.20 0.07 1.17 P1 Noncoding ## 3 Gene36 1.83 -0.28 -1.08 -1.08 0.43 P1 Noncoding ## 4 Gene66 1.82 -0.08 0.61 1.99 0.17 P1 Noncoding ## 5 Gene18 1.78 -0.07 1.28 0.69 -0.41 P1 Coding ## 6 Gene30 1.69 -0.26 0.05 -0.29 0.80 P1 Coding 4.4.6 Select rows position wise using slice() # Select 25th to 30th row slice(gen, 25:30); ## Gene D1 D2 D3 D4 D5 Path Genetype ## 1 Gene25 -2.09 2.12 0.11 -0.72 -0.17 P1 Coding ## 2 Gene26 2.12 0.14 0.54 -0.43 1.88 P1 Coding ## 3 Gene27 0.09 -0.78 -0.72 -0.21 0.47 P1 Coding ## 4 Gene28 -0.49 -0.92 1.56 0.59 -1.37 P1 Coding ## 5 Gene29 1.01 -0.72 0.07 0.32 0.99 P1 Coding ## 6 Gene30 1.69 -0.26 0.05 -0.29 0.80 P1 Coding 4.4.7 Select column using select() # Select D1, D5 and Path column select(gen, D1, D5, Path) %&gt;% head; ## D1 D5 Path ## 1 0.25 0.10 P1 ## 2 -0.12 -1.31 P1 ## 3 -1.34 -0.59 P1 ## 4 0.43 0.10 P1 ## 5 1.04 1.07 P1 ## 6 -1.83 0.04 P1 # Exclude D2 column select(gen, -D2) %&gt;% head; ## Gene D1 D3 D4 D5 Path Genetype ## 1 Gene1 0.25 -0.59 -0.48 0.10 P1 Coding ## 2 Gene2 -0.12 -1.74 -0.43 -1.31 P1 Coding ## 3 Gene3 -1.34 -0.86 -0.59 -0.59 P1 Coding ## 4 Gene4 0.43 -1.88 -0.39 0.10 P1 Coding ## 5 Gene5 1.04 -2.00 -2.44 1.07 P1 Coding ## 6 Gene6 -1.83 -0.01 -0.99 0.04 P1 Coding # Exclude D2, D5 column select(gen, -c(D2,D5)) %&gt;% head; ## Gene D1 D3 D4 Path Genetype ## 1 Gene1 0.25 -0.59 -0.48 P1 Coding ## 2 Gene2 -0.12 -1.74 -0.43 P1 Coding ## 3 Gene3 -1.34 -0.86 -0.59 P1 Coding ## 4 Gene4 0.43 -1.88 -0.39 P1 Coding ## 5 Gene5 1.04 -2.00 -2.44 P1 Coding ## 6 Gene6 -1.83 -0.01 -0.99 P1 Coding # Column name starts with select(gen, starts_with(&quot;D&quot;)) %&gt;% head; ## D1 D2 D3 D4 D5 ## 1 0.25 0.90 -0.59 -0.48 0.10 ## 2 -0.12 1.66 -1.74 -0.43 -1.31 ## 3 -1.34 0.04 -0.86 -0.59 -0.59 ## 4 0.43 -1.69 -1.88 -0.39 0.10 ## 5 1.04 1.04 -2.00 -2.44 1.07 ## 6 -1.83 1.37 -0.01 -0.99 0.04 # Column name ends with 3 select(gen, ends_with(&quot;3&quot;)) %&gt;% head; ## D3 ## 1 -0.59 ## 2 -1.74 ## 3 -0.86 ## 4 -1.88 ## 5 -2.00 ## 6 -0.01 # Column name contains &quot;e&quot; select(gen, contains(&quot;e&quot;)) %&gt;% head; ## Gene Genetype ## 1 Gene1 Coding ## 2 Gene2 Coding ## 3 Gene3 Coding ## 4 Gene4 Coding ## 5 Gene5 Coding ## 6 Gene6 Coding # Select all column from D1 to Path select(gen, D1:Path) %&gt;% head; ## D1 D2 D3 D4 D5 Path ## 1 0.25 0.90 -0.59 -0.48 0.10 P1 ## 2 -0.12 1.66 -1.74 -0.43 -1.31 P1 ## 3 -1.34 0.04 -0.86 -0.59 -0.59 P1 ## 4 0.43 -1.69 -1.88 -0.39 0.10 P1 ## 5 1.04 1.04 -2.00 -2.44 1.07 P1 ## 6 -1.83 1.37 -0.01 -0.99 0.04 P1 # Select 2nd and 4th column select(gen, c(2,4)) %&gt;% head ## D1 D3 ## 1 0.25 -0.59 ## 2 -0.12 -1.74 ## 3 -1.34 -0.86 ## 4 0.43 -1.88 ## 5 1.04 -2.00 ## 6 -1.83 -0.01 4.4.8 Extract unique rows using distinct() # Select unique entries in D1 column select(gen, D1) %&gt;% distinct %&gt;% nrow ## [1] 154 # Select D2 and Path column then find unique rows select(gen, D2, Path) %&gt;% distinct %&gt;% nrow ## [1] 191 4.4.9 Add new columns with mutate() and transmute() function # mutate(gen,difD1D2=D1-D2): Adds a column named as “difD1D2”, which consists of difference between values of D1 and D2 gene expressions, to the existing dataset. mutate(gen, diffD1D2 = D1-D2) %&gt;% head ## Gene D1 D2 D3 D4 D5 Path Genetype diffD1D2 ## 1 Gene1 0.25 0.90 -0.59 -0.48 0.10 P1 Coding -0.65 ## 2 Gene2 -0.12 1.66 -1.74 -0.43 -1.31 P1 Coding -1.78 ## 3 Gene3 -1.34 0.04 -0.86 -0.59 -0.59 P1 Coding -1.38 ## 4 Gene4 0.43 -1.69 -1.88 -0.39 0.10 P1 Coding 2.12 ## 5 Gene5 1.04 1.04 -2.00 -2.44 1.07 P1 Coding 0.00 ## 6 Gene6 -1.83 1.37 -0.01 -0.99 0.04 P1 Coding -3.20 # mutate(gen,difD1D2=D1-D2,pdifD1D2=difD1D2*100) Use newly created column difD1D2 to create another pdifD1D2. So, you can create and reuse newly created columns. mutate(gen, diffD1D2 = D1-D2, pdiffD1D2=diffD1D2*100) %&gt;% head ## Gene D1 D2 D3 D4 D5 Path Genetype diffD1D2 pdiffD1D2 ## 1 Gene1 0.25 0.90 -0.59 -0.48 0.10 P1 Coding -0.65 -65 ## 2 Gene2 -0.12 1.66 -1.74 -0.43 -1.31 P1 Coding -1.78 -178 ## 3 Gene3 -1.34 0.04 -0.86 -0.59 -0.59 P1 Coding -1.38 -138 ## 4 Gene4 0.43 -1.69 -1.88 -0.39 0.10 P1 Coding 2.12 212 ## 5 Gene5 1.04 1.04 -2.00 -2.44 1.07 P1 Coding 0.00 0 ## 6 Gene6 -1.83 1.37 -0.01 -0.99 0.04 P1 Coding -3.20 -320 mutate(gen, diffD1D2 = D1-D2, pdiffD1D2=diffD1D2*100, meanexp=rowMeans(select(gen,D1,D2,D3,D4,D5))) %&gt;% head ## Gene D1 D2 D3 D4 D5 Path Genetype diffD1D2 pdiffD1D2 ## 1 Gene1 0.25 0.90 -0.59 -0.48 0.10 P1 Coding -0.65 -65 ## 2 Gene2 -0.12 1.66 -1.74 -0.43 -1.31 P1 Coding -1.78 -178 ## 3 Gene3 -1.34 0.04 -0.86 -0.59 -0.59 P1 Coding -1.38 -138 ## 4 Gene4 0.43 -1.69 -1.88 -0.39 0.10 P1 Coding 2.12 212 ## 5 Gene5 1.04 1.04 -2.00 -2.44 1.07 P1 Coding 0.00 0 ## 6 Gene6 -1.83 1.37 -0.01 -0.99 0.04 P1 Coding -3.20 -320 ## meanexp ## 1 0.036 ## 2 -0.388 ## 3 -0.668 ## 4 -0.686 ## 5 -0.258 ## 6 -0.284 # Just keeps the new columns only. transmute(gen, difD1D2=D1-D2, pdifD1D2 = difD1D2 * 100) %&gt;% head ## difD1D2 pdifD1D2 ## 1 -0.65 -65 ## 2 -1.78 -178 ## 3 -1.38 -138 ## 4 2.12 212 ## 5 0.00 0 ## 6 -3.20 -320 4.4.10 Summarise values with summarise() summarise(gen, D1mean = mean(D1), D2mean = mean(D2)) ## D1mean D2mean ## 1 0.041 0.00235 4.4.11 Grouped operations # Group genes as per pathway gengrp=group_by(gen, Path); # For every group then do some operation summarise(gengrp, n()) ## # A tibble: 4 x 2 ## Path `n()` ## &lt;chr&gt; &lt;int&gt; ## 1 P1 70 ## 2 P2 60 ## 3 P3 40 ## 4 P4 30 summarise(gengrp, mean(D1), mean(D2), mean(D3)) ## # A tibble: 4 x 4 ## Path `mean(D1)` `mean(D2)` `mean(D3)` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 P1 0.0453 -0.051 -0.108 ## 2 P2 -0.0450 0.0115 -0.147 ## 3 P3 0.152 -0.118 -0.111 ## 4 P4 0.0547 0.269 -0.269 summarise(gengrp, mD1=mean(D1), mD2=mean(D2), mD3=mean(D3)) %&gt;% filter(.,mD1&gt;0.05) %&gt;% select(.,Path,mD1); ## # A tibble: 2 x 2 ## Path mD1 ## &lt;chr&gt; &lt;dbl&gt; ## 1 P3 0.152 ## 2 P4 0.0547 summarise(gengrp, OverExp_Genecount_D1=sum(D1&gt;1.5), OverExp_Genecount_D2=sum(D2&gt;1.5), OverExp_Genecount_D3=sum(D3&gt;1.5)) ## # A tibble: 4 x 4 ## Path OverExp_Genecount_D1 OverExp_Genecount_D2 OverExp_Genecount_D3 ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 P1 6 3 7 ## 2 P2 2 3 4 ## 3 P3 3 2 0 ## 4 P4 3 5 1 4.4.12 Joins two table Currently dplyr supports following join types: inner_join() left_join() right_join() semi_join() anti_join() full_join() Create Pathway information data frame which we will use to demonstrate join # Select one gene from each pathway, for demo purpose tempgen = group_by(gen,Path) %&gt;% slice(1); # Create Pathway information. Note that we dont have pathway information for P4 Pathwayinfo=data.frame(Path=c(&quot;P1&quot;,&quot;P2&quot;,&quot;P3&quot;,&quot;P5&quot;), Name=c(&quot;Glycolysis&quot;,&quot;Gluconeogenesis&quot;,&quot;Purine metabolism&quot;,&quot;Apotopsis&quot;), ID=c(&quot;ID0752&quot;,&quot;ID3251&quot;,&quot;ID2567&quot;,&quot;ID4568&quot;)); Pathwayinfo; ## Path Name ID ## 1 P1 Glycolysis ID0752 ## 2 P2 Gluconeogenesis ID3251 ## 3 P3 Purine metabolism ID2567 ## 4 P5 Apotopsis ID4568 tempgen; ## # A tibble: 4 x 8 ## # Groups: Path [4] ## Gene D1 D2 D3 D4 D5 Path Genetype ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Gene1 0.25 0.9 -0.59 -0.48 0.1 P1 Coding ## 2 Gene71 -1.05 0.84 -1.43 0.65 -1.05 P2 Noncoding ## 3 Gene131 0.59 0 0.51 0.2 0.33 P3 Coding ## 4 Gene171 1.44 -0.31 -0.56 -1.09 -0.76 P4 Coding Pathwayinfo; ## Path Name ID ## 1 P1 Glycolysis ID0752 ## 2 P2 Gluconeogenesis ID3251 ## 3 P3 Purine metabolism ID2567 ## 4 P5 Apotopsis ID4568 # Return all rows from x where there are matching values in y (i.e. matching x rows) # Return all columns from x and y. # If there are multiple matches between x and y, all combination of the matches are returned. inner_join(tempgen, Pathwayinfo, by=&quot;Path&quot;); ## Warning: Column `Path` joining character vector and factor, coercing into ## character vector ## # A tibble: 3 x 10 ## # Groups: Path [3] ## Gene D1 D2 D3 D4 D5 Path Genetype Name ID ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; ## 1 Gene1 0.25 0.9 -0.59 -0.48 0.1 P1 Coding Glycolysis ID07… ## 2 Gene71 -1.05 0.84 -1.43 0.65 -1.05 P2 Noncoding Gluconeogene… ID32… ## 3 Gene131 0.59 0 0.51 0.2 0.33 P3 Coding Purine metab… ID25… # Return all rows from x # All columns from x and y. # Rows in x with no match in y will have NA values in the new columns. If there are multiple matches between x and y, all combinations of the matches are returned. left_join(tempgen, Pathwayinfo, by=&quot;Path&quot;); ## Warning: Column `Path` joining character vector and factor, coercing into ## character vector ## # A tibble: 4 x 10 ## # Groups: Path [4] ## Gene D1 D2 D3 D4 D5 Path Genetype Name ID ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; ## 1 Gene1 0.25 0.9 -0.59 -0.48 0.1 P1 Coding Glycolysis ID07… ## 2 Gene71 -1.05 0.84 -1.43 0.65 -1.05 P2 Noncoding Gluconeogene… ID32… ## 3 Gene131 0.59 0 0.51 0.2 0.33 P3 Coding Purine metab… ID25… ## 4 Gene171 1.44 -0.31 -0.56 -1.09 -0.76 P4 Coding &lt;NA&gt; &lt;NA&gt; # Return all rows from y # all columns from x and y. # Rows in y with no match in x will have NA values in the new columns. If there are multiple matches between x and y, all combinations of the matches are returned. right_join(tempgen, Pathwayinfo, by=&quot;Path&quot;); ## Warning: Column `Path` joining character vector and factor, coercing into ## character vector ## # A tibble: 4 x 10 ## # Groups: Path [4] ## Gene D1 D2 D3 D4 D5 Path Genetype Name ID ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; ## 1 Gene1 0.25 0.9 -0.59 -0.48 0.1 P1 Coding Glycolysis ID07… ## 2 Gene71 -1.05 0.84 -1.43 0.65 -1.05 P2 Noncoding Gluconeogene… ID32… ## 3 Gene131 0.59 0 0.51 0.2 0.33 P3 Coding Purine metab… ID25… ## 4 &lt;NA&gt; NA NA NA NA NA P5 &lt;NA&gt; Apotopsis ID45… # Return all rows and all columns from both x and y. # Where there are not matching values, returns NA for the one missing. full_join(tempgen, Pathwayinfo, by=&quot;Path&quot;); ## Warning: Column `Path` joining character vector and factor, coercing into ## character vector ## # A tibble: 5 x 10 ## # Groups: Path [5] ## Gene D1 D2 D3 D4 D5 Path Genetype Name ID ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; ## 1 Gene1 0.25 0.9 -0.59 -0.48 0.1 P1 Coding Glycolysis ID07… ## 2 Gene71 -1.05 0.84 -1.43 0.65 -1.05 P2 Noncoding Gluconeogene… ID32… ## 3 Gene131 0.59 0 0.51 0.2 0.33 P3 Coding Purine metab… ID25… ## 4 Gene171 1.44 -0.31 -0.56 -1.09 -0.76 P4 Coding &lt;NA&gt; &lt;NA&gt; ## 5 &lt;NA&gt; NA NA NA NA NA P5 &lt;NA&gt; Apotopsis ID45… # Return all rows from x where there are matching values in y, keeping just columns from x. semi_join(tempgen, Pathwayinfo, by=&quot;Path&quot;); ## Warning: Column `Path` joining character vector and factor, coercing into ## character vector ## # A tibble: 3 x 8 ## # Groups: Path [3] ## Gene D1 D2 D3 D4 D5 Path Genetype ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Gene1 0.25 0.9 -0.59 -0.48 0.1 P1 Coding ## 2 Gene71 -1.05 0.84 -1.43 0.65 -1.05 P2 Noncoding ## 3 Gene131 0.59 0 0.51 0.2 0.33 P3 Coding # Return all rows from x where there are not matching values in y, keeping just columns from x. anti_join(tempgen, Pathwayinfo, by=&quot;Path&quot;); ## Warning: Column `Path` joining character vector and factor, coercing into ## character vector ## # A tibble: 1 x 8 ## # Groups: Path [1] ## Gene D1 D2 D3 D4 D5 Path Genetype ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Gene171 1.44 -0.31 -0.56 -1.09 -0.76 P4 Coding 4.4.13 References https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html "],
["data-visualization.html", "Chapter 5 Data Visualization 5.1 Base Graphics 5.2 Plot using ggplot2", " Chapter 5 Data Visualization 5.1 Base Graphics R has high-level and low-level plotting functions. 5.1.1 Simple scatter plot x=sample(x = 100, size = 50); # Create a vector x, 50 elements, values between 0 and 100 plot(x); # Plot the value of x against the index plot(x, type=&quot;l&quot;); # type: line plot(x, type=&quot;o&quot;); # type: overplotted (point and line) plot(x, type=&quot;h&quot;); # type: histogram like plot(x, type=&quot;s&quot;); # type: stair steps plot(x, type=&quot;n&quot;); # type: no plotting 5.1.2 Saving plot Steps: Create a graphics device (BMP, JPEG, PNG, TIFF) then plot and switch off the device. # File will be saved in current working directory getwd() png(filename = &quot;myplot.png&quot;, width = 480, height = 480, units = &quot;px&quot; , type=&quot;cairo&quot;); plot(x, type=&quot;l&quot;); dev.off(); ## png ## 2 5.1.3 Add title/subtitle/x-axis label/y-axis label to plot 5.1.4 Increase line thickness # Parameters: lwd plot(x, type=&quot;l&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2); 5.1.5 Assign color to lines and points # Parameters: col plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = &quot;red&quot;); # There are 50 elements in x. so 50 points in plot. # col=c(“red”,”green”,”blue”) is a vector of 3 elements which will be recycled to color the 50 points. # So points will look like alternate red/green/blue. plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;)); # length(x) is 50. col=rainbow(length(x)) will generate 50 consecutive colors which will be assigned to 50 points on the plot. plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = rainbow(length(x))); # Lets display first 20 points as red, next 20 as blue and last 10 as green. Create a vector of colors where red is repeated 20 times followed by blue 20 times and green 10 times. # Using c() and rep() function we created veccol vector # col=veccol assigns 50 colors of veccol vector to 50 points on the plot. veccol=c(rep(&quot;red&quot;,20),rep(&quot;blue&quot;,20),rep(&quot;green&quot;,10)); plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = veccol); 5.1.6 Explore built-in colors head(colors(), 50) # Explore default colors, 50 displayed ## [1] &quot;white&quot; &quot;aliceblue&quot; &quot;antiquewhite&quot; &quot;antiquewhite1&quot; ## [5] &quot;antiquewhite2&quot; &quot;antiquewhite3&quot; &quot;antiquewhite4&quot; &quot;aquamarine&quot; ## [9] &quot;aquamarine1&quot; &quot;aquamarine2&quot; &quot;aquamarine3&quot; &quot;aquamarine4&quot; ## [13] &quot;azure&quot; &quot;azure1&quot; &quot;azure2&quot; &quot;azure3&quot; ## [17] &quot;azure4&quot; &quot;beige&quot; &quot;bisque&quot; &quot;bisque1&quot; ## [21] &quot;bisque2&quot; &quot;bisque3&quot; &quot;bisque4&quot; &quot;black&quot; ## [25] &quot;blanchedalmond&quot; &quot;blue&quot; &quot;blue1&quot; &quot;blue2&quot; ## [29] &quot;blue3&quot; &quot;blue4&quot; &quot;blueviolet&quot; &quot;brown&quot; ## [33] &quot;brown1&quot; &quot;brown2&quot; &quot;brown3&quot; &quot;brown4&quot; ## [37] &quot;burlywood&quot; &quot;burlywood1&quot; &quot;burlywood2&quot; &quot;burlywood3&quot; ## [41] &quot;burlywood4&quot; &quot;cadetblue&quot; &quot;cadetblue1&quot; &quot;cadetblue2&quot; ## [45] &quot;cadetblue3&quot; &quot;cadetblue4&quot; &quot;chartreuse&quot; &quot;chartreuse1&quot; ## [49] &quot;chartreuse2&quot; &quot;chartreuse3&quot; # colors() will list all colorsUsing c() and rep() function we created veccol vector ## function (mode = &quot;logical&quot;, length = 0L) ## .Internal(vector(mode, length)) ## &lt;bytecode: 0x559bee972fd8&gt; ## &lt;environment: namespace:base&gt; rainbow(5); # Create a vector of 5 contiguous colors. ## [1] &quot;#FF0000FF&quot; &quot;#CCFF00FF&quot; &quot;#00FF66FF&quot; &quot;#0066FFFF&quot; &quot;#CC00FFFF&quot; 5.1.7 Explore different symbols # Parameter: pch # Try ?pch to explore more about points. plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = veccol, pch = 15); 5.1.8 Explore different line types # Parameter: lty # Try other lty values (0=blank, 1=solid (default), 2=dashed, 3=dotted, 4=dotdash, 5=longdash, 6=twodash) plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = veccol, pch = 15, lty=2); 5.1.9 Rescale the x-axis and y-axis # Parameter: xlim, ylim. # xlim and ylim parameters are used to change the default x and y axis ranges. # We have to give the minimum and maximum values of x and y-axis. # xlim=c(0,100) will scale x-axis from 0 to 100. plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = veccol, pch = 15, lty=2, xlim=c(0,100), ylim=c(0,150)); 5.1.10 Magnification of labels and symbols # Parameter: cex.lab, cex.axis, cex.main, cex.sub, cex # cex.lab=1.5 will magnify the x-axis and y-axis labels by 50%. # Default cex.lab=1 # cex.axis=1.2 magnifies the labels on the tick-marks of axis. # cex.main=1.2 magnifies the title # cex.sub=1.2 magnifies the subtitle. # cex=1.2 magnifies the symbol/text on the plots plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = veccol, pch = 15, lty=2, cex.lab=1.2, cex.axis=1.2, cex= 1.2, cex.main=1.2); 5.1.11 Explore bty (box type) # bty=”n” will not draw box around the plot. # If bty is one of &quot;o&quot; (the default), &quot;l&quot;, &quot;7&quot;, &quot;c&quot;, &quot;u&quot;, or &quot;]&quot; the resulting box resembles the corresponding upper case letter. plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = veccol, pch = 15, lty=2, cex.lab=1.2, cex.axis=1.2, cex= 1.2, cex.main=1.2, bty=&quot;n&quot;); 5.1.12 Explore las (style of axis labels) # Style of axis tick mark labels is given by las=1. # 0: parallel to axis, 1: always horizontal, 2: always perpendicular to axis, 3: always vertical) plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = veccol, pch = 15, lty=2, cex.lab=1.2, cex.axis=1.2, cex= 1.2, cex.main=1.2, las = 1); 5.1.13 Explore col.axis, col.lab, col.main, col.sub parameters # col.axis=”red” will color the axis labels on the tick marks to red color # col.lab=”brown” will color the x-axis and y-axis labels to brown. plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = veccol, pch = 15, lty=2, cex.lab=1.2, cex.axis=1.2, cex= 1.2, cex.main=1.2, las = 1, col.axis = &quot;red&quot;, col.lab = &quot;blue&quot;, col.main = &quot;pink&quot;, col.sub = &quot;brown&quot;); 5.1.14 Low level plotting functions (lines) lines() draws lines on a plot. To draw lines we need x and y coordinates of points. The syntax: pass x- coordinates of all points as 1st argument and all y- coordinates as 2nd argument. lty and lwd can alsoplot(x, type=“o”, xlab = “Index”, ylab = “Expression values”, main= “Scatter plot”, lwd = 2, col = veccol, pch = 15, lty=2, cex.lab=1.2, cex.axis=1.2, cex= 1.2, cex.main=1.2, las = 1, ylim=c(0,150)); be used. # First call high level plotting function plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = veccol, pch = 15, lty=2, cex.lab=1.2, cex.axis=1.2, cex= 1.2, cex.main=1.2, las = 1, ylim=c(0,150)); # Call low level plotting functions which will be applied on the plot generated above. lines(c(0,60),c(50,50), lty=2, col=&quot;red&quot;, lwd=2); lines(c(-10,60),c(100,100), lty=2, col=&quot;blue&quot;,lwd=2); 5.1.15 Low level plotting functions (legend) legend() draws legends on a plot. To draw legend we need to specify where to draw legend by specifying x and y coordinates as 1st and 2nd argument. The legends to be written as 3rd argument. Colors of legends are passed by col parameter while lwd sets line width. plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = veccol, pch = 15, lty=2, cex.lab=1.2, cex.axis=1.2, cex= 1.2, cex.main=1.2, las = 1, ylim=c(0,150)); legend(0,155,c(&quot;Day1&quot;,&quot;Day2&quot;,&quot;Day3&quot;), lwd=2, col=c(&quot;red&quot;,&quot;blue&quot;,&quot;green&quot;)) 5.1.16 Adding texts to existing plot (text) text() adds texts to existing plots. To add text, we need x- and y- coordinates which we pass as 1st and 2nd arguments respectively. Third argument (labels) is the texts that are to be written on the plot. Since we want to write the values of x on the points, the x and y coordinates of text will be exactly same as the points i.e. x-coordinates will be 1 to 50 while y coordinates will be value of x itself. The text to be added will also be x. plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = veccol, pch = 15, lty=2, cex.lab=1.2, cex.axis=1.2, cex= 1.2, cex.main=1.2, las = 1, ylim=c(0,150)); text(1:50,x,labels=x); pos=3 will add the text on the top of point. pos=1/2/3/4 means below/left/top/right to point cex=0.6 decrease the text size. plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = veccol, pch = 15, lty=2, cex.lab=1.2, cex.axis=1.2, cex= 1.2, cex.main=1.2, las = 1, ylim=c(0,150)); text(1:50,x,labels=x, pos=3, cex=0.6); Offset is usedbarplot(A, names.arg = c(“Day1”,“Day2”,“Day3”,“Day4”,“Day5”), xlab=“Days”, ylab=“Revenue”, border=“red”); to put space between point and text. plot(x, type=&quot;o&quot;, xlab = &quot;Index&quot;, ylab = &quot;Expression values&quot;, main= &quot;Scatter plot&quot;, lwd = 2, col = veccol, pch = 15, lty=2, cex.lab=1.2, cex.axis=1.2, cex= 1.2, cex.main=1.2, las = 1, ylim=c(0,150)); text(1:50,x,labels=x, pos=3, cex=0.6, offset = 0.8); 5.1.17 Explore Line Plot Create 3 vectors x1, x2, x3 with 50 elements with different range values. To visualize x1, x2 and x3 as lines, we need to first draw x1 using high-level plot() command then x2 and x3 can be drawn using low-level lines() command by adding lines to the already existing plots. Below code plot 3-lines but we can’t see x2 and x3 lines since the plot(x1) will plot using x1 whose y-axis margin lies between 0-50 but x2 values between 50-100 and x3 between 100-150. So x2 and x3 will be out-of margin on the plot. x1=sample(1:50, 50); x2=sample(50:100, 50); x3=sample(100:150, 50); plot(x1, type= &quot;l&quot;, lty = 2); lines(x2, lty = 2, col=&quot;red&quot;); lines(x3, lty = 2, col = &quot;blue&quot;); To correctly see x2 and x3, we fi{#morelines}rst set the ylim to 0-200 plot(x1, type= &quot;l&quot;, lty = 2, ylim=c(0,200)); lines(x2, lty = 2, col=&quot;red&quot;); lines(x3, lty = 2, col = &quot;blue&quot;); 5.1.18 Explore simple Bar plot Barplot: Here x can be considered as heights of bars in a bar plot. x=c(3, 2, 6, 8, 4); barplot(x); # Using names.arg=c() we can name the bars. # border=”red” will give red border to bars. barplot(x, names.arg = c(&quot;Day1&quot;,&quot;Day2&quot;,&quot;Day3&quot;,&quot;Day4&quot;,&quot;Day5&quot;), border = &quot;red&quot;, xlab=&quot;Days&quot;, ylab=&quot;Revenue&quot;); # horiz=TRUE will make horizontal bar plot. Note: xlab and ylab need to be changed accordingly. barplot(x, names.arg = c(&quot;Day1&quot;,&quot;Day2&quot;,&quot;Day3&quot;,&quot;Day4&quot;,&quot;Day5&quot;), border = &quot;red&quot;, horiz = TRUE, xlab=&quot;Revenue&quot;, ylab=&quot;Days&quot;); 5.1.19 Explore stacked bar plot When argument to barplot() is a matrix, a stacked bar plot will be generated. # Create a matrix A &lt;- matrix(c(3,5,7,1,9,4,6,5,2,12,2,1,7,6,8), nrow=3, byrow = TRUE); print(A); ## [,1] [,2] [,3] [,4] [,5] ## [1,] 3 5 7 1 9 ## [2,] 4 6 5 2 12 ## [3,] 2 1 7 6 8 barplot(A); # Using names.arg assign name to each bar barplot(A, names.arg = c(&quot;Day1&quot;,&quot;Day2&quot;,&quot;Day3&quot;,&quot;Day4&quot;,&quot;Day5&quot;), xlab=&quot;Days&quot;, ylab=&quot;Revenue&quot;, border=&quot;red&quot;); # col parameter to color each stack. barplot(A, names.arg = c(&quot;Day1&quot;,&quot;Day2&quot;,&quot;Day3&quot;,&quot;Day4&quot;,&quot;Day5&quot;), xlab=&quot;Days&quot;, ylab=&quot;Revenue&quot;, border=&quot;red&quot;, col=c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;)); # Add legend (Note on using pch in legend) legend(x=0.2, y=24,c(&quot;High&quot;,&quot;Mid&quot;,&quot;Low&quot;), pch = 15, col=c(&quot;red&quot;,&quot;blue&quot;,&quot;green&quot;)) 5.1.20 Grouped Bar plots The argument beside=TRUE will convert stacked to grouped bar plot space=c(0.1, 1) specifies to add 0.1 spacing between bars and spacing of 1 between each groups. barplot(A, names.arg = c(&quot;Day1&quot;,&quot;Day2&quot;,&quot;Day3&quot;,&quot;Day4&quot;,&quot;Day5&quot;), xlab=&quot;Days&quot;, ylab=&quot;Revenue&quot;, border=&quot;red&quot;, col=c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;), beside = TRUE, space = c(0.1, 1)); 5.1.21 Histogram x=sample(20,1000, replace = TRUE); hist(x); # labels=TRUE will add label on the bars. # col will fill the bars with colors # border is to give border color of bar. hist(x, labels = TRUE, col = &quot;lightblue&quot;, border=&quot;pink&quot;,ylim=c(0,130)); # Breaks=20 will assign number of histogram bins to 20. hist(x, labels = TRUE, col = &quot;lightblue&quot;, border=&quot;pink&quot;,ylim=c(0,130), breaks = 20); # Freq=FALSE will plot probability instead of frequency. Note: Probaility lies between 0 to 1. So we have to change ylim accordingly. hist(x, labels = FALSE, col = &quot;lightblue&quot;, border=&quot;pink&quot;,ylim=c(0,0.2), breaks = 20, freq = FALSE); 5.1.22 Density plot density(x) function computes kernel density estimates of x which is plotted by plot(density(x)). plot(density(x), xlab=&quot;Value&quot;, ylab=&quot;Probability density of x&quot;, cex.lab=1.2, cex.axis=1.2); 5.1.23 Plot density plot of two distributions x and y are two distributions whose density are estimated using density(x) and density(y). x=sample(20,1000, replace = TRUE); y=sample(50:100,1000, replace = TRUE); # Plot density of x and y. Since the x-ranges of x and y are different (x values between 0-20 while y between 50 and 100), we can’t see distribution of y in this plot. plot(density(x)); lines(density(y)); # Change xlim between 0 and 100 so that both x and y densities are within plot-margin. plot(density(x), xlim = c(0,120), xlab=&quot;Value&quot;, ylab=&quot;Probability density&quot;, main=&quot;Probability density of x and y&quot;); lines(density(y),col=&quot;red&quot;); legend(100, 0.05, c(&quot;x&quot;,&quot;y&quot;), col=c(&quot;black&quot;,&quot;red&quot;), lwd=5) 5.1.24 Box plots Create a matrix of 1000*4 dimensions. Let’s assume that these are the gene expression values of 1000 genes measured across two days among control and treatment sample. Columns represents: Control-Day1, Control-Day2, Treatment-Day1 and Treatment-Day2. x1=sample(1:100,1000, replace = TRUE); x2=sample(100:200,1000, replace = TRUE); x3=sample(200:300,1000, replace = TRUE); x4=sample(300:400,1000, replace = TRUE); m=cbind(x1,x2,x3,x4) head(m); ## x1 x2 x3 x4 ## [1,] 30 139 206 370 ## [2,] 27 134 269 345 ## [3,] 93 162 227 379 ## [4,] 40 170 278 380 ## [5,] 15 194 258 322 ## [6,] 26 142 206 316 boxplot(m); # col parameters sets colors to each box. boxplot(m, col=c(&quot;red&quot;,&quot;blue&quot;,&quot;red&quot;,&quot;blue&quot;),xlab=&quot;Day&quot;,ylab=&quot;Expression&quot;) # names parameter sets names below each box. boxplot(m, col=c(&quot;red&quot;,&quot;blue&quot;,&quot;red&quot;,&quot;blue&quot;),xlab=&quot;Day&quot;,ylab=&quot;Expression&quot;, names= c(&quot;Day1&quot;,&quot;Day2&quot;,&quot;Day1&quot;,&quot;Day2&quot;)); legend(0.5, 400, c(&quot;Control&quot;,&quot;Treatment&quot;), col=c(&quot;red&quot;,&quot;blue&quot;), pch =15) 5.1.25 Pie chart x=c(70, 15, 5); pie(x); # 1st argument is the proportion values # col assigns colors to each category pie(x, col=c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;)); # labels will assign labels to each category pie(x, col=c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;), labels = x); legend(0.97, 0.92, c(&quot;High&quot;,&quot;Mid&quot;,&quot;Low&quot;), pch=15,col=c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;) ) 5.1.26 Venn diagram library(gplots); ## ## Attaching package: &#39;gplots&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## lowess x1=1:5 x2=4:6 x3=c(4, 8:10); x4=c(7,5,10); x5=c(7, 10); v1=venn(list(x1, x2, x3)); v2=venn(list(x1, x2, x3, x4)); v3=venn(list(x1, x2, x3, x4, x5)); 5.1.27 Heatmap m1 = read.table(&quot;./data/Day2/GenExp_heatmap.txt&quot;,sep=&quot;\\t&quot;, header=TRUE); rownames(m1)=m1$Gene; m1$Gene=NULL; m1=as.matrix(m1); # Convert data.frame to matrix head(m1); ## D1 D2 D3 D4 D5 ## Gene1 0.59 1.01 0.36 -1.25 -1.11 ## Gene2 -0.76 -1.42 -0.09 -0.93 -0.45 ## Gene3 -0.37 0.76 0.06 -1.31 0.94 ## Gene4 -0.19 1.59 -0.15 1.01 0.74 ## Gene5 1.45 0.26 0.46 -0.30 -0.59 ## Gene6 -1.24 -0.14 1.15 2.16 -2.72 library(gplots); heatmap.2(m1); # Disable trace. trace=”none” will prevent to draw tract of color key. heatmap.2(m1, trace = &quot;none&quot;); # Disable column clustering. Colv=FALSE will prevent the ordering of column as per hierarchical clustering. So the dendrogram won’t be displayed. Rowv=FALSE will prevent clustering of rows. heatmap.2(m1, trace = &quot;none&quot;, Colv = FALSE); ## Warning in heatmap.2(m1, trace = &quot;none&quot;, Colv = FALSE): Discrepancy: Colv ## is FALSE, while dendrogram is `both&#39;. Omitting column dendogram. # Disable row clustering heatmap.2(m1, trace = &quot;none&quot;, Rowv = FALSE); ## Warning in heatmap.2(m1, trace = &quot;none&quot;, Rowv = FALSE): Discrepancy: Rowv ## is FALSE, while dendrogram is `both&#39;. Omitting row dendogram. # Data scaling heatmap.2(m1, trace = &quot;none&quot;, scale = &quot;row&quot;); # Add cellnote. notecex: magnification for cell note. cellnote=m will allow us to write the values of matrix m in each cell. notecol=”black” will set the color of notes in each cell as black. heatmap.2(m1, trace = &quot;none&quot;, scale = &quot;row&quot;, cellnote = m1, notecol = &quot;black&quot;, notecex=0.8); # col parameter heatmap.2(m1, trace = &quot;none&quot;, scale = &quot;row&quot;, col=redgreen(75)); # Custom colors library(RColorBrewer) my_palette &lt;- colorRampPalette(c(&quot;blue&quot;,&quot;white&quot;,&quot;red&quot;))(n = 149) heatmap.2(m1, trace = &quot;none&quot;, scale = &quot;row&quot;, col=my_palette); The argument (n = 149) lets us define how many individuals colors we want to have in our palette. Obviously, the higher the number of individual colors, the smoother the transition will be; the number 149 should be sufficiently large enough for a smooth transition. By default, RColorBrewer will divide the colors evenly so that every color in our palette will be an interval of individual colors of similar size. However, sometimes we want to have a little skewed color range depending on the data we are analyzing. Our example dataset (m1) ranges from –3 to 3, and we are particularly interested in samples that have a (relatively) high expression: R values in the range between 2 to 3 and -2 to -3. In this case, we can define our color breaks “unevenly” by using the following code: # Color breaks col_breaks = c(seq(-3,-2,length=50), # for red seq(-1.9,2,length=50), # for yellow seq(2.1,3,length=50)) # for green heatmap.2(m1, trace = &quot;none&quot;, col=my_palette, breaks = col_breaks); ## Warning in image.default(z = matrix(z, ncol = 1), col = col, breaks = ## tmpbreaks, : unsorted &#39;breaks&#39; will be sorted before use # Adjust Row and column label size using cexRow and cexCol parameter heatmap.2(m1, trace = &quot;none&quot;, col=my_palette, breaks = col_breaks, cexRow=0.5,cexCol=0.75); ## Warning in image.default(z = matrix(z, ncol = 1), col = col, breaks = ## tmpbreaks, : unsorted &#39;breaks&#39; will be sorted before use # Categorize genes (Rows) into category, red and blue. heatmap.2(m1, trace = &quot;none&quot;, col=my_palette, breaks = col_breaks, RowSideColors = c(rep(&quot;red&quot;,10),rep(&quot;blue&quot;,10))); ## Warning in image.default(z = matrix(z, ncol = 1), col = col, breaks = ## tmpbreaks, : unsorted &#39;breaks&#39; will be sorted before use legend(&quot;topright&quot;, # location of the legend on the heatmap plot legend = c(&quot;category1&quot;, &quot;category2&quot;), # category labels col = c(&quot;red&quot;, &quot;blue&quot;), # color key lty= 1, # line style lwd = 2 # line width ) # Explore # labRow=NA: Disable row label # key = TRUE: Disable color key panel # density.info=&quot;none&quot;: disable density info in color key panel 5.1.28 Scatter plot Matrices pairs() function is useful to draw a matrix of scatterplots. This is useful to get a global view of data distribution. x1=sample(1:100, 30, replace = TRUE); x2=sample(1:100, 30, replace = TRUE); x3=sample(1:100, 30, replace = TRUE); x4=sample(1:100, 30, replace = TRUE); # m is a dataframe of dimension 30*4. m=data.frame(x1,x2,x3,x4); head(m); ## x1 x2 x3 x4 ## 1 39 35 79 26 ## 2 13 3 80 59 ## 3 12 81 98 76 ## 4 96 67 68 2 ## 5 16 83 85 88 ## 6 84 55 80 21 pairs(m); pairs(m, pch =16, col=rep(c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;), each=10)); 5.1.29 Ballon plot library(gplots) pathway = sample(c(&quot;P1&quot;,&quot;P2&quot;,&quot;P3&quot;), 50, replace = TRUE) genes = sample(c(&quot;Gene1&quot;,&quot;Gene2&quot;,&quot;Gene3&quot;,&quot;Gene4&quot;,&quot;Gene5&quot;), 50, replace = TRUE); tab &lt;- table(pathway, genes); print(tab); ## genes ## pathway Gene1 Gene2 Gene3 Gene4 Gene5 ## P1 2 5 8 4 5 ## P2 1 5 1 1 5 ## P3 3 3 3 1 3 balloonplot(tab, main=&quot;Gene distributions in pathway&quot;); 5.1.30 Multi panel plots By setting the mfrow parameter in par() to number of rows and columns, multi-panel plots can be generated. # we set the mfrow parameter to c(2,2) i.e. 2 rows and 2 columns and pass mfrow in par() function. par() after modifying the graphics parameter, returns original state of graphics device which we store in oldpar. oldpar= par(mfrow=c(2,2)); x1=sample(1:100, 30, replace = TRUE); x2=sample(1:100, 30, replace = TRUE); x3=sample(1:100, 30, replace = TRUE); x4=sample(1:100, 30, replace = TRUE); # m is a dataframe of dimension 30*4. m=data.frame(x1,x2,x3,x4); hist(m[,1]); hist(m[,2]); hist(m[,3]); hist(m[,4]); # Reset to old graphics setting par(oldpar); 5.1.31 PCA (Prinicipal Component Analysis) head(iris); ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa piris=princomp(iris[,1:4], cor=TRUE, scores=TRUE); # Summary of individual principal components summary(piris); ## Importance of components: ## Comp.1 Comp.2 Comp.3 Comp.4 ## Standard deviation 1.7083611 0.9560494 0.38308860 0.143926497 ## Proportion of Variance 0.7296245 0.2285076 0.03668922 0.005178709 ## Cumulative Proportion 0.7296245 0.9581321 0.99482129 1.000000000 # Shows a screeplot plot(piris); # biplot biplot(piris); Plot PCA objects using ggfortify pacakge # Load ggfortify library library(ggfortify); ## Loading required package: ggplot2 Plot PC1 vs PC2 autoplot(piris, x=1, y=2); Plot PC2 and PC3 autoplot(piris, x=2, y=3); Draw Frame (draws convex for each cluster) autoplot(piris, x=1, y=2, frame=TRUE); Pass original data for additional features autoplot(piris, x=1, y=2, data=iris, colour=&#39;Species&#39;); Draw PCA loadings autoplot(piris, x=1, y=2, data=iris, colour=&#39;Species&#39;, loadings = TRUE, loadings.label = TRUE, loadings.colour = &#39;blue&#39;, loadings.label.size = 3); Show frame autoplot(piris, x=1, y=2, data=iris, frame=TRUE, colour=&#39;Species&#39;); autoplot(piris, x=1, y=2, data=iris, frame=TRUE, colour=&#39;Species&#39;, frame.type=&#39;t&#39;); Show Labels autoplot(piris, x=1, y=2, data=iris, colour=&#39;Species&#39;, label=TRUE, label.size=3, shape=FALSE); Explore ggfortify package for further details. https://cran.r-project.org/web/packages/ggfortify/vignettes/plot_pca.html 5.1.32 Classical (Metric) Multidimensional Scaling Multidimensional scaling takes a set of dissimilarities and returns a set of points such that the distances between the points are approximately equal to the dissimilarities. m1 = read.table(&quot;./data/Day2/GenExp_heatmap.txt&quot;,sep=&quot;\\t&quot;, header=TRUE); rownames(m1)=m1$Gene; m1$Gene=NULL; m1=as.matrix(m1); # Convert data.frame to matrix head(m1); ## D1 D2 D3 D4 D5 ## Gene1 0.59 1.01 0.36 -1.25 -1.11 ## Gene2 -0.76 -1.42 -0.09 -0.93 -0.45 ## Gene3 -0.37 0.76 0.06 -1.31 0.94 ## Gene4 -0.19 1.59 -0.15 1.01 0.74 ## Gene5 1.45 0.26 0.46 -0.30 -0.59 ## Gene6 -1.24 -0.14 1.15 2.16 -2.72 # Gene clustering distmat = dist(m1, upper = TRUE, diag = TRUE); cmd = cmdscale(distmat, k=2); plot(cmd[,1], cmd[,2], type = &quot;n&quot;, xlab = &quot;Dim 1&quot;, ylab = &quot;Dim 2&quot;, asp = 1, main = &quot;cmdscale&quot;) text(cmd[,1], cmd[,2], rownames(cmd), cex = 0.6); # Sample clustering distmat = dist(t(m1), upper = TRUE, diag = TRUE); cmd = cmdscale(distmat, k=2); plot(cmd[,1], cmd[,2], type = &quot;n&quot;, xlab = &quot;Dim 1&quot;, ylab = &quot;Dim 2&quot;, asp = 1, main = &quot;cmdscale&quot;) text(cmd[,1], cmd[,2], rownames(cmd), cex = 0.6); 5.1.33 Plotting K-means # Using autoplot function of gfortify package autoplot(kmeans(iris[,1:4], 3), data = iris); # 4 cluster autoplot(kmeans(iris[,1:4], 4), data = iris); # Add label autoplot(kmeans(iris[,1:4], 4), data = iris, label = TRUE, label.size=3, shape=FALSE); 5.1.34 Dendrogram # Pass distance matrix to hclust function hc = hclust(dist(iris[,1:4])); plot(hc, cex=0.5); # Cut the tree at h=2 # Convert hclust object to dendrogram object plot(cut(as.dendrogram(hc), h =2)$upper, main = &quot;Upper tree of cut at h=2&quot;) Explore https://rpubs.com/gaston/dendrograms for advanced plots. 5.1.35 Network graphs library(igraph); ## ## Attaching package: &#39;igraph&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## as_data_frame, groups, union ## The following objects are masked from &#39;package:stats&#39;: ## ## decompose, spectrum ## The following object is masked from &#39;package:base&#39;: ## ## union data=matrix(sample(0:1, 100, replace=TRUE), nc=10); rownames(data) &lt;- paste(&quot;G&quot;,1:10,sep=&quot;&quot;); colnames(data) &lt;- paste(&quot;G&quot;,1:10,sep=&quot;&quot;); print(data); ## G1 G2 G3 G4 G5 G6 G7 G8 G9 G10 ## G1 0 1 0 0 0 0 1 1 0 1 ## G2 1 0 1 0 1 1 0 1 0 1 ## G3 1 1 0 1 1 1 1 0 0 1 ## G4 0 0 0 1 1 1 1 0 0 0 ## G5 1 0 1 0 1 0 0 0 1 1 ## G6 0 1 1 0 0 1 0 1 0 0 ## G7 0 0 0 1 1 0 1 0 0 1 ## G8 1 0 1 0 1 0 1 1 1 1 ## G9 1 0 1 1 1 0 0 0 0 0 ## G10 1 1 0 1 0 1 0 1 1 1 network=graph_from_adjacency_matrix(data , mode=&#39;undirected&#39;, diag=F ); print(network); ## IGRAPH 7aa6332 UN-- 10 35 -- ## + attr: name (v/c) ## + edges from 7aa6332 (vertex names): ## [1] G1--G2 G1--G3 G1--G5 G1--G7 G1--G8 G1--G9 G1--G10 G2--G3 ## [9] G2--G5 G2--G6 G2--G8 G2--G10 G3--G4 G3--G5 G3--G6 G3--G7 ## [17] G3--G8 G3--G9 G3--G10 G4--G5 G4--G6 G4--G7 G4--G9 G4--G10 ## [25] G5--G7 G5--G8 G5--G9 G5--G10 G6--G8 G6--G10 G7--G8 G7--G10 ## [33] G8--G9 G8--G10 G9--G10 plot(network); # Customize vertex shape plot(network, vertex.shape=c(&quot;circle&quot;,&quot;square&quot;)); # Customize vertex color to G1 and G2 plot(network, vertex.shape=c(&quot;circle&quot;,&quot;square&quot;), vertex.color=c(&quot;lightpink&quot;,&quot;lightblue&quot;), vertex.size=20); Explore http://www.r-graph-gallery.com/portfolio/network/ for advanced network graphs. 5.2 Plot using ggplot2 5.2.1 Scatter plot library(ggplot2); library(dplyr); head(diamonds); ## # A tibble: 6 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.290 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 # This will just loads the dataset. No plot will be printed until you add the geom layers. ggplot(diamonds); # Here we have added x and y axis. Still no plot of data. ggplot(diamonds, aes(x=carat, y=price)); 5.2.2 Add geom_point() layer # Add geom_point layer. Each layer can be added by + ggplot(diamonds, aes(x=carat, y=price))+ geom_point() 5.2.3 Add geom_smooth() layer, linear modeling # ggplot(diamonds, aes(x=carat, y=price))+ geom_point() + geom_smooth(); ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; # se=FALSE removes confidence bands ggplot(diamonds, aes(x=carat, y=price))+ geom_point() + geom_smooth(se=FALSE); ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 5.2.4 Explore aesthetic parameter “col” # Color the points w.r.t. cut column ggplot(diamonds, aes(x=carat, y=price, color=cut))+ geom_point() + geom_smooth(); ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 5.2.5 Assign aes() to individual layer ggplot(diamonds, aes(x=carat, y=price))+ geom_point(aes(color=cut)) + geom_smooth(); # We have removed aes to smooth layer ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 5.2.6 Explore aesthetic parameter “shape” ggplot(diamonds, aes(x=carat, y=price))+ geom_point(aes(color=cut, shape=clarity)) + geom_smooth(); # We have removed aes to smooth layer ## Warning: Using shapes for an ordinal variable is not advised ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; ## Warning: The shape palette can deal with a maximum of 6 discrete values ## because more than 6 becomes difficult to discriminate; you have 8. ## Consider specifying shapes manually if you must have them. ## Warning: Removed 5445 rows containing missing values (geom_point). 5.2.7 Add axis lables and plot title using labs() ggplot(diamonds, aes(x=carat, y=price))+ geom_point(aes(color=cut, shape=clarity)) + geom_smooth() + labs(title=&quot;Scatterplot&quot;, x=&quot;Carat&quot;, y=&quot;Price&quot;); ## Warning: Using shapes for an ordinal variable is not advised ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; ## Warning: The shape palette can deal with a maximum of 6 discrete values ## because more than 6 becomes difficult to discriminate; you have 8. ## Consider specifying shapes manually if you must have them. ## Warning: Removed 5445 rows containing missing values (geom_point). 5.2.8 Change color pelette ggplot(diamonds, aes(x=carat, y=price))+ geom_point(aes(color=cut, shape=clarity)) + geom_smooth() + labs(title=&quot;Scatterplot&quot;, x=&quot;Carat&quot;, y=&quot;Price&quot;)+scale_colour_brewer(palette = &quot;Set1&quot;) ; ## Warning: Using shapes for an ordinal variable is not advised ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; ## Warning: The shape palette can deal with a maximum of 6 discrete values ## because more than 6 becomes difficult to discriminate; you have 8. ## Consider specifying shapes manually if you must have them. ## Warning: Removed 5445 rows containing missing values (geom_point). 5.2.9 Save the ggplot object and then print. g=ggplot(diamonds, aes(x=carat, y=price))+ geom_point(aes(color=cut, shape=clarity)) + geom_smooth() + labs(title=&quot;Scatterplot&quot;, x=&quot;Carat&quot;, y=&quot;Price&quot;); print(g); ## Warning: Using shapes for an ordinal variable is not advised ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; ## Warning: The shape palette can deal with a maximum of 6 discrete values ## because more than 6 becomes difficult to discriminate; you have 8. ## Consider specifying shapes manually if you must have them. ## Warning: Removed 5445 rows containing missing values (geom_point). 5.2.10 The Theme We can use theme() function to adjust size of labels. Parameters plot.title, axis.text.x, axis.text.y, axis.title.x, axis.title.y can be set using element_text() function g &lt;- ggplot(diamonds, aes(x=carat, y=price, color=cut)) + geom_point() + labs(title=&quot;Scatterplot&quot;, x=&quot;Carat&quot;, y=&quot;Price&quot;); gg1 &lt;- g + theme(plot.title=element_text(size=30, face=&quot;bold&quot;), axis.text.x=element_text(size=15), axis.text.y=element_text(size=15), axis.title.x=element_text(size=25), axis.title.y=element_text(size=25)); print(gg1); 5.2.11 Adjusting the legend title You can change legned title. Based on the type of legend ggplot2 provides different function. For a legend representing color and if the color attribute is derived from discrete values, use scale_color_discrete() function. If legend correspond to shape and discrete use scale_shape_discrete(). Other functions are scale_shape_continuous(name=“legend title”). For fill attribute: scale_fill_continuous(name=“legend title”) gg2 &lt;- gg1 + scale_color_discrete(name=&quot;Cut of diamonds&quot;) + scale_shape_discrete(name=&quot;clarity attribute&quot;); print(gg2); 5.2.12 Facet_wrap # Split based on &quot;cut&quot; column. plot will be distributed in n*3 layouts gg &lt;- ggplot(diamonds, aes(x=carat, y=price, color=cut)) + geom_point() + labs(title=&quot;Scatterplot&quot;, x=&quot;Carat&quot;, y=&quot;Price&quot;) gg3 = gg + facet_wrap( ~ cut, ncol=3); print(gg3); 5.2.13 Bar charts ggplot(diamonds,aes(x=cut))+geom_bar(); ggplot(diamonds,aes(x=cut))+geom_bar(aes(fill=clarity)); ggplot(diamonds,aes(x=cut))+geom_bar(aes(fill=clarity)) + coord_flip(); # Suppose for every cut class, plot mean depth. x-axis: cut class while y-axis: mean(depth) tempdf=group_by(diamonds, cut) %&gt;% summarise(meandepth=mean(depth)) ggplot(tempdf, aes(x=cut, y=meandepth))+geom_col(); # geom bar for continious data ggplot(diamonds, aes(x=carat))+geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 5.2.14 Density plot ggplot(diamonds, aes(carat))+ geom_density(); ggplot(diamonds, aes(carat, colour=cut))+ geom_density(); ggplot(diamonds, aes(carat, colour=cut, fill= cut))+ geom_density(); ggplot(diamonds, aes(carat, colour=cut, fill= cut))+ geom_density(alpha=0.1); # Stacked density plots: ggplot(diamonds, aes(carat, colour=cut, fill= cut))+ geom_density(alpha=0.1, position=&quot;stack&quot;); 5.2.15 Box plot ggplot(diamonds, aes(x=cut, y=table)) + geom_boxplot(); ggplot(diamonds, aes(x=cut, y=table)) + geom_boxplot(notch = TRUE); ggplot(diamonds, aes(x=cut, y=table, colour=cut)) + geom_boxplot(notch = TRUE); ggplot(diamonds, aes(x=cut, y=table)) + geom_boxplot(fill = &quot;white&quot;, colour = &quot;#3366FF&quot;); ggplot(diamonds, aes(x=cut, y=table)) + geom_boxplot(outlier.colour = &quot;red&quot;, outlier.shape = 1); 5.2.16 References http://r-statistics.co/ggplot2-Tutorial-With-R.html http://ggplot2.tidyverse.org/reference/ "],
["bioconductor.html", "Chapter 6 Bioconductor 6.1 Introduction 6.2 Explore Maftools 6.3 Explore cummeRbund for Diffrential Gene Expression Analysis 6.4 References", " Chapter 6 Bioconductor 6.1 Introduction The purpose of this section is to introduce you about the steps to install any R package from Bioconductor repository. We will demonstrate the installation and usage of Maftools package. Bioconductor provides tools for the analysis and comprehension of high-throughput genomic data. Bioconductor uses the R statistical programming language, and is open source and open development. It has two releases each year, 1383 software packages, and an active user community. Website: https://www.bioconductor.org/ 6.1.1 Install How to install Bioconductor Open R and type following commands. You must be connected to internet. source(“https://bioconductor.org/biocLite.R”) biocLite() How to install bioconductor packages biocLite(c(“GenomicFeatures”, “AnnotationDbi”)) Further details https://www.bioconductor.org/install/ 6.1.2 Explore Bioconductor Tutorials https://www.bioconductor.org/help/workflows/ 6.1.3 Explore course and conferences materials https://www.bioconductor.org/help/course-materials/ 6.1.4 Explore and Search for package using BiocViews BiocViews allows you to browse through packages avaiable in Bioconductor. Packages are organized under different categories which will allow you to search easily. https://www.bioconductor.org/packages/release/BiocViews.html#___Software 6.1.5 Bioconductor Forum https://support.bioconductor.org/ Here you can ask questions. 6.2 Explore Maftools For demo purpose we will explore maftools [1]. Suppose you are doing a large scale sequencing project where you have done whole genome sequencing for ~100 patients and you have carried out variant detection pipeline to obtain variants (SNPs, Indels) in each sample. The variant information from each patient is aggregated in MAF file (Mutation Annotation Format. Now you want to analyze this MAF file. You searched in bioconductor for any pacakge that can help you to analyze MAF file and you came across maftools. 6.2.1 About MAFtools With advances in Cancer Genomics, Mutation Annotation Format (MAF) is being widley accepted and used to store somatic variants detected. The Cancer Genome Atlas Project has seqenced over 30 different cancers with sample size of each cancer type being over 200. Resulting data consisting of somatic variants are stored in the form of Mutation Annotation Format. This package attempts to summarize, analyze, annotate and visualize MAF files in an efficient manner from either TCGA sources or any in-house studies as long as the data is in MAF format [2]. 6.2.2 About MAF file MAF files contain many fields ranging from chromosome names to cosmic annotations. However most of the analysis in maftools uses following fields. Mandatoty fields: Hugo_Symbol, Chromosome, Start_Position, End_Position, Variant_Classification, Variant_Type and Tumor_Sample_Barcode. Complete specififcation of MAF files can be found on NCI TCGA page. 6.2.3 Install maftools. source(“https://bioconductor.org/biocLite.R”) biocLite(“maftools”) 6.2.4 Load maftools library library(maftools); 6.2.5 Read example maf file # laml file path laml.maf = system.file(&#39;extdata&#39;, &#39;tcga_laml.maf.gz&#39;, package = &#39;maftools&#39;); # read laml maf file laml = read.maf(maf = laml.maf, useAll = FALSE); ## reading maf.. ## Taking input= as a system command (&#39;zcat &lt; /home/priyabrata/R/x86_64-pc-linux-gnu-library/3.4/maftools/extdata/tcga_laml.maf.gz&#39;) and a variable has been used in the expression passed to `input=`. Please use fread(cmd=...). There is a security concern if you are creating an app, and the app could have a malicious user, and the app is not running in a secure envionment; e.g. the app is running as root. Please read item 5 in the NEWS file for v1.11.6 for more information and for the option to suppress this message. ## --Using only `Somatic` variants from Mutation_Status. Set useAll = TRUE to include everything. ## ---Oops! Mutation_Status not found. Assuming all variants are Somatic and validated. ## silent variants: 475 ## ID N ## 1: Samples 157 ## 2: 5&#39;Flank 3 ## 3: IGR 5 ## 4: Intron 8 ## 5: RNA 10 ## 6: Silent 449 ## Summarizing.. ## ID summary Mean Median ## 1: NCBI_Build 37 NA NA ## 2: Center genome.wustl.edu NA NA ## 3: Samples 192 NA NA ## 4: nGenes 1241 NA NA ## 5: Frame_Shift_Del 52 0.271 0 ## 6: Frame_Shift_Ins 91 0.474 0 ## 7: In_Frame_Del 10 0.052 0 ## 8: In_Frame_Ins 42 0.219 0 ## 9: Missense_Mutation 1342 6.990 7 ## 10: Nonsense_Mutation 103 0.536 0 ## 11: Splice_Site 92 0.479 0 ## 12: total 1732 9.021 9 ## Gene Summary.. ## Hugo_Symbol Frame_Shift_Del Frame_Shift_Ins In_Frame_Del ## 1: FLT3 0 0 1 ## 2: DNMT3A 4 0 0 ## 3: NPM1 0 33 0 ## 4: IDH2 0 0 0 ## 5: IDH1 0 0 0 ## --- ## 1237: ZNF689 0 0 0 ## 1238: ZNF75D 0 0 0 ## 1239: ZNF827 1 0 0 ## 1240: ZNF99 0 0 0 ## 1241: ZPBP 0 0 0 ## In_Frame_Ins Missense_Mutation Nonsense_Mutation Splice_Site total ## 1: 33 15 0 3 52 ## 2: 0 39 5 6 54 ## 3: 0 1 0 0 34 ## 4: 0 20 0 0 20 ## 5: 0 18 0 0 18 ## --- ## 1237: 0 1 0 0 1 ## 1238: 0 1 0 0 1 ## 1239: 0 0 0 0 1 ## 1240: 0 1 0 0 1 ## 1241: 0 1 0 0 1 ## MutatedSamples AlteredSamples ## 1: 52 52 ## 2: 48 48 ## 3: 33 33 ## 4: 20 20 ## 5: 18 18 ## --- ## 1237: 1 1 ## 1238: 1 1 ## 1239: 1 1 ## 1240: 1 1 ## 1241: 1 1 ## Checking clinical data.. ## NOTE: Missing clinical data! It is strongly recommended to provide clinical data associated with samples if available. ## Done ! 6.2.6 Print maf object Summarized MAF file is stored as an MAF object. MAF object contains main maf file, summarized data and an oncomatrix which is useful to plot oncoplots (aka waterfall plots). laml; ## An object of class MAF ## ID summary Mean Median ## 1: NCBI_Build 37 NA NA ## 2: Center genome.wustl.edu NA NA ## 3: Samples 192 NA NA ## 4: nGenes 1241 NA NA ## 5: Frame_Shift_Del 52 0.271 0 ## 6: Frame_Shift_Ins 91 0.474 0 ## 7: In_Frame_Del 10 0.052 0 ## 8: In_Frame_Ins 42 0.219 0 ## 9: Missense_Mutation 1342 6.990 7 ## 10: Nonsense_Mutation 103 0.536 0 ## 11: Splice_Site 92 0.479 0 ## 12: total 1732 9.021 9 6.2.7 Structure of maf object str(laml); ## Formal class &#39;MAF&#39; [package &quot;maftools&quot;] with 8 slots ## ..@ data :Classes &#39;data.table&#39; and &#39;data.frame&#39;: 1732 obs. of 17 variables: ## .. ..$ Hugo_Symbol : chr [1:1732] &quot;ABCA10&quot; &quot;ABCA4&quot; &quot;ABCB11&quot; &quot;ABCC3&quot; ... ## .. ..$ Entrez_Gene_Id : int [1:1732] 10349 24 8647 8714 23 64137 64241 25 55289 92370 ... ## .. ..$ Center : chr [1:1732] &quot;genome.wustl.edu&quot; &quot;genome.wustl.edu&quot; &quot;genome.wustl.edu&quot; &quot;genome.wustl.edu&quot; ... ## .. ..$ NCBI_Build : int [1:1732] 37 37 37 37 37 37 37 37 37 37 ... ## .. ..$ Chromosome : int [1:1732] 17 1 2 17 6 11 2 9 2 3 ... ## .. ..$ Start_Position : int [1:1732] 67170917 94490594 169780250 48760974 30554429 119031351 44079555 133760430 111542370 141011154 ... ## .. ..$ End_Position : int [1:1732] 67170917 94490594 169780250 48760974 30554429 119031351 44079555 133760430 111542370 141011154 ... ## .. ..$ Strand : chr [1:1732] &quot;+&quot; &quot;+&quot; &quot;+&quot; &quot;+&quot; ... ## .. ..$ Variant_Classification: Factor w/ 7 levels &quot;Frame_Shift_Del&quot;,..: 7 5 5 5 5 5 5 5 5 5 ... ## .. ..$ Variant_Type : Factor w/ 3 levels &quot;DEL&quot;,&quot;INS&quot;,&quot;SNP&quot;: 3 3 3 3 3 3 3 3 3 3 ... ## .. ..$ Reference_Allele : chr [1:1732] &quot;T&quot; &quot;C&quot; &quot;G&quot; &quot;C&quot; ... ## .. ..$ Tumor_Seq_Allele1 : chr [1:1732] &quot;T&quot; &quot;C&quot; &quot;G&quot; &quot;C&quot; ... ## .. ..$ Tumor_Seq_Allele2 : chr [1:1732] &quot;C&quot; &quot;T&quot; &quot;A&quot; &quot;T&quot; ... ## .. ..$ Tumor_Sample_Barcode : Factor w/ 192 levels &quot;TCGA-AB-2802&quot;,..: 171 63 190 81 111 125 96 182 140 114 ... ## .. ..$ Protein_Change : chr [1:1732] &quot;p.K960R&quot; &quot;p.R1517H&quot; &quot;p.A1283V&quot; &quot;p.P1271S&quot; ... ## .. ..$ i_TumorVAF_WU : num [1:1732] 45.7 38.1 47 56.4 41 ... ## .. ..$ i_transcript_name : chr [1:1732] &quot;NM_080282.3&quot; &quot;NM_000350.2&quot; &quot;NM_003742.2&quot; &quot;NM_003786.1&quot; ... ## .. ..- attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; ## ..@ variants.per.sample :Classes &#39;data.table&#39; and &#39;data.frame&#39;: 192 obs. of 2 variables: ## .. ..$ Tumor_Sample_Barcode: Factor w/ 192 levels &quot;TCGA-AB-2802&quot;,..: 190 6 146 185 114 155 45 103 118 71 ... ## .. ..$ Variants : int [1:192] 34 25 23 21 20 20 20 19 18 18 ... ## .. ..- attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; ## ..@ variant.type.summary :Classes &#39;data.table&#39; and &#39;data.frame&#39;: 192 obs. of 5 variables: ## .. ..$ Tumor_Sample_Barcode: Factor w/ 192 levels &quot;TCGA-AB-2802&quot;,..: 190 6 146 185 45 114 155 103 71 118 ... ## .. ..$ DEL : int [1:192] 0 2 0 0 0 1 0 0 0 0 ... ## .. ..$ INS : int [1:192] 6 0 0 0 1 1 1 1 1 2 ... ## .. ..$ SNP : int [1:192] 28 23 23 21 19 18 19 18 17 16 ... ## .. ..$ total : num [1:192] 34 25 23 21 20 20 20 19 18 18 ... ## .. ..- attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; ## ..@ variant.classification.summary:Classes &#39;data.table&#39; and &#39;data.frame&#39;: 192 obs. of 9 variables: ## .. ..$ Tumor_Sample_Barcode: Factor w/ 192 levels &quot;TCGA-AB-2802&quot;,..: 190 6 146 185 45 114 155 103 71 118 ... ## .. ..$ Frame_Shift_Del : int [1:192] 0 1 0 0 0 1 0 0 0 0 ... ## .. ..$ Frame_Shift_Ins : int [1:192] 5 0 0 0 1 1 1 1 0 2 ... ## .. ..$ In_Frame_Del : int [1:192] 0 1 0 0 0 0 0 0 0 0 ... ## .. ..$ In_Frame_Ins : int [1:192] 1 0 0 0 0 0 0 0 1 0 ... ## .. ..$ Missense_Mutation : int [1:192] 25 16 22 15 16 15 16 15 17 11 ... ## .. ..$ Nonsense_Mutation : int [1:192] 2 3 0 1 1 3 2 1 0 2 ... ## .. ..$ Splice_Site : int [1:192] 1 4 1 5 2 0 1 2 0 3 ... ## .. ..$ total : num [1:192] 34 25 23 21 20 20 20 19 18 18 ... ## .. ..- attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; ## ..@ gene.summary :Classes &#39;data.table&#39; and &#39;data.frame&#39;: 1241 obs. of 11 variables: ## .. ..$ Hugo_Symbol : chr [1:1241] &quot;FLT3&quot; &quot;DNMT3A&quot; &quot;NPM1&quot; &quot;IDH2&quot; ... ## .. ..$ Frame_Shift_Del : int [1:1241] 0 4 0 0 0 10 1 2 0 6 ... ## .. ..$ Frame_Shift_Ins : int [1:1241] 0 0 33 0 0 4 3 2 0 2 ... ## .. ..$ In_Frame_Del : int [1:1241] 1 0 0 0 0 0 1 0 0 2 ... ## .. ..$ In_Frame_Ins : int [1:1241] 33 0 0 0 0 0 0 0 0 6 ... ## .. ..$ Missense_Mutation: int [1:1241] 15 39 1 20 18 4 8 11 15 2 ... ## .. ..$ Nonsense_Mutation: int [1:1241] 0 5 0 0 0 8 5 1 0 1 ... ## .. ..$ Splice_Site : int [1:1241] 3 6 0 0 0 1 1 3 0 0 ... ## .. ..$ total : num [1:1241] 52 54 34 20 18 27 19 19 15 19 ... ## .. ..$ MutatedSamples : int [1:1241] 52 48 33 20 18 17 16 15 15 13 ... ## .. ..$ AlteredSamples : int [1:1241] 52 48 33 20 18 17 16 15 15 13 ... ## .. ..- attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; ## ..@ summary :Classes &#39;data.table&#39; and &#39;data.frame&#39;: 12 obs. of 4 variables: ## .. ..$ ID : chr [1:12] &quot;NCBI_Build&quot; &quot;Center&quot; &quot;Samples&quot; &quot;nGenes&quot; ... ## .. ..$ summary: chr [1:12] &quot;37&quot; &quot;genome.wustl.edu&quot; &quot;192&quot; &quot;1241&quot; ... ## .. ..$ Mean : num [1:12] NA NA NA NA 0.271 0.474 0.052 0.219 6.99 0.536 ... ## .. ..$ Median : num [1:12] NA NA NA NA 0 0 0 0 7 0 ... ## .. ..- attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; ## ..@ maf.silent :Classes &#39;data.table&#39; and &#39;data.frame&#39;: 475 obs. of 17 variables: ## .. ..$ Hugo_Symbol : chr [1:475] &quot;ABCC11&quot; &quot;ACAN&quot; &quot;ACAT1&quot; &quot;ACCN2&quot; ... ## .. ..$ Entrez_Gene_Id : int [1:475] 85320 176 38 41 59 284382 8728 56999 111 83440 ... ## .. ..$ Center : chr [1:475] &quot;genome.wustl.edu&quot; &quot;genome.wustl.edu&quot; &quot;genome.wustl.edu&quot; &quot;genome.wustl.edu&quot; ... ## .. ..$ NCBI_Build : int [1:475] 37 37 37 37 37 37 37 37 37 37 ... ## .. ..$ Chromosome : int [1:475] 16 15 11 12 10 19 5 3 3 15 ... ## .. ..$ Start_Position : int [1:475] 48244997 89401084 108009744 50452780 90695109 8808551 156920098 64532572 123071312 73045153 ... ## .. ..$ End_Position : int [1:475] 48244997 89401084 108009744 50452780 90695109 8808551 156920098 64532572 123071312 73045153 ... ## .. ..$ Strand : chr [1:475] &quot;+&quot; &quot;+&quot; &quot;+&quot; &quot;+&quot; ... ## .. ..$ Variant_Classification: chr [1:475] &quot;Silent&quot; &quot;Silent&quot; &quot;Silent&quot; &quot;Silent&quot; ... ## .. ..$ Variant_Type : chr [1:475] &quot;SNP&quot; &quot;SNP&quot; &quot;SNP&quot; &quot;SNP&quot; ... ## .. ..$ Reference_Allele : chr [1:475] &quot;G&quot; &quot;C&quot; &quot;T&quot; &quot;C&quot; ... ## .. ..$ Tumor_Seq_Allele1 : chr [1:475] &quot;G&quot; &quot;C&quot; &quot;T&quot; &quot;C&quot; ... ## .. ..$ Tumor_Seq_Allele2 : chr [1:475] &quot;A&quot; &quot;T&quot; &quot;G&quot; &quot;G&quot; ... ## .. ..$ Tumor_Sample_Barcode : chr [1:475] &quot;TCGA-AB-2830&quot; &quot;TCGA-AB-2898&quot; &quot;TCGA-AB-2887&quot; &quot;TCGA-AB-3009&quot; ... ## .. ..$ Protein_Change : chr [1:475] &quot;p.I490I&quot; &quot;p.S1756S&quot; &quot;p.T185T&quot; &quot;p.L77L&quot; ... ## .. ..$ i_TumorVAF_WU : num [1:475] 34.27 38.3 49.04 48.1 0.201 ... ## .. ..$ i_transcript_name : chr [1:475] &quot;NM_032583.3&quot; &quot;NM_013227.2&quot; &quot;NM_000019.3&quot; &quot;NM_020039.2&quot; ... ## .. ..- attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; ## ..@ clinical.data :Classes &#39;data.table&#39; and &#39;data.frame&#39;: 192 obs. of 1 variable: ## .. ..$ Tumor_Sample_Barcode: Factor w/ 192 levels &quot;TCGA-AB-2802&quot;,..: 190 6 146 185 114 155 45 103 118 71 ... ## .. ..- attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; 6.2.8 Shows sample summry. getSampleSummary(laml); ## Tumor_Sample_Barcode Frame_Shift_Del Frame_Shift_Ins In_Frame_Del ## 1: TCGA-AB-3009 0 5 0 ## 2: TCGA-AB-2807 1 0 1 ## 3: TCGA-AB-2959 0 0 0 ## 4: TCGA-AB-3002 0 0 0 ## 5: TCGA-AB-2849 0 1 0 ## --- ## 188: TCGA-AB-2933 0 0 0 ## 189: TCGA-AB-2942 0 0 0 ## 190: TCGA-AB-2946 0 0 0 ## 191: TCGA-AB-2954 0 0 0 ## 192: TCGA-AB-2982 0 0 0 ## In_Frame_Ins Missense_Mutation Nonsense_Mutation Splice_Site total ## 1: 1 25 2 1 34 ## 2: 0 16 3 4 25 ## 3: 0 22 0 1 23 ## 4: 0 15 1 5 21 ## 5: 0 16 1 2 20 ## --- ## 188: 0 1 0 0 1 ## 189: 1 0 0 0 1 ## 190: 0 1 0 0 1 ## 191: 0 1 0 0 1 ## 192: 0 1 0 0 1 6.2.9 Show frequently mutated genes. getGeneSummary(laml); ## Hugo_Symbol Frame_Shift_Del Frame_Shift_Ins In_Frame_Del ## 1: FLT3 0 0 1 ## 2: DNMT3A 4 0 0 ## 3: NPM1 0 33 0 ## 4: IDH2 0 0 0 ## 5: IDH1 0 0 0 ## --- ## 1237: ZNF689 0 0 0 ## 1238: ZNF75D 0 0 0 ## 1239: ZNF827 1 0 0 ## 1240: ZNF99 0 0 0 ## 1241: ZPBP 0 0 0 ## In_Frame_Ins Missense_Mutation Nonsense_Mutation Splice_Site total ## 1: 33 15 0 3 52 ## 2: 0 39 5 6 54 ## 3: 0 1 0 0 34 ## 4: 0 20 0 0 20 ## 5: 0 18 0 0 18 ## --- ## 1237: 0 1 0 0 1 ## 1238: 0 1 0 0 1 ## 1239: 0 0 0 0 1 ## 1240: 0 1 0 0 1 ## 1241: 0 1 0 0 1 ## MutatedSamples AlteredSamples ## 1: 52 52 ## 2: 48 48 ## 3: 33 33 ## 4: 20 20 ## 5: 18 18 ## --- ## 1237: 1 1 ## 1238: 1 1 ## 1239: 1 1 ## 1240: 1 1 ## 1241: 1 1 6.2.10 Shows all fields in MAF getFields(laml); ## [1] &quot;Hugo_Symbol&quot; &quot;Entrez_Gene_Id&quot; ## [3] &quot;Center&quot; &quot;NCBI_Build&quot; ## [5] &quot;Chromosome&quot; &quot;Start_Position&quot; ## [7] &quot;End_Position&quot; &quot;Strand&quot; ## [9] &quot;Variant_Classification&quot; &quot;Variant_Type&quot; ## [11] &quot;Reference_Allele&quot; &quot;Tumor_Seq_Allele1&quot; ## [13] &quot;Tumor_Seq_Allele2&quot; &quot;Tumor_Sample_Barcode&quot; ## [15] &quot;Protein_Change&quot; &quot;i_TumorVAF_WU&quot; ## [17] &quot;i_transcript_name&quot; 6.2.11 Plotting MAF summary plotmafSummary(maf = laml, rmOutlier = TRUE, addStat = &#39;median&#39;, dashboard = TRUE); ## Warning: `legend.margin` must be specified using `margin()`. For the old ## behavior use legend.spacing ## Warning: Removed 1 rows containing non-finite values (stat_boxplot). ## Warning: `panel.margin` is deprecated. Please use `panel.spacing` property ## instead 6.2.12 Oncoplots #We will draw oncoplots for top ten mutated genes. (Removing non-mutated samples from the plot for better visualization) oncoplot(maf = laml, top = 10, removeNonMutated = TRUE); 6.2.13 Transition and Transversions. laml.titv = titv(maf = laml, plot = FALSE, useSyn = TRUE); #plot titv summary plotTiTv(res = laml.titv); ## Warning: `legend.margin` must be specified using `margin()`. For the old ## behavior use legend.spacing 6.3 Explore cummeRbund for Diffrential Gene Expression Analysis cummeRbund: Allows for persistent storage, access, exploration, and manipulation of Cufflinks high-throughput sequencing data. In addition, provides numerous plotting functions for commonly used visualizations. https://bioconductor.org/packages/release/bioc/html/cummeRbund.html 6.4 References https://bioconductor.org/packages/release/bioc/html/maftools.html Mayakonda, A. &amp; Koeffler, H.P. Maftools: Efficient analysis, visualization and summarization of MAF files from large-scale cohort based cancer studies. bioRxiv (2016). doi: http://dx.doi.org/10.1101/052662 "],
["r-case-study-and-tasks.html", "Chapter 7 R Case study and Tasks 7.1 Case study1: Gene Expression Data Analysis 7.2 Case study1: Solution 7.3 Tasks 7.4 Solutions", " Chapter 7 R Case study and Tasks 7.1 Case study1: Gene Expression Data Analysis 7.1.1 Experimental setup There are two varieties of plant xyz, one is resistant (R) to a fungal infection while other is susceptible to the fungal disease (D). The experiment was conducted to study the differential expression of 490 genes (G1, G2, G3,.., G490), which are involved in 3 different pathways (P1, P2 and P3). The gene expression was measured in the two mentioned varieties of plants, R and D, on Day 2, Day 4, Day 6 and Day 8. The gene expression values for variety R on these days are given as R2, R4, R6 and R8 and that for variety D are given as D2, D4, D6 and D8. The gene expression data is stored in a file path.txt. The first 6 rows of the file are shown below. 7.1.2 Objective Data exploration, visualization and analysis of gene expression data, in a given file, using R to find out those genes, which are differentially expressed on 3 or more days between two varieties, R and D. 7.1.3 Steps Import the file “path.txt” into R. What is the data structure of imported file? How many rows and columns are there? What are column names? Find out minimum, first quantile, median, third quantile, mean and maximum of expression values on each day. Store the result in a file. Visualization of gene expression on 2,4,6,8 days of D and R plants using boxplot. 7.1.3.1 . Visualization of pairwise correlation of gene expressions among R2, R4, R6 and R8. 7.1.3.2 . Visualization of pairwise correlation of gene expressions among D2, D4, D6 and D8. 7.1.3.3 . Calculate the pairwise correlation coefficient values among R2, R4, R6 and R8. 7.1.3.4 . Calculate the pairwise correlation coefficient values among D2, D4, D6 and D8. 7.1.3.5 . Draw a four panel plot depicting four scatterplots of R2 Vs D2, R4 Vs D4, R6 Vs D6 and R8 Vs D8. 7.1.3.6 . Filter those genes that are up-regulated in D variety on all days i.e. (D2-R2)&gt;0; (D4-R4)&gt;0; (D6-R6)&gt;0 and (D8-R8)&gt;0. Write the differential expression values of these filtered genes in a file, up.txt. Ans: 172 genes. 7.1.3.7 . Count the pathway wise gene count for the genes, which are filtered in step 12. Ans: P1 P2 P3 106 43 23 7.1.3.8 . Plot the heatmap showing clustering of genes filtered in step 12. Save the heatmap image. 7.1.3.9 . You are provided with an annotation file, anno.txt, of all the genes containing information of gene name, description and accession number. Retrieve the annotations for genes filtered in step 12 from anno.txt file. Hint: Search “%in%” in help and try to understand from the given example. 7.1.3.10 . Group the genes as per their pathways. Arrange the values for each group according expression on D2. Write the arranged data in a file, Genes_arranged.txt. 7.2 Case study1: Solution Import the file “path.txt” into R. data=read.table(&quot;path.txt&quot;,header=T) What is the data structure of imported file? str(data) How many rows and columns are there? dim(data) What are column names? colnames(data) Find out minimum, first quantile, median, third quantile, mean and maximum of expression values on each day. Store the result in a file. summary(data) Visualization of gene expression on 2,4,6,8 days of D and R plants using boxplot. boxplot(data[,2:9]); Visualization of pairwise correlation of gene expressions among R2, R4, R6 and R8. pairs(data[,2:5],upper.panel=NULL) Visualization of pairwise correlation of gene expressions among D2, D4, D6 and D8. pairs(data[,6:9],upper.panel=NULL) Calculate the pairwise correlation coefficient values among R2, R4, R6 and R8. rcor=cor(data[,2:5]) Calculate the pairwise correlation coefficient values among D2, D4, D6 and D8. dcor=cor(data[,6:9]) Draw a four panel plot depicting four scatterplots of R2 Vs D2, R4 Vs D4, R6 Vs D6 and R8 Vs D8. par(mfrow=c(2,2)) plot(data$D2,data$R2,xlab=&quot;D2&quot;,ylab=&quot;R2&quot;,cex.lab=1.5); plot(data$D4,data$R4,xlab=&quot;D4&quot;,ylab=&quot;R4&quot;,cex.lab=1.5); plot(data$D6,data$R6,xlab=&quot;D6&quot;,ylab=&quot;R6&quot;,cex.lab=1.5); plot(data$D8,data$R8,xlab=&quot;D8&quot;,ylab=&quot;R8&quot;,cex.lab=1.5); Filter those genes that are up-regulated in D variety on all days i.e. (D2-R2)&gt;0; (D4-R4)&gt;0; (D6-R6)&gt;0 and (D8-R8)&gt;0. Write the differential expression values of these filtered genes in a file, up.txt. library(dplyr) # Filter those genes which are up/down regulated in Diseased condition. temp=mutate(data,diff2=D2-R2,diff4=D4-R4,diff6=D6-R6,diff8=D8-R8,diff2up=diff2&gt;0,diff4up=diff4&gt;0,diff6up=diff6&gt;0,diff8up=diff8&gt;0,totup=diff2up+diff4up+diff6up+diff8up); head(temp) up3=filter(temp,totup&gt;3); write.table(up3,file=&quot;up.txt&quot;,sep=&quot;\\t&quot;,eol=&quot;\\n&quot;,quote=F,row.names=F) Count the pathway wise gene count for the genes, which are filtered in step 12. pathcount=table(up3$Path); Plot the heatmap showing clustering of genes filtered in step 12. Save the heatmap image. library(&quot;gplots&quot;); h=heatmap.2(as.matrix(up3[,2:9]),trace=&quot;none&quot;) You are provided with an annotation file, anno.txt, of all the genes containing information of gene name, description and accession number. Retrieve the annotations for genes filtered in step 12 from anno.txt file. Hint: Search “%in%” in help and try to understand from the given example. annotation=read.table(&quot;anno.txt&quot;, sep=&quot;\\t&quot;,header=T) temp=annotation$Gene %in% up3$Gene info=annotation[temp,] 16 Group the genes as per their pathways. Arrange the values for each group according expression on D2. Write the arranged data in a file, Genes_arranged.txt. gengrp=group_by(up3, Path) arr=arrange(gengrp,D2) write.table(arr,&quot;Genes_arranged.txt&quot;, sep=&quot;\\t&quot;, quote = F) 7.3 Tasks 7.3.1 Vector creation Create a vector x13 with values 2, 3, 4, 5, 6 Create a vector x14 with values 2.0, 2.1, 2.2, 2.3, 2.4, .., 4 Create a vector x15 with 10 random values between 4 and 6 Create a vector x16 with repeated values 3, 4, 5, 3, 4, 5, 3, 4, 5 Create x17 with repeated values 7,7,7,8,8,8,9,9,9 Create a vector x18 with 10 random values between 20 and 30 Create a vector x19 with 10 normally distributed random values Create a vector x20 with values of vectors x13 and x16 followed by 3, 5,10 7.3.2 Fetching vector elements Create a vector x21 with values 33,55,66,88,99. Fetch its 3rd, 5th and 2nd values Fetch values of x21 from 1 to 4 Fetch values of x21 vector excluding 2nd and 3rd elements 12 Fetch last element of x21 using length() 7.3.3 Vector manipulation Create a vector x23 with values 5, 7, 6, 8, 1, 4. Delete 1st and last element. Reset the value of second element to 12. Add value 0 at the beginning of a vector x 7.3.4 Vector arithmetic Write the arithmetic expression to calculate variance of a vector. Cross check your result using var() function. Formula: Variance= sum((x-mean(x))^2) /n-1 where n is total number of elements. Given x, y, z coordinates of two atoms. Atom1 (1.2, 2.3, 3.4) and Atom2 (4.5, 5.6, 6.7). Find distance between 2 atoms. Formula: sqrt((x2-x1)2+(y2-y1)2+(z2-z1)^2) Find out the numbers between 1 to 100, which are divisible by 2 or 3. 7.3.5 Matrix Create a matrix from a vector consisting of numbers from 1 to 12 with 3 columns Fetch 2nd row. Fetch 3rd column Fetch the value 6 Fetch the value 8 and 12 Fetch the value 7, 8, 11 and 12 7.3.6 Data Frame Create a data frame of gene expression data such that First column,“Genes”, is a character vector of 6 gene names (G1, G2, …, G6). Second column, “C1” is a numeric vector of 6 random values from 3 to 5. Hint: Generate random numbers using function sample(). Use R help to see the syntax of sample. Third column, “C2” is a numeric vector of 6 random values from 3 to 5. Fourth column, “T1” is a numeric vector of 6 random values from 5 to 7. Fifth column, “T2” is a numeric vector of 6 random values from 5 to 7. Sixth column, “Pathway” is a character vector of which first 3 represent one pathway “P1” and other 3 represent pathway “P2”. Fetch values of column T2 Fetch values of gene G2 Fetch value of gene G3 from C2 Delete column C2 Insert column C3, which should be numeric vector of 6 random values from 3 to 5. Find mean of column C1 7.3.7 Tasks on Iris data set Open iris data set file using read.table() and store in a variable names “iris_data” Check the structure of “iris_data”. Note the column names. How many categories are there in column named as “Species”. Note the names of species. How many rows and columns are there? How many observations (rows) are there for each species? Number of rows with Species as setosa Number of rows with Species as virginica Number of rows with Species as versicolor Find the mean of all sepal lengths. Find the mean of sepal lengths in Species setosa. What is the overall correlation between Sepal length and Petal length? What is the correlation between Sepal width and Petal width of Species virginica? Find the difference between sepal lengths of species setosa and versicolor. What is the mean difference between them? Carry out the t-test between sepal lengths of species setosa and versicolor. Is it statistically significant? 7.3.8 Visualization You are provided with an excel file “iris.xls”. The file contains IRIS data, 150 flowers, Categorized into 3 plants (SP:Setosa/Versicolor/Virginica) and two colors (Col:Red/Blue). The data consists of SL (Sepal length), SW (Sepal width), PL (Petal length) and PW (Petal width) in cm. Task: Load the data in R using appropriate function and extract useful information by data visualization. Plot1: Scatter plot of Sepal length vs Petal length of all 150 flowers, color according to species/plants. Plot2: Barplot showing distribution of Sepal lengths among 6 classes of flowers (3 plants and 2 colors). Plot3: Multi panel plot showing the histogram of SL, PL, SW, PW of all 150 flowers. Plot4: Box plot showing SL, SW, PL, PW distribution along with a line joining their mean lengths. Plot5: Probability density plot of Sepal lengths among three different categories of plants. Plot6: 3D plot showing distinct clustering of flowers in terms of SL, SW and PL. Different colors for different plants. Plot7: Scatter plot matrix showing a global view of the distribution of SL, SW, PL and PW across 3 plants. Plot8: Heatmap showing clustering of flowers in terms of their SL, SW, PL and PW properties. Plot9: Pie chart showing the number of flowers in 6 categories (3 plants and 2 colors) Plot10: Dot chart showing clear distribution of SL among 3 plants. 7.4 Solutions 7.4.1 Vector creation 1. Create a vector x13 with values 2, 3, 4, 5, 6 x13=c(2,3,4,5,6) 2. Create a vector x14 with values 2.0, 2.1, 2.2, 2.3, 2.4, .., 4 x14=seq(from=2,to=4, by=0.1) 3. Create a vector x15 with 10 random values between 4 and 6 x15=sample(4:6,10, replace=T) 4. Create a vector x16 with repeated values 3, 4, 5, 3, 4, 5, 3, 4, 5 x16=rep(c(3,4,5),times=3) 5. create x17 with repeated values 7,7,7,8,8,8,9,9,9 x17=rep(c(7,8,9),each=3) 6. Create a vector x18 with 10 random values between 20 and 30 x18=sample(20:30,10) 7. Create a vector x19 with 10 normally distributed random values x19=rnorm(10) 8. Create a vector x20 with values of vectors x13 and x16 followed by 3, 5,10 x20=c(x13,x16,3,5,10) 7.4.2 Fetching vector elements 9. Create a vector x21 with values 33,55,66,88,99 and fetch its 3rd, 5th and 2nd values x21=c(33,55,66,88,99) x21[c(3,5,2)] 10. Fetch its values from 1 to 4 x21[1:4] 11. Fetch values of x21 vector excluding 2nd and 3rd elements x22=x21[-c(2,3)] x22 12 Fetch last element of x21 using length() x21[length(x21)] 7.4.3 Vector manipulation 13. Create a vector x23 with values 5, 7, 6, 8, 1, 4. x23=c(5,7,6,8,1,4) Delete 1st and last elements. x23=x23[-c(1,length(x23))] Reset the value of second element to 12. x23[2]=12 Add value 0 at the beginning of a vector x23 x23=c(0,x23) 7.4.4 Vector arithmetic 14. Calculate Variance Write the arithmetic expression to calculate variance of a vector. Cross check your result using var() function. Formula: Variance= sum((x-mean(x))^2) /n-1 where n is total number of elements. x=c(5,7,6,8,1,4) xvar=sum((x-mean(x))^2)/(length(x)-1) xvar var(x) 15. Distance between atoms Given x, y, z coordinates of two atoms. Atom1 (1.2, 2.3, 3.4) and Atom2 (4.5, 5.6, 6.7). Find distance between 2 atoms. Formula: sqrt((x2-x1)2+(y2-y1)2+(z2-z1)2) atom1=c(1.2,2.3,3.4) atom2=c(4.5,5.6,6.7) dist=sum((atom1-atom2)^2) dist 16. Find out the numbers between 1 to 100, which are divisible by 2 or 3. x=1:100 x[which(x%%2==0 &amp; x%%3==0)] 7.4.5 Matrix 17 Create matrix Create a matrix from a vector cosisting of numbers from 1 to 12 with 3 columns mt=matrix(1:12,ncol=3) 18. Fetch 2nd row. Fetch 3rd column mt[2,] mt[,3] 19. Fetch the value 6 mt[2,2] 20. Fetch the value 8 and 12 mt[4,c(2,3)] 21. Fetch the value 7, 8, 11 and 12 mt[c(3,4),c(2,3)] 7.4.6 Data Frame 22. Create a data frame of gene expression data such that First column,“Genes”, is a character vector of 6 gene names (G1, G2, …, G6). Second column, “C1” is a numeric vector of 6 random values from 3 to 5. Hint: Generate random numbers using function sample(). Use R help to see the syntax of sample. Third column, “C2” is a numeric vector of 6 random values from 3 to 5. Fourth column, “T1” is a numeric vector of 6 random values from 5 to 7. Fifth column, “T2” is a numeric vector of 6 random values from 5 to 7. Sixth column, “Pathway” is a character vector of which first 3 represent one pathway “P1” and other 3 represent pathway “P2”. genes=paste(“G”,1:6,sep=&quot;&quot;) C1=sample(3:5,6, replace=T) C2=sample(3:5,6, replace=T) T1=sample(5:7,6, replace=T) T2=sample(5:7,6, replace=T) pathway=rep(c(“P1”,“P2”),each=3) exp=data.frame(“Genes”=genes,“C1”=C1,“C2”=C2,“T1”=T1,“T2”=T2,“Pathway”=pathway) 23. Fetch values of column D2 exp$T2 24. Fetch values of gene G2 exp[2,] 25. Fetch value of gene G3 from C2 exp[3,3] 26. Delete column C2 exp$C2=NULL 27. Insert column C3, which should be numeric vector of 6 random values from 3 to 5. exp$C3=sample(3:5,6, replace=T) 28. Find mean of column C1 mean(exp$C1) 7.4.7 Tasks on iris data set 1. Open iris data set file using read.table() and store in a variable name “iris_data” iris_data=read.table(“iris.txt”,header=T) 2. Check the structure of “iris_data”. Note the column names. How many categories are there in column named as “Species”. Note the names of species. str(iris_data) levels(iris_data$Species) 3. How many rows and columns are there? dim(iris_data) 4. How many observations (rows) are there for each species? a. Number of rows with Species as setosa b. Number of rows with Species as virginica c. Number of rows with Species as versicolor table(iris_data$Species) 5. Find the mean of all sepal lengths. mean(iris_data$Sepal.Length) 6. Find the mean of sepal lengths in Species setosa. library(dplyr) setosa=filter(iris_data, Species==“setosa”) mean(setosa$Sepal.Length) 7. What is the overall correlation between Sepal length and Petal length? cor(iris_data$Sepal.Length, iris_data$Petal.Length) 8. What is the correlation between Sepal width and Petal width of Species virginica? virginica=filter(iris_data, Species==“virginica”) cor(virginica$Sepal.Width, virginica$Petal.Width) 9. Find the difference between sepal lengths of species setosa and versicolor. What is the mean difference between them? versicolor=filter(iris_data, Species==“versicolor”) sldiff= setosa$Sepal.Length - versicolor$Sepal.Length mean(sldiff) 10. Carry out the t-test between sepal lengths of species setosa and versicolor. Is it statistically significant? Assumptions: Sepal lengths of two species are normally distributed Their variances may not be equal Observations are not paired Two sided t-test, we are just interested to know if sepal lenghts between species are significantly different or not. t.test(setosa$Sepal.Length, versicolor$Sepal.Length) Based on p-value we reject null hypothesis at 95 % confidence interval Hence sepal lengths of species setosa and versicolor are significantly different Note: Please see the help for t.test to find out various options for t-test 7.4.8 Visualization Plot1: Scatter plot of Sepal length vs Petal length of all 150 flowers, color according to species/plants. library(gdata) irisd=read.xls(&quot;iris.xls&quot;); plot(irisd$SL,irisd$PL,col=rep(c(&quot;red&quot;,&quot;blue&quot;,&quot;green&quot;),each=50),pch=15,xlab=&quot;Sepal Length&quot;,ylab=&quot;Petal Length&quot;,cex.lab=1.2,main=&quot;Sepal Vs Petal Length&quot;,cex.axis=1.2) legend(4.2,7,c(&quot;Setosa&quot;,&quot;Versicolor&quot;,&quot;virginia&quot;),col=c(&quot;red&quot;,&quot;blue&quot;,&quot;green&quot;),pch=15) Plot2: Barplot showing distribution of Sepal lengths among 6 classes of flowers (3 plants and 2 colors). barplot(t(table(irisd$SP,irisd$Col)),beside=T,col=c(&quot;red&quot;,&quot;blue&quot;),ylim=c(0,50),cex.axis=1.5,cex.name=1.5) legend(1,50,c(&quot;Red&quot;,&quot;Blue&quot;),pch=15,col=c(&quot;red&quot;,&quot;blue&quot;)) Plot3: Multi panel plot showing the histogram of SL, PL, SW, PW of all 150 flowers. par(mfrow=c(2,2)) hist(irisd[,1],xlab=&quot;Sepal Length&quot;,ylab=&quot;Frequency&quot;,main=&quot;&quot;,cex.lab=1.2,col=&quot;gray&quot;) hist(irisd[,2],xlab=&quot;Sepal width&quot;,ylab=&quot;Frequency&quot;,main=&quot;&quot;,cex.lab=1.2,col=&quot;gray&quot;) hist(irisd[,3],xlab=&quot;Petal Length&quot;,ylab=&quot;Frequency&quot;,main=&quot;&quot;,cex.lab=1.2,col=&quot;gray&quot;) hist(irisd[,4],xlab=&quot;Petal Width&quot;,ylab=&quot;Frequency&quot;,main=&quot;&quot;,cex.lab=1.2,col=&quot;gray&quot;) par(mfrow=c(1,1)) Plot4: Box plot showing SL, SW, PL, PW distribution along with a line joining their mean lengths. boxplot(irisd[,1:4],col=c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;,&quot;orange&quot;),main=&quot;Length Distribution&quot;,cex.axis=1.2,ylab=&quot;Length (cm)&quot;,cex.lab=1.2) l=summarise(irisd,mean(SL),mean(SW),mean(PL),mean(PW)) lines(c(1,2,3,4),l,lwd=4,col=&quot;brown&quot;) legend(3.5,8,c(&quot;Mean\\nLength&quot;),lty=1,lwd=4,col=&quot;brown&quot;) Plot5: Probability density plot of Sepal lengths among three different categories of plants. # First filter library(dplyr) set_SL=filter(irisd,SP==&quot;setosa&quot;) %&gt;% select(SL) versi_SL=filter(irisd,SP==&quot;versicolor&quot;) %&gt;% select(SL) virgi_SL=filter(irisd,SP==&quot;virginica&quot;) %&gt;% select(SL) # Convert them to vector set_SL=set_SL$SL versi_SL=versi_SL$SL; virgi_SL=virgi_SL$SL; # use density to plot plot(density(set_SL),xlim=c(4,10),lwd=2,xlab=&quot;Length (cm)&quot;,main=&quot;Prob. Density of Sepal Length across different flowers&quot;) lines(density(versi_SL),col=&quot;red&quot;,lwd=2) lines(density(virgi_SL),col=&quot;green&quot;,lwd=2) legend(8,1.2,lwd=2,c(&quot;Setosa&quot;,&quot;Versicolor&quot;,&quot;Virginica&quot;),col=c(&quot;black&quot;,&quot;red&quot;,&quot;green&quot;)) Plot6: 3D plot showing distinct clustering of flowers in terms of SL, SW and PL. Different colors for different plants. library(rgl) plot3d(irisd[,1:3],col=rep(c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;),each=50)) Plot7: Scatter plot matrix showing a global view of the distribution of SL, SW, PL and PW across 3 plants. pairs(irisd[,1:4],col=rep(c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;),each=50)) Plot8: Heatmap showing clustering of flowers in terms of their SL, SW, PL and PW properties. m=as.matrix(irisd[,1:4]); library(&quot;gplots&quot;) heatmap.2(m, trace=&quot;none&quot;) Plot9: Pie chart showing the number of flowers in 6 categories (3 plants and 2 colors) #Subset species by colors library(dplyr) Set_B=filter(irisd, SP==&quot;setosa&quot; &amp; Col==&quot;Blue&quot; ) Set_R=filter(irisd, SP==&quot;setosa&quot; &amp; Col==&quot;Red&quot; ) Ver_B=filter(irisd, SP==&quot;versicolor&quot; &amp; Col==&quot;Blue&quot; ) Ver_R=filter(irisd, SP==&quot;versicolor&quot; &amp; Col==&quot;Red&quot; ) Vir_B=filter(irisd, SP==&quot;virginica&quot; &amp; Col==&quot;Blue&quot; ) Vir_R=filter(irisd, SP==&quot;virginica&quot; &amp; Col==&quot;Red&quot; ) #Create vector of counts in each subset irisp=c(nrow(Set_B),nrow(Set_R),nrow(Ver_B),nrow(Ver_R),nrow(Vir_B),nrow(Vir_R)) pie(irisp, labels=irisp, col=c(&quot;Red&quot;, &quot;Cyan&quot;, &quot;yellow&quot;, &quot;Blue&quot;, &quot;Green&quot;, &quot;Magenta&quot;)) legend(0.9,1,c(&quot;Set_B&quot;,&quot;Ver_B&quot;,&quot;Vir_B&quot;,&quot;Set_R&quot;,&quot;Ver_R&quot;,&quot;Vir_R&quot;),pch=15, col=c(&quot;Red&quot;,&quot;Yellow&quot;,&quot;Green&quot;, &quot;Cyan&quot;,&quot;Blue&quot;,&quot;Magenta&quot;)) Plot10: Dot chart showing clear distribution of SL among 3 plants. dotchart(irisd$SL,group=irisd$SP, main=&quot;Sepal Length across 3 Plants&quot;) "],
["descriptive-statistics.html", "Chapter 8 Descriptive statistics 8.1 Measure of Centrality 8.2 Measure of Spread 8.3 Handle missing values 8.4 Estimate Skewness and Kurtosis 8.5 Further with Skewness and Kurtosis.", " Chapter 8 Descriptive statistics 8.1 Measure of Centrality data=c(11,2,35,46,55); print(data); ## [1] 11 2 35 46 55 mean(data); # Estimate mean ## [1] 29.8 median(data); # Estimate median ## [1] 35 summary(data); # Summarise the data ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2.0 11.0 35.0 29.8 46.0 55.0 quantile(data); # Estimate quartiles ## 0% 25% 50% 75% 100% ## 2 11 35 46 55 quantile(x = data, probs = 0.25); # First quantile ## 25% ## 11 quantile(x = data, probs = 0.5); # Second quantile or Median ## 50% ## 35 quantile(x = data, probs = 0.75); # Third quantile ## 75% ## 46 # Percentile quantile(x = data, probs = c(0.30, 0.45, 0.65)); # 30th, 45th and 65th percentile ## 30% 45% 65% ## 15.8 30.2 41.6 8.2 Measure of Spread var(data); # Variance ## [1] 512.7 sd(data); # Standard deviation ## [1] 22.64288 range(data); # range, returns min and max ## [1] 2 55 max(data) - min(data); # Range ## [1] 53 IQR(data); # Inter quartile range ## [1] 35 # Estimate IQR by yourself, IQR= quantile3-quantil1 i.e. Q3-Q1 # Compare the result with the result of IQR function q1 = quantile(x = data, probs = 0.25); # First quantile q3 = quantile(x = data, probs = 0.75); # Third quantile print(q3-q1); ## 75% ## 35 8.3 Handle missing values # Before adding NA, data: print(data); ## [1] 11 2 35 46 55 # Add one missing value at the end data=c(data,NA); # After adding NA, data: print(data); ## [1] 11 2 35 46 55 NA mean(data); # without na.rm parameter, if Na is present result will be NA ## [1] NA mean(data, na.rm = TRUE); # with na.rm parameter, if NA is present, then they are excluded ## [1] 29.8 # u have to use na.rm in median, var, sd, IQR, range, quantile function summary(data); # no need to give na.rm, NA are treated separately ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 2.0 11.0 35.0 29.8 46.0 55.0 1 8.3.1 Shape / Data Distribution # Consider iris dataset head(iris); ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa # Check sepal length distribution # Since sepal length is numerical data, we can use hist() and density() to see the distribution # Histogram hist(iris$Sepal.Length, xlab=&quot;Sepal Length&quot;, main=&quot;Histogram of Sepal Length&quot;); # Density plot # You can see its a unimodal distribution plot(density(iris$Sepal.Length), xlab=&quot;Sepal Length&quot;, main=&quot;Density of Sepal Length&quot;) # Box plot boxplot(iris$Sepal.Length, main=&quot;Boxplot of Sepal Length&quot;) # Histogram of four features (Sepal.Length Sepal.Width Petal.Length Petal.Width) of iris dataset par(mfrow=c(2,2)); hist(iris$Sepal.Length, xlab=&quot;Sepal Length&quot;, main=&quot;Histogram of Sepal Length&quot;) hist(iris$Sepal.Width, xlab=&quot;Sepal Width&quot;, main=&quot;Histogram of Sepal Width&quot;) hist(iris$Petal.Length, xlab=&quot;Petal Length&quot;, main=&quot;Histogram of Petal Length&quot;) hist(iris$Petal.Width, xlab=&quot;Petal Width&quot;, main=&quot;Histogram of Petal Width&quot;) # Density plot of four features (Sepal.Length Sepal.Width Petal.Length Petal.Width) of iris dataset par(mfrow=c(2,2)); plot(density(iris$Sepal.Length), xlab=&quot;Sepal Length&quot;, main=&quot;Density plot of Sepal Length&quot;) plot(density(iris$Sepal.Width), xlab=&quot;Sepal Width&quot;, main=&quot;Density plot of Sepal Width&quot;) plot(density(iris$Petal.Length), xlab=&quot;Petal Length&quot;, main=&quot;Density plot of Petal Length&quot;) plot(density(iris$Petal.Width), xlab=&quot;Petal Width&quot;, main=&quot;Density plot of Petal Width&quot;) # Box plot of four features (Sepal.Length Sepal.Width Petal.Length Petal.Width) of iris dataset par(mfrow=c(1,1)); boxplot(iris[,1:4]) # Density plot of four features (Sepal.Length Sepal.Width Petal.Length Petal.Width) of iris dataset. Mean is marked in red line while median in blue. par(mfrow=c(2,2)); plot(density(iris$Sepal.Length), xlab=&quot;Sepal Length&quot;, main=&quot;Density plot of Sepal Length&quot;) meanval= mean(iris$Sepal.Length) medianval=median(iris$Sepal.Length); lines(c(meanval, meanval),c(0,1), lwd=2, col=&quot;red&quot;); # mean line lines(c(medianval, medianval),c(0,1), lwd=2, col=&quot;blue&quot;); # mean line plot(density(iris$Sepal.Width), xlab=&quot;Sepal Width&quot;, main=&quot;Density plot of Sepal Width&quot;) meanval= mean(iris$Sepal.Width) medianval=median(iris$Sepal.Width); lines(c(meanval, meanval),c(0,1), lwd=2, col=&quot;red&quot;); # mean line lines(c(medianval, medianval),c(0,1), lwd=2, col=&quot;blue&quot;); # mean line plot(density(iris$Petal.Length), xlab=&quot;Petal Length&quot;, main=&quot;Density plot of Petal Length&quot;) meanval= mean(iris$Petal.Length) medianval=median(iris$Petal.Length); lines(c(meanval, meanval),c(0,1), lwd=2, col=&quot;red&quot;); # mean line lines(c(medianval, medianval),c(0,1), lwd=2, col=&quot;blue&quot;); # mean line plot(density(iris$Petal.Width), xlab=&quot;Petal Width&quot;, main=&quot;Density plot of Petal Width&quot;) meanval= mean(iris$Petal.Width) medianval=median(iris$Petal.Width); lines(c(meanval, meanval),c(0,1), lwd=2, col=&quot;red&quot;); # mean line lines(c(medianval, medianval),c(0,1), lwd=2, col=&quot;blue&quot;); # mean line 8.4 Estimate Skewness and Kurtosis Load the moments library library(moments); Calculate skewness. Skewness is a measure of symmetry. Negative skewness: mean of the data &lt; median and the data distribution is left-skewed. Positive skewness: mean of the data &gt; median and the data distribution is right-skewed. skewness(iris$Sepal.Length); # distribution is skewed towards the right. ## [1] 0.3117531 skewness(iris$Sepal.Width); # distribution is skewed towards the right. ## [1] 0.3157671 skewness(iris$Petal.Length); # distribution is skewed towards the left. ## [1] -0.2721277 skewness(iris$Petal.Width); # distribution is skewed towards the left. ## [1] -0.1019342 Estimate kurtosis. kurtosis describes the tail shape of the data distribution. The normal distribution has zero kurtosis and thus the standard tail shape. It is said to be mesokurtic. Negative kurtosis would indicate a thin-tailed data distribution, and is said to be platykurtic. Positive kurtosis would indicate a fat-tailed distribution, and is said to be leptokurtic. kurtosis(iris$Sepal.Length); ## [1] 2.426432 kurtosis(iris$Sepal.Width); ## [1] 3.180976 kurtosis(iris$Petal.Length); ## [1] 1.604464 kurtosis(iris$Petal.Width); ## [1] 1.663933 8.5 Further with Skewness and Kurtosis. Source: http://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm Many classical statistical tests and intervals depend on normality assumptions. Significant skewness and kurtosis clearly indicate that data are not normal. If a data set exhibits significant skewness or kurtosis (as indicated by a histogram or the numerical measures), what can we do about it? One approach is to apply some type of transformation to try to make the data normal, or more nearly normal. The Box-Cox transformation is a useful technique for trying to normalize a data set. In particular, taking the log or square root of a data set is often useful for data that exhibit moderate right skewness. Another approach is to use techniques based on distributions other than the normal. For example, in reliability studies, the exponential, Weibull, and lognormal distributions are typically used as a basis for modeling rather than using the normal distribution. "],
["data-distributions.html", "Chapter 9 Data Distributions 9.1 Normal distribution 9.2 Effect of mean and sd parameter on normal distribution 9.3 Effect of n (sample size) on normal distribution 9.4 Use z score to calculate percentile (area below or lower tail) 9.5 Use z score to calculate Upper tail 9.6 Given percentile (area below the curve or lower tail area), find the z score 9.7 Explore the applet 9.8 Evaluating the normal distribution 9.9 Sampling distribution 9.10 Standard Error 9.11 Confidence interval 9.12 Hypothesis test for single sample mean 9.13 One tailed test (Greater) 9.14 One tailed test (Lesser) 9.15 Hypothesis test for two sample mean, unpaired 9.16 Hypothesis test for two sample mean, paired 9.17 Check for normality 9.18 Check for uniform variance 9.19 Hypothesis test for single sample proportion", " Chapter 9 Data Distributions 9.1 Normal distribution Normal distribution is explain by 2 parameter, mean and standard deviation Normal distribution with mean = 0 and sd = 1 is called the standard normal distribution, and is denoted as N(0,1). Changing the mean value will shift the distribution along x-axis Changing the standard deviation will change the spread of distribution, thus shape. 9.2 Effect of mean and sd parameter on normal distribution set.seed(15); # Fetch 100 random elements from a normal distribution with mean 0, sd 1 x1 = rnorm(n = 100, mean = 0, sd = 1); # Fetch 100 random elements from a normal distribution with mean 0, sd 3 x2 = rnorm(n = 100, mean = 0, sd = 2); # Fetch 100 random elements from a normal distribution with mean 5, sd 1 x3 = rnorm(n = 100, mean = 5, sd = 1); # Fetch 100 random elements from a normal distribution with mean 5, sd 3 x4 = rnorm(n = 100, mean = 5, sd = 2); plot(density(x1), lwd=2, xlim=c(-10,10)); lines(density(x2), col=&quot;red&quot;, lwd=2); lines(density(x3), col=&quot;green&quot;, lwd=2); lines(density(x4), col=&quot;blue&quot;, lwd=2); 9.3 Effect of n (sample size) on normal distribution set.seed(35); # Fetch 10 random elements from a normal distribution with mean 0, sd 1 x1 = rnorm(n = 10, mean = 0, sd = 1); # Fetch 20 random elements from a normal distribution with mean 0, sd 1 x2 = rnorm(n = 20, mean = 0, sd = 1); # Fetch 50 random elements from a normal distribution with mean 0, sd 1 x3 = rnorm(n = 50, mean = 0, sd = 1); # Fetch 100 random elements from a normal distribution with mean 0, sd 1 x4 = rnorm(n = 100, mean = 0, sd = 1); # Fetch 1000 random elements from a normal distribution with mean 0, sd 1 x5 = rnorm(n = 1000, mean = 0, sd = 1); As n increases (&gt;30), distribution approximates to normal distribution. plot(density(x1), lwd=2, xlim=c(-10,10)); lines(density(x2), col=&quot;red&quot;, lwd=2); lines(density(x3), col=&quot;green&quot;, lwd=2); lines(density(x4), col=&quot;blue&quot;, lwd=2); lines(density(x5), col=&quot;cyan&quot;, lwd=2); 9.4 Use z score to calculate percentile (area below or lower tail) Percentile is percentage of observations that fall below a given data point Use pnorm (probability distribution function) q = quantile. As q increases, the area under the curve below q increases. So as pnorm pnorm(q = -0.5, mean = 0, sd = 1); # 30% observations fall below -0.5 ## [1] 0.3085375 pnorm(q = -0.2, mean = 0, sd = 1); # 42% observations fall below -0.2 ## [1] 0.4207403 pnorm(q = -0.1, mean = 0, sd = 1); # 46% observations fall below -0.1 ## [1] 0.4601722 pnorm(q = 0.1, mean = 0, sd = 1); # 53% observations fall below 0.1 ## [1] 0.5398278 pnorm(q = 0.2, mean = 0, sd = 1); # 57% observations fall below 0.2 ## [1] 0.5792597 pnorm(q = 0.5, mean = 0, sd = 1); # 69% observations fall below 0.5 ## [1] 0.6914625 # Now changing with mean and sd pnorm(q = 4, mean = 5, sd = 1); # 15% observations fall below 4 ## [1] 0.1586553 9.5 Use z score to calculate Upper tail pnorm(q = -0.5, mean = 0, sd = 1, lower.tail = FALSE); # 69% observations fall above -0.5 ## [1] 0.6914625 pnorm(q = -0.2, mean = 0, sd = 1, lower.tail = FALSE); # 57% observations fall above -0.2 ## [1] 0.5792597 pnorm(q = -0.1, mean = 0, sd = 1, lower.tail = FALSE); # 53% observations fall above -0.1 ## [1] 0.5398278 pnorm(q = 0.1, mean = 0, sd = 1, lower.tail = FALSE); # 46% observations fall above 0.1 ## [1] 0.4601722 pnorm(q = 0.2, mean = 0, sd = 1, lower.tail = FALSE); # 42% observations fall above 0.2 ## [1] 0.4207403 pnorm(q = 0.5, mean = 0, sd = 1, lower.tail = FALSE); # 30% observations fall above 0.5 ## [1] 0.3085375 9.6 Given percentile (area below the curve or lower tail area), find the z score Use qnorm (Quantile function) qnorm(p = 0.3, mean = 0, sd = 1); # Data point at which 30% observations found below is -0.52 ## [1] -0.5244005 qnorm(p = 0.4, mean = 0, sd = 1); # Data point at which 40% observations found below is -0.25 ## [1] -0.2533471 qnorm(p = 0.5, mean = 0, sd = 1); # Data point at which 50% observations found below is 0 because mean = 0 ## [1] 0 qnorm(p = 0.6, mean = 0, sd = 1); # Data point at which 60% observations found below is 0.25 ## [1] 0.2533471 qnorm(p = 0.7, mean = 0, sd = 1); # Data point at which 70% observations found below is 0.52 ## [1] 0.5244005 qnorm(p = 0.9, mean = 0, sd = 1); # Data point at which 90% observations found below is 1.28 ## [1] 1.281552 9.7 Explore the applet https://gallery.shinyapps.io/dist_calc/ 9.8 Evaluating the normal distribution Histogram though is a nice way to look the overall distribution of data, it sometimes become difficult to check for normality from the plot itself. Another useful alternative way is to draw a normal probability plot (normal Q-Q plot or quantile-quantile plot). Below we draw QQplot for each features from iris dataset. In a perfectly normal distribution, x-axis (theoretical quantiles) and y-axis (Observed quantiles) should match perfectly well, thus all points will be on the diagonel line. Any deviation (skewness) will show the deviation of datapoints away from the line. Based on which end the deviation is, one can guess whether the given data is either left/right skewed. A data set that is nearly normal will result in a probability plot where the points closely follow the line. Any deviations from normality leads to deviations of these points from the line. In the example below par(mfrow=c(2,2)) qqnorm(iris$Sepal.Length); qqline(iris$Sepal.Length); qqnorm(iris$Sepal.Width); qqline(iris$Sepal.Width); qqnorm(iris$Petal.Length); # Strongly negatively skewed qqline(iris$Petal.Length); qqnorm(iris$Petal.Width); # Strongly negatively skewed qqline(iris$Petal.Width); 9.9 Sampling distribution Lets take sepal length from iris dataset. There are 150 flowers. Lets consider this as population i.e. the 150 sepal length values are suppose the population (Which is not true in real sense). sl = iris$Sepal.Length; print(sl); ## [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 ## [18] 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 ## [35] 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 ## [52] 6.4 6.9 5.5 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 ## [69] 6.2 5.6 5.9 6.1 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 ## [86] 6.0 6.7 6.3 5.6 5.5 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 ## [103] 7.1 6.3 6.5 7.6 4.9 7.3 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 ## [120] 6.0 6.9 5.6 7.7 6.3 6.7 7.2 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 ## [137] 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8 6.7 6.7 6.3 6.5 6.2 5.9 Lets randomly select 50 flowers and see the mean sepal length. sample1 = sample(sl, 50); print(mean(sample1)); ## [1] 5.932 Lets repeat the sampling process 5 times and see how the mean values varies. As you can see from the result, each time we randomly sample, the sample mean varies. This variation is due to random sampling. Sampling distribution implies the distribution of sample statistics. set.seed(15); sample1 = sample(sl, 50); sample2 = sample(sl, 50); sample3 = sample(sl, 50); sample4 = sample(sl, 50); sample5 = sample(sl, 50); print(c(mean(sample1), mean(sample2), mean(sample3), mean(sample4), mean(sample5))) ## [1] 5.934 5.866 5.748 5.838 5.902 Lets repeat this sampling 100 times and plot the distribution of sample means. meanvalues = 0; for(i in 1:100) { meanvalues = c(meanvalues, mean(sample(sl, 50))); } meanvalues = meanvalues[-1]; plot(density(meanvalues), xlab=&quot;sample mean&quot;); 9.10 Standard Error # Standard deviation of sample means is called standard error print(sd(meanvalues)); # Standard Error ## [1] 0.09538724 # Estimate standard error from a single sample mean sample1 = sample(sl, 50); sd(sample1)/sqrt(length(sample1)); ## [1] 0.1210215 How larger sample sizes have low standard error i.e. larger sample truely represents population Lets repeat the sampling 5000 times. Also lets explore the different sample sizes n=10, n=30, n=100, n=1000 meanvalues1 = 0; meanvalues2 = 0; meanvalues3 = 0; meanvalues4 = 0; for(i in 1:5000) { meanvalues1 = c(meanvalues1, mean(sample(sl, 10))); meanvalues2 = c(meanvalues2, mean(sample(sl, 30))); meanvalues3 = c(meanvalues3, mean(sample(sl, 100, replace = TRUE))); meanvalues4 = c(meanvalues4, mean(sample(sl, 1000, replace = TRUE))); } meanvalues1 = meanvalues1[-1]; meanvalues2 = meanvalues2[-1]; meanvalues3 = meanvalues3[-1]; meanvalues4 = meanvalues4[-1]; # Standard error is less for n=1000 case # i.e. as sample size increases, sampling bias decreases i.e. sample mean can truely represent the population mean print(c(sd(meanvalues1),sd(meanvalues2),sd(meanvalues3),sd(meanvalues4))); ## [1] 0.25022862 0.13585496 0.08228301 0.02609450 # From the plot below, you can see the spread for n=1000 sample is less (blue line) i.e. having low standard error par(mfrow=c(1,1)) plot(density(meanvalues1), xlab=&quot;sample mean&quot;, ylim=c(0,16), lwd=2); lines(density(meanvalues2), xlab=&quot;sample mean&quot;, col=&quot;red&quot;, lwd=2); lines(density(meanvalues3), xlab=&quot;sample mean&quot;, col=&quot;green&quot;, lwd=2); lines(density(meanvalues4), xlab=&quot;sample mean&quot;, col=&quot;blue&quot;, lwd=2); legend(6,15,legend = c(&quot;n=10&quot;,&quot;n=30&quot;,&quot;n=100&quot;,&quot;n=1000&quot;), lwd=2, col=c(&quot;black&quot;,&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;)) 9.11 Confidence interval First decide what confidece interval you want. Suppose lets say you want to estimate the 95% confidence interval for mean sepal length of iris dataset. So 95% interval means, middle area around mean is 95%. So remaining upper and lower tail area would be 2.5% each i.e. 0.025 (Lower 2.5%, Upper 2.5% so that total = 5%). Estimate the zscore for 0.025 using qnorm function. Or to estimate the upper tail one can use (0.025+0.95 = 0.975). Since there are two tails of the normal distribution, the 95% confidence level would imply the 97.5th percentile of the normal distribution at the upper tail. q95 = qnorm(p = 0.025); # Lower tail print(q95); ## [1] -1.959964 q95 = qnorm(p = 0.025); # Upper tail print(q95); ## [1] -1.959964 Now estimate standard error for sepal length sl = iris$Sepal.Length; sl_stderror = sd(sl)/sqrt(length(sl)); print(sl_stderror); ## [1] 0.06761132 Now estimate confidence interval (mean +/- z* * SE) z* * SE is called margin of error. conf_low = mean(sl) + q95 * sl_stderror; print(conf_low); ## [1] 5.710818 conf_high = mean(sl) - q95 * sl_stderror; print(conf_high); ## [1] 5.975849 So we are 95% confident that population mean of sepal length will lie between 5.71 and 5.95. 9.12 Hypothesis test for single sample mean Consider sepal length from IRIS dataset. Lets assume that its a sample of 150 flowers whose sepal length is measured. However the actual population must be larger than 150 flower. From this sample of 150 flowers estimate the sample mean. Objective is to compare this sample mean w.r.t some population mean and ask the question whether the sample mean is different/greater/less than the population mean. If answer comes its really different/greater/less, then how much confident/sure we are. We will proceed slowly. For now, first estimate sample mean. sl = iris$Sepal.Length; mean(sl); ## [1] 5.843333 So sample mean estimated is 5.84; Lets ask the question whether mean sepal length of iris flowers are different than 6 or not? Null hypo: sample mean = 6 Alternate hypo: sample mean not equal to 6 Such hypothesis testing is called two-tailed. Lets do a t-test with two tailed. tres= t.test(x = sl, mu = 6, alternative = &quot;two.sided&quot;); print(tres); ## ## One Sample t-test ## ## data: sl ## t = -2.3172, df = 149, p-value = 0.02186 ## alternative hypothesis: true mean is not equal to 6 ## 95 percent confidence interval: ## 5.709732 5.976934 ## sample estimates: ## mean of x ## 5.843333 Lets analyze the results. How do u get t-statistics value as -2.31 ? t = (x - population mean)/ standard error of mean Lets calculate one by one mean_sl = mean(sl); # sample mean of sepal length sd_sl = sd(sl); # sample standard deviation n_sl = length(sl); # sample size se_sl = sd_sl/sqrt(n_sl); # standard error of sample mean tstat = (mean_sl - 6)/se_sl; # t statistics for which hypothesis testing is to be performed print(tstat); ## [1] -2.317166 So we saw that test statistics is -2.31 Degree of freedom df is n-1 i.e. 149 Now lets estimate 95% confidence interval of sample mean zstar= qnorm(0.975); me_sl = zstar*se_sl; # margin of error at 95% conf interval conf_low = mean_sl - me_sl; conf_high = mean_sl + me_sl; print(c(conf_low, conf_high)); ## [1] 5.710818 5.975849 Now lets estimate pvalue. Its the probability of observing a value &gt; test statistics since we are using t-test, we can call pt function. pval = 2* pt(q = tstat, df = n_sl-1); # Why multiplying with 2? Its 2 tail print(pval); ## [1] 0.02185662 So this pval is &lt; 0.05, we reject null hypothesis and state that there is strong evidence exist to support the fact that the sample mean of sepal length is significantly different than 6 9.13 One tailed test (Greater) Null: sample mean = 6 Alternative : sample mean &gt; 6 tres= t.test(x = sl, mu = 6, alternative = &quot;greater&quot;); print(tres); ## ## One Sample t-test ## ## data: sl ## t = -2.3172, df = 149, p-value = 0.9891 ## alternative hypothesis: true mean is greater than 6 ## 95 percent confidence interval: ## 5.731427 Inf ## sample estimates: ## mean of x ## 5.843333 test statistics is -2.3172 as calculated above Confidence interval has no upper limit What is probability of observing values &gt; -2.3172 with 149 degree of freedom? pt(q = tstat, df = n_sl-1, lower.tail = FALSE) ## [1] 0.9890717 Here we didnot multiply with 2 since we are performing one tailed test. pval observed was 0.98 which is &gt; 0.05 so we cant reject null hypothesis. i.e. there is no substantial evidence exist by which we can claim that sample mean of sepal length is &gt; 6. 9.14 One tailed test (Lesser) Null: sample mean = 6 Alternative : sample mean &lt; 6 tres= t.test(x = sl, mu = 6, alternative = &quot;less&quot;); print(tres); ## ## One Sample t-test ## ## data: sl ## t = -2.3172, df = 149, p-value = 0.01093 ## alternative hypothesis: true mean is less than 6 ## 95 percent confidence interval: ## -Inf 5.95524 ## sample estimates: ## mean of x ## 5.843333 test statistics is -2.3172 as calculated above Confidence interval has no lower limit What is probability of observing values &lt; -2.3172 with 149 degree of freedom? pt(q = tstat, df = n_sl-1, lower.tail = TRUE) ## [1] 0.01092831 Here we didnot multiply with 2 since we are performing one tailed test. pval observed was 0.01 which is &lt; 0.05 so we can reject null hypothesis saying that we have substantial evidence to claim that sample mean of sepal length is &lt; 6. 9.15 Hypothesis test for two sample mean, unpaired Using this test we can compare two samples and perform 3 possible tests Whether sample means of the two samples are same or not. Whether sample1 mean is &gt; sample2 mean or not? Whether sample1 mean is &lt; sample2 mean or not? In this case we assume that two samples are not paired. So sample sizes may vary. However we assume that Both samples are from a normally distributed population. Observations are independent. Samples are with uniform variability. Lets take an example from IRIS dataset. We have 3 flowers, setosa versicolor virginica, each 50 flowers. Our task is to check whether mean sepal length of these three flowers differ among them or not? sl_setosa = iris[iris$Species==&quot;setosa&quot;, &quot;Sepal.Length&quot;]; sl_versicolor = iris[iris$Species==&quot;versicolor&quot;, &quot;Sepal.Length&quot;]; sl_virginica = iris[iris$Species==&quot;virginica&quot;, &quot;Sepal.Length&quot;]; Now lets check whether sample mean of setosa and versicolor are different or not? t.test(x = sl_setosa, y = sl_versicolor) ## ## Welch Two Sample t-test ## ## data: sl_setosa and sl_versicolor ## t = -10.521, df = 86.538, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -1.1057074 -0.7542926 ## sample estimates: ## mean of x mean of y ## 5.006 5.936 Now lets look at the output one by one Lets estimate mean of x and mean of y and cross check with the output. mean(sl_setosa); ## [1] 5.006 mean(sl_versicolor); ## [1] 5.936 Now calculate test statistics which is equal to difference of mean tstat = mean(sl_setosa) - mean(sl_versicolor); print(tstat); ## [1] -0.93 9.16 Hypothesis test for two sample mean, paired 9.17 Check for normality 9.18 Check for uniform variance 9.19 Hypothesis test for single sample proportion "],
["regression.html", "Chapter 10 Regression 10.1 Simple linear Regression 10.2 Multiple Linear Regression", " Chapter 10 Regression 10.1 Simple linear Regression 10.1.1 Build model head(faithful); ## eruptions waiting ## 1 3.600 79 ## 2 1.800 54 ## 3 3.333 74 ## 4 2.283 62 ## 5 4.533 85 ## 6 2.883 55 eruption.lm = lm(eruptions~waiting, data = faithful); print(eruption.lm); ## ## Call: ## lm(formula = eruptions ~ waiting, data = faithful) ## ## Coefficients: ## (Intercept) waiting ## -1.87402 0.07563 Now that we have built the linear model, we also have established the relationship between the predictor and response in the form of a mathematical formula for eruptions as a function for waiting time. For the above output, you can notice the ‘Coefficients’ part having two components: Intercept: -1.87402, waiting: 0.07563. These are also called the beta coefficients. In other words, eruptions = Intercept + (β ∗ waiting) eruptions = −1.87402 + 0.07563∗ waiting 10.1.2 Obtain model summary (Linear Regression Diagnostics) # Obtain model summary eruption.lm.summary = summary(eruption.lm) eruption.lm.summary; ## ## Call: ## lm(formula = eruptions ~ waiting, data = faithful) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.29917 -0.37689 0.03508 0.34909 1.19329 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.874016 0.160143 -11.70 &lt;2e-16 *** ## waiting 0.075628 0.002219 34.09 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4965 on 270 degrees of freedom ## Multiple R-squared: 0.8115, Adjusted R-squared: 0.8108 ## F-statistic: 1162 on 1 and 270 DF, p-value: &lt; 2.2e-16 Now the linear model is built and we have a formula that we can use to predict the dist value if a corresponding speed is known. Is this enough to actually use this model? NO! Before using a regression model, you have to ensure that it is statistically significant. How do you ensure this? We need to understand the following parameters model coefficients Statistical significance of overrall model (model p value) Statistical significance of individual coefficients (p value of coefficients) t statistics or test statistics Residuals and Standard residuals R-squared and Adjusted R-squared Residual standard error AIC and BIC Use the model to predict new dataset We will explore these one by one 10.1.3 Model coefficients # From the result fetch coefficients coeffs = eruption.lm$coefficients; coeffs ## (Intercept) waiting ## -1.87401599 0.07562795 # Use coefficients function coeffs = coefficients(eruption.lm); coeffs ## (Intercept) waiting ## -1.87401599 0.07562795 10.1.4 Model significance and Coefficient significance The summary statistics above tells us a number of things. One of them is the model p-Value (bottom last line) and the p-Value of individual predictor variables (extreme right column under ‘Coefficients’). p-Values are very important because, We can consider a linear model to be statistically significant only when both these p-Values are less that the pre-determined statistical significance level, which is ideally 0.05. This is visually interpreted by the significance stars at the end of the row. The more the stars beside the variable’s p-Value, the more significant the variable. Null and alternate hypothesis : In Linear Regression, the Null Hypothesis is that the coefficients associated with the variables is equal to zero. The alternate hypothesis is that the coefficients are not equal to zero (i.e. there exists a relationship between the independent variable in question and the dependent variable). Check pvalue and based on significance level (e.g. 0.05) decide whether to reject null hypothesis or not. If p value is &lt; significance level (e.g. 0.05), we can say that there is a strong evidence exist to reject the null hypothesis and we are 95% confident about this. You can see that p value of model is 2.2e-16 which is &lt; 0.05 so we can reject null hypothesis (beta coefficients are zero i.e. slope is 0 i.e. no relation between X and Y i.e. no relation between explanatory and dependent variable). Hence there is a significant relationship between the variables in the linear regression model of the data set faithful. t-value We can interpret the t-value something like this. A larger t-value indicates that it is less likely that the coefficient is not equal to zero purely by chance. So, higher the t-value, the better. Pr(&gt;|t|) or p-value is the probability that you get a t-value as high or higher than the observed value when the Null Hypothesis (the β coefficient is equal to zero or that there is no relationship) is true. So if the Pr(&gt;|t|) is low, the coefficients are significant (significantly different from zero). If the Pr(&gt;|t|) is high, the coefficients are not significant. It is absolutely important for the model to be statistically significant before we can go ahead and use it to predict (or estimate) the dependent variable, otherwise, the confidence in predicted values from that model reduces and may be construed as an event of chance. 10.1.5 Coefficient of Determination or R-squared The actual information in a data is the total variation it contains. What R-Squared/coefficient of determination tells us is the proportion of variation in the dependent (response) variable that has been explained by this model. Higher the value, better is the model fit to data. We don’t necessarily discard a model based on a low R-Squared value. Its a better practice to look at the AIC and prediction accuracy on validation sample when deciding on the efficacy of a model. eruption.lm.summary = summary(eruption.lm); str(eruption.lm.summary); ## List of 11 ## $ call : language lm(formula = eruptions ~ waiting, data = faithful) ## $ terms :Classes &#39;terms&#39;, &#39;formula&#39; language eruptions ~ waiting ## .. ..- attr(*, &quot;variables&quot;)= language list(eruptions, waiting) ## .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1 ## .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. ..$ : chr [1:2] &quot;eruptions&quot; &quot;waiting&quot; ## .. .. .. ..$ : chr &quot;waiting&quot; ## .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;waiting&quot; ## .. ..- attr(*, &quot;order&quot;)= int 1 ## .. ..- attr(*, &quot;intercept&quot;)= int 1 ## .. ..- attr(*, &quot;response&quot;)= int 1 ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; ## .. ..- attr(*, &quot;predvars&quot;)= language list(eruptions, waiting) ## .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot; ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;eruptions&quot; &quot;waiting&quot; ## $ residuals : Named num [1:272] -0.5006 -0.4099 -0.3895 -0.5319 -0.0214 ... ## ..- attr(*, &quot;names&quot;)= chr [1:272] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ coefficients : num [1:2, 1:4] -1.87402 0.07563 0.16014 0.00222 -11.70212 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;waiting&quot; ## .. ..$ : chr [1:4] &quot;Estimate&quot; &quot;Std. Error&quot; &quot;t value&quot; &quot;Pr(&gt;|t|)&quot; ## $ aliased : Named logi [1:2] FALSE FALSE ## ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;(Intercept)&quot; &quot;waiting&quot; ## $ sigma : num 0.497 ## $ df : int [1:3] 2 270 2 ## $ r.squared : num 0.811 ## $ adj.r.squared: num 0.811 ## $ fstatistic : Named num [1:3] 1162 1 270 ## ..- attr(*, &quot;names&quot;)= chr [1:3] &quot;value&quot; &quot;numdf&quot; &quot;dendf&quot; ## $ cov.unscaled : num [1:2, 1:2] 0.10403 -0.00142 -0.00142 0.00002 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;waiting&quot; ## .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;waiting&quot; ## - attr(*, &quot;class&quot;)= chr &quot;summary.lm&quot; print(eruption.lm.summary$r.squared); ## [1] 0.8114608 Now thats about R-Squared. What about adjusted R-Squared? As you add more X variables to your model, the R-Squared value of the new bigger model will always be greater than that of the smaller subset. This is because, since all the variables in the original model is also present, their contribution to explain the dependent variable will be present in the super-set as well, therefore, whatever new variable we add can only add (if not significantly) to the variation that was already explained. It is here, the adjusted R-Squared value comes to help. Adj R-Squared penalizes total value for the number of terms (read predictors) in your model. Therefore when comparing nested models, it is a good practice to look at adj-R-squared value over R-squared. In this example since we had only one explanatory variable i.e. waiting, both R-squared and adjusted R-squared value remains same. 10.1.6 Standard Error and F-Statistic Both standard errors and F-statistic are measures of goodness of fit. Standard error should be low (Closer to 0 is better) and higher F-statistics is better. eruption.lm.summary; ## ## Call: ## lm(formula = eruptions ~ waiting, data = faithful) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.29917 -0.37689 0.03508 0.34909 1.19329 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.874016 0.160143 -11.70 &lt;2e-16 *** ## waiting 0.075628 0.002219 34.09 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4965 on 270 degrees of freedom ## Multiple R-squared: 0.8115, Adjusted R-squared: 0.8108 ## F-statistic: 1162 on 1 and 270 DF, p-value: &lt; 2.2e-16 eruption.lm.summary$fstatistic; ## value numdf dendf ## 1162.063 1.000 270.000 Here numdf is numerator degree of freedom [number of variables - 1]. We have two variables, eruptions and waiting. So numdf = 2-1 i.e. 1 dendf is denominator degree of freedom which is number of observations - number of variables. dim(faithful) says 272 observations. So 272-number of variables i.e. 272-2 = 270. 10.1.7 AIC and BIC The Akaike’s information criterion - AIC (Akaike, 1974) and the Bayesian information criterion - BIC (Schwarz, 1978) are measures of the goodness of fit of an estimated statistical model and can also be used for model selection. For model comparison, the model with the lowest AIC and BIC score is preferred. AIC(object = eruption.lm); ## [1] 395.0159 BIC(object = eruption.lm); ## [1] 405.8333 10.1.8 Residuals and Residual plot Residual is the difference between observed and predicted value of y. # Obtain residual using model object head(eruption.lm$residuals); ## 1 2 3 4 5 6 ## -0.50059190 -0.40989320 -0.38945216 -0.53191679 -0.02135959 0.59747885 # Obtain residual using function head(resid(eruption.lm)) ## 1 2 3 4 5 6 ## -0.50059190 -0.40989320 -0.38945216 -0.53191679 -0.02135959 0.59747885 Residual plot X = faithful$waiting; Y = resid(eruption.lm); plot(X,Y, xlab=&quot;Waiting Time&quot;, ylab=&quot;Residuals&quot;); abline(0,0); It can be seen that there are much difference between observed and predicted value. Standardized Residual The standardized residual is the residual divided by its standard deviation. rstd = rstandard(eruption.lm) head(rstd); ## 1 2 3 4 5 6 ## -1.01073883 -0.82944175 -0.78589633 -1.07413200 -0.04318464 1.20863241 X = faithful$waiting; Y = rstd; plot(X,Y, xlab=&quot;Waiting Time&quot;, ylab=&quot;Standardized Residual&quot;); abline(0,0); Normal Probability Plot of Residuals Check whether the residuals show normal distribution or not? qqnorm(rstd, ylab=&quot;Standardized Residuals&quot;, xlab=&quot;Normal Scores&quot;, main=&quot;Old Faithful Eruptions (QQ plot)&quot;) qqline(rstd) Correlation between observed and predicted Y (Model fitness) Ypred = resid(eruption.lm); Ytrue = faithful$eruptions; # Correlation testing cor.test(Ytrue, Ypred); ## ## Pearson&#39;s product-moment correlation ## ## data: Ytrue and Ypred ## t = 7.9204, df = 270, p-value = 6.204e-14 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.3324440 0.5259831 ## sample estimates: ## cor ## 0.4342111 Correlation: 0.43 suggesting positive correlation Pvalue &lt; 0.05 suggesting significant association Correlation plot plot(Ytrue, Ypred, xlab=&quot;True Eruption&quot;, ylab=&quot;Predicted Eruption&quot;); 10.1.9 How to know if the model is best fit for your data? source: http://r-statistics.co/Linear-Regression.html 10.1.10 Lets predict a new dataset using the built model testdata = data.frame(waiting=80); testdata; ## waiting ## 1 80 predict(object = eruption.lm, newdata = testdata) ## 1 ## 4.17622 # Lets manually predict based on coefficients print(coeffs) ## (Intercept) waiting ## -1.87401599 0.07562795 coeffs[1] + coeffs[2]*testdata[1,1]; # intercept + slope * x ## (Intercept) ## 4.17622 Confidence Interval and Prediction interval for Linear Regression Assume that the error term ϵ in the simple linear regression model is independent of x, and is normally distributed, with zero mean and constant variance. For a given value of x, the interval estimate of the dependent variable y is called the prediction interval. For a given value of x, the interval estimate for the mean of the dependent variable, ¯y , is called the confidence interval. Using the testdataset, predict the 95% prediction interval of the eruption and 95% confidence interval for mean eruption, for the waiting time 80. testdata; ## waiting ## 1 80 # The 95% confidence interval of the mean eruption duration for the waiting time of 80 minutes is between 4.1048 and 4.2476 minutes. predict(object = eruption.lm, newdata = testdata, interval = &quot;confidence&quot;); ## fit lwr upr ## 1 4.17622 4.104848 4.247592 #The 95% prediction interval of the eruption duration for the waiting time of 80 minutes is between 3.1961 and 5.1564 minutes. predict(object = eruption.lm, newdata = testdata, interval = &quot;prediction&quot;); ## fit lwr upr ## 1 4.17622 3.196089 5.156351 10.2 Multiple Linear Regression A multiple linear regression (MLR) model describes a dependent variable y by independent variables x1, x2, …, xp (p &gt; 1). Lets consider stackloss dataset desribing observations from a chemical plant operation. stackloss is a data frame with 21 observations on 4 variables. Air Flow Flow of cooling air Water Temp Cooling Water Inlet Temperature Acid Conc. Concentration of acid [per 1000, minus 500] stack.loss Stack loss “Obtained from 21 days of operation of a plant for the oxidation of ammonia (NH3) to nitric acid (HNO3). The nitric oxides produced are absorbed in a countercurrent absorption tower”. For details type ?stackloss head(stackloss); ## Air.Flow Water.Temp Acid.Conc. stack.loss ## 1 80 27 89 42 ## 2 80 27 88 37 ## 3 75 25 90 37 ## 4 62 24 87 28 ## 5 62 22 87 18 ## 6 62 23 87 18 10.2.1 Build multiple regression model In this model we try to predict stack loss (y) using x (air flow, water temp and acid conc). Lets change the column labels. colnames(stackloss) = c(&quot;Airflow&quot;,&quot;Watertemp&quot;,&quot;Acidconc&quot;,&quot;Stackloss&quot;) head(stackloss); ## Airflow Watertemp Acidconc Stackloss ## 1 80 27 89 42 ## 2 80 27 88 37 ## 3 75 25 90 37 ## 4 62 24 87 28 ## 5 62 22 87 18 ## 6 62 23 87 18 stackloss.lm = lm(Stackloss ~ Airflow + Watertemp + Acidconc, data=stackloss); stackloss.lm; ## ## Call: ## lm(formula = Stackloss ~ Airflow + Watertemp + Acidconc, data = stackloss) ## ## Coefficients: ## (Intercept) Airflow Watertemp Acidconc ## -39.9197 0.7156 1.2953 -0.1521 We have now 4 coefficients. Intercept Airflow Watertemp Acidconc Lets summarise the model summary(stackloss.lm); ## ## Call: ## lm(formula = Stackloss ~ Airflow + Watertemp + Acidconc, data = stackloss) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.2377 -1.7117 -0.4551 2.3614 5.6978 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -39.9197 11.8960 -3.356 0.00375 ** ## Airflow 0.7156 0.1349 5.307 5.8e-05 *** ## Watertemp 1.2953 0.3680 3.520 0.00263 ** ## Acidconc -0.1521 0.1563 -0.973 0.34405 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.243 on 17 degrees of freedom ## Multiple R-squared: 0.9136, Adjusted R-squared: 0.8983 ## F-statistic: 59.9 on 3 and 17 DF, p-value: 3.016e-09 Model significance Model pvalue observed is 3.016e-09. So model is significant at 0.05 significance level. so we are 95% confident that prediction of Y from X is significant i.e. there is definitely some degree of association exists between Y and X. Coefficients significance Intercept pvalue is 0.00375 (&lt; 0.05) so significant ** Airflow pvalue 5.8e-05 (&lt; 0.001) so highly significant *** Watertemp pvalue 0.00263 (, 0.05) so significant ** Acidconc pvalue 0.34405 (&gt; 0.05) so not significant So except Acidconc, we can say with 95% confidence that for other variables like Airflow and Watertemp, some degree of association with Stackloss exists. R-squared Multiple R-squared: 0.9136 means the regression model explains 91% of data variation. However since multiple X variables are involved, we should look at adjusted R-squared values (0.8983) Residual standard error 3.243 on 17 degree of freedom. This may not be useful for a single model, however we can use this to compare the model with other alternative models. Use model to predict test dataset testdata = data.frame(Airflow=72, Watertemp=20, Acidconc=85) testdata_result = predict(object = stackloss.lm, testdata); testdata_result; ## 1 ## 24.58173 Measure 95% confidence interval testdata_result = predict(object = stackloss.lm, testdata, interval=&quot;confidence&quot;); testdata_result; ## fit lwr upr ## 1 24.58173 20.21846 28.945 So we are 95% confident that the mean stackloss will be between 20.21 to 28.94 Measure 95% prediction interval testdata_result = predict(object = stackloss.lm, testdata, interval=&quot;prediction&quot;); testdata_result; ## fit lwr upr ## 1 24.58173 16.4661 32.69736 So we are 95% confident that the predicted stackloss will be between 16.46 to 32.69 "],
["clustering.html", "Chapter 11 Clustering 11.1 Data preparation 11.2 Clustering 11.3 K-means clustering 11.4 Determining The Optimal Number Of Clusters", " Chapter 11 Clustering 11.1 Data preparation 11.1.1 Load library library(dplyr) library(data.table) library(&quot;factoextra&quot;) 11.1.2 Load TCGA data df = fread(&quot;./data/stat/BRCA_TCGA_exp.tsv&quot;, header=T) %&gt;% data.frame() dim(df); ## [1] 413 49 # Genes in columns and samples in rows print(df[1:3,1:5]); ## Sample UBE2T BIRC5 NUF2 CDC6 ## 1 TCGA-5T-A9QA-01 1.9323 0.2744 1.7735 1.3728 ## 2 TCGA-A1-A0SE-01 0.7931 -0.1335 -0.0023 -0.1102 ## 3 TCGA-A1-A0SH-01 -0.6785 -0.4435 -0.9456 -0.7541 rownames(df) = df$Sample; df$Sample = NULL; dim(df); ## [1] 413 48 print(df[1:3,1:5]); ## UBE2T BIRC5 NUF2 CDC6 CCNB1 ## TCGA-5T-A9QA-01 1.9323 0.2744 1.7735 1.3728 0.1060 ## TCGA-A1-A0SE-01 0.7931 -0.1335 -0.0023 -0.1102 0.1857 ## TCGA-A1-A0SH-01 -0.6785 -0.4435 -0.9456 -0.7541 -0.8197 11.1.3 Vizualize data boxplot(df, main= &quot;Before scaling&quot;, las=2, cex.axis=0.7, ylab=&quot;Expression Values&quot;) 11.1.4 Data preparation To perform a cluster analysis in R, generally, the data should be prepared as follow: Rows are observations (individuals) and columns are variables Any missing value in the data must be removed or estimated. The data must be standardized (i.e., scaled) to make variables comparable. 11.1.5 Check for NA # Number of missing values print(sum(is.na(df))) ## [1] 0 # Either replace NA with 0 or ignore the variable #df[is.na(df)] = 0 #df &lt;- na.omit(df) 11.1.6 Scale the data dim(df) ## [1] 413 48 df = scale(df); dim(df) ## [1] 413 48 11.1.7 Vizualize data after scaling boxplot(df, main= &quot;After scaling&quot;, las=2, cex.axis=0.7, ylab=&quot;Expression Values&quot;) 11.2 Clustering We can use 2 clustering approach Partitional clustering (or partitioning clustering) K-means clustering K-medoids clustering or PAM (Partitioning Around Medoids) CLARA algorithm Hierarchical Clustering Agglomerative clustering Divise clustering 11.3 K-means clustering set.seed(123) # nstart: The number of random starting partitions when centers is a number. Trying nstart &gt; 1 is often recommended. # iter.max: The maximum number of iterations allowed. Default value is 10. # centers = number of clusters km.res &lt;- kmeans(df, centers = 3, nstart = 25) str(km.res) ## List of 9 ## $ cluster : Named int [1:413] 2 1 1 2 2 3 1 3 3 2 ... ## ..- attr(*, &quot;names&quot;)= chr [1:413] &quot;TCGA-5T-A9QA-01&quot; &quot;TCGA-A1-A0SE-01&quot; &quot;TCGA-A1-A0SH-01&quot; &quot;TCGA-A1-A0SJ-01&quot; ... ## $ centers : num [1:3, 1:48] -0.538 0.447 1.225 -0.504 0.374 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:3] &quot;1&quot; &quot;2&quot; &quot;3&quot; ## .. ..$ : chr [1:48] &quot;UBE2T&quot; &quot;BIRC5&quot; &quot;NUF2&quot; &quot;CDC6&quot; ... ## $ totss : num 19776 ## $ withinss : num [1:3] 4812 4503 4855 ## $ tot.withinss: num 14169 ## $ betweenss : num 5607 ## $ size : int [1:3] 238 111 64 ## $ iter : int 3 ## $ ifault : int 0 ## - attr(*, &quot;class&quot;)= chr &quot;kmeans&quot; 11.3.1 Visualizing k-means clusters in 2D space It is a good idea to plot the cluster results. These can be used to assess the choice of the number of clusters as well as comparing two different cluster analyses. The problem is that the data contains more than 2 variables and the question is what variables to choose for the xy scatter plot. A solution is to reduce the number of dimensions by applying a dimensionality reduction algorithm, such as Principal Component Analysis (PCA), that operates on the four variables and outputs two new variables (that represent the original variables) that you can use to do the plot. In other words, if we have a multi-dimensional data set, a solution is to perform Principal Component Analysis (PCA) and to plot data points according to the first two principal components coordinates. fviz_cluster(km.res, df,ellipse.type = &quot;norm&quot;) 11.3.2 Get details of clusters # A vector of integers (from 1:k) indicating the cluster to which each point is allocated km.res$cluster %&gt;% head() ## TCGA-5T-A9QA-01 TCGA-A1-A0SE-01 TCGA-A1-A0SH-01 TCGA-A1-A0SJ-01 ## 2 1 1 2 ## TCGA-A1-A0SM-01 TCGA-A1-A0SO-01 ## 2 3 # Cluster centres vector # A matrix of cluster centers (cluster means) km.res$centers ## UBE2T BIRC5 NUF2 CDC6 CCNB1 TYMS ## 1 -0.5381358 -0.5037394 -0.4172786 -0.3643092 -0.5582258 -0.3818445 ## 2 0.4474144 0.3736463 0.1707142 0.6855249 0.5665286 0.1184049 ## 3 1.2252081 1.2252380 1.2556722 0.1658175 1.0933293 1.2146258 ## MYBL2 CEP55 MELK NDC80 RRM2 UBE2C ## 1 -0.5166326 -0.5067061 -0.5694512 -0.5061323 -0.5454494 -0.4828338 ## 2 0.4287505 0.3259956 0.3733934 0.1962653 0.7845567 0.2895321 ## 3 1.1776132 1.3189147 1.4700425 1.5417818 0.6676745 1.2933809 ## CENPF PTTG1 EXO1 ANLN CCNE1 CDC20 ## 1 -0.4730242 -0.4992177 -0.5387736 -0.4657973 -0.26076434 -0.51243416 ## 2 0.3295429 0.2618704 0.3440448 0.2841369 -0.03185303 0.09069983 ## 3 1.1875077 1.4022845 1.4068616 1.2393838 1.02496246 1.74830699 ## MKI67 KIF2C ACTR3B EGFR KRT5 PHGDH ## 1 -0.5067970 -0.5753623 -0.2885008 -0.1060590 -0.1054281 -0.22132843 ## 2 0.4517616 0.2775719 -0.1881744 0.0803030 -0.2263553 -0.06734312 ## 3 1.1011272 1.6582150 1.3992272 0.2551312 0.7846457 0.93986333 ## CDH3 MIA KRT17 FOXC1 SFRP1 KRT14 ## 1 -0.2867862 -0.1752148 -0.1274771 -0.3133222 -0.1307482 -0.06439213 ## 2 -0.2459070 -0.2189368 -0.2488694 -0.3266296 -0.3521362 -0.18777396 ## 3 1.4929813 1.0312986 0.9056883 1.7316653 1.0969563 0.56512870 ## ESR1 SLC39A6 BAG1 MAPT PGR CXXC5 ## 1 0.3138789 0.2513056 0.1273421 0.3932007 0.2378463 0.2295830 ## 2 -0.1451685 -0.1603125 -0.1360777 -0.3421107 -0.2318286 0.1080276 ## 3 -0.9154603 -0.6565007 -0.2375439 -0.8688669 -0.4824130 -1.0411221 ## MLPH BCL2 MDM2 NAT1 FOXA1 BLVRA ## 1 0.3479332 0.3957708 0.04951648 0.2553808 0.3347050 0.008023586 ## 2 -0.1189275 -0.3565101 0.17520655 -0.1495978 0.1577757 0.385061933 ## 3 -1.0876118 -0.8534503 -0.48801326 -0.6902389 -1.5183265 -0.697679500 ## MMP11 GPR160 FGFR4 GRB7 TMEM45B ERBB2 ## 1 -0.07289671 0.09997528 -0.2184167 -0.1917350 0.05079603 -0.1981701 ## 2 0.35666940 0.43998710 0.6111470 0.4866052 0.18998569 0.5583575 ## 3 -0.34751384 -1.13488569 -0.2477209 -0.1309415 -0.51840419 -0.2314563 # withinness of each cluster # withinss: Vector of within-cluster sum of squares, one component per cluster km.res$withinss ## [1] 4811.568 4502.683 4855.162 # Total withinness # tot.withinss: Total within-cluster sum of squares, i.e. sum(withinss) km.res$tot.withinss ## [1] 14169.41 sum(km.res$withinss) ## [1] 14169.41 # Cluster size # size: The number of observations in each cluster km.res$size ## [1] 238 111 64 # Betweenness # betweenss: The between-cluster sum of squares, i.e. totss−tot.withinss km.res$betweenss ## [1] 5606.587 #The total sum of squares (TSS). TSS measures the total variance in the data. km.res$totss ## [1] 19776 11.4 Determining The Optimal Number Of Clusters Determining the optimal number of clusters in a data set is a fundamental issue in partitioning clustering, such as k-means clustering, which requires the user to specify the number of clusters k to be generated. Unfortunately, there is no definitive answer to this question. The optimal number of clusters is somehow subjective and depends on the method used for measuring similarities and the parameters used for partitioning These methods include direct methods and statistical testing methods: Direct methods: consists of optimizing a criterion, such as the within cluster sums of squares or the average silhouette. The corresponding methods are named elbow and silhouette methods, respectively. Statistical testing methods: consists of comparing evidence against null hypothesis. An example is the gap statistic. In addition to elbow, silhouette and gap statistic methods, there are more than thirty other indices and methods that have been published for identifying the optimal number of clusters. 11.4.1 Elbow method Basic idea behind partitioning methods, such as k-means clustering, is to define clusters such that the total intra-cluster variation [or total within-cluster sum of square (WSS)] is minimized. The total WSS measures the compactness of the clustering and we want it to be as small as possible. Elbow method looks at the total WSS as a function of the number of clusters: One should choose a number of clusters so that adding another cluster doesn’t improve much better the total WSS. The optimal number of clusters can be defined as follow: Compute clustering algorithm (e.g., k-means clustering) for different values of k. For instance, by varying k from 1 to 10 clusters. For each k, calculate the total within-cluster sum of square (wss). Plot the curve of wss according to the number of clusters k. The location of a bend (knee) in the plot is generally considered as an indicator of the appropriate number of clusters. Note that, the elbow method is sometimes ambiguous. An alternative is the average silhouette method (Kaufman and Rousseeuw [1990]) which can be also used with any clustering approach. # method = c(&quot;silhouette&quot;, &quot;wss&quot;, &quot;gap_stat&quot;) # FUNcluster = kmeans, cluster::pam, cluster::clara, cluster::fanny, hcut fviz_nbclust(df, FUNcluster = kmeans, method = &quot;wss&quot;) + geom_vline(xintercept = 3, linetype = 2) 11.4.2 Average silhouette method The average silhouette approach measures the quality of a clustering. That is, it determines how well each object lies within its cluster. A high average silhouette width indicates a good clustering. Average silhouette method computes the average silhouette of observations for different values of k. The optimal number of clusters k is the one that maximize the average silhouette over a range of possible values for k (Kaufman and Rousseeuw 1990). Steps - Compute clustering algorithm (e.g., k-means clustering) for different values of k. For instance, by varying k from 1 to 10 clusters. - For each k, calculate the average silhouette of observations (avg.sil). - Plot the curve of avg.sil according to the number of clusters k. - The location of the maximum is considered as the appropriate number of clusters. fviz_nbclust(df, kmeans, method = &quot;silhouette&quot;)+ labs(subtitle = &quot;Silhouette method&quot;) 11.4.3 Gap statistic method The gap statistic has been published by R. Tibshirani, G. Walther, and T. Hastie (Standford University, 2001). The gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e, that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points. Note that, using B = 500 gives quite precise results so that the gap plot is basically unchanged after an another run. Steps Cluster the observed data, varying the number of clusters from k = 1, …, kmax, and compute the corresponding total within intra-cluster variation Wk. Generate B reference data sets with a random uniform distribution. Cluster each of these reference data sets with varying number of clusters k = 1, …, kmax, and compute the corresponding total within intra-cluster variation Wkb. Compute the estimated gap statistic as the deviation of the observed Wk value from its expected value Wkb under the null hypothesis: Gap(k)=1B∑b=1Blog(W∗kb)−log(Wk) Compute also the standard deviation of the statistics. Choose the number of clusters as the smallest value of k such that the gap statistic is within one standard deviation of the gap at k+1: Gap(k)≥Gap(k + 1)−sk + 1. # Gap statistic # nboot = 50 to keep the function speedy. # recommended value: nboot= 500 for your analysis. # Use verbose = FALSE to hide computing progression. set.seed(123) fviz_nbclust(df, kmeans, nstart = 25, method = &quot;gap_stat&quot;, nboot = 5)+ labs(subtitle = &quot;Gap statistic method&quot;) 11.4.4 NbClust() function: 30 indices for choosing the best number of clusters 30 indices for choosing the best number of clusters library(NbClust) # NbClust(data = NULL, diss = NULL, distance = &quot;euclidean&quot;,min.nc = 2, max.nc = 15, method = NULL) #data: matrix #diss: dissimilarity matrix to be used. By default, diss=NULL, but if it is replaced by a dissimilarity matrix, distance should be “NULL” #distance: the distance measure to be used to compute the dissimilarity matrix. Possible values include “euclidean”, “manhattan” or “NULL”. #min.nc, max.nc: minimal and maximal number of clusters, respectively #method: The cluster analysis method to be used including “ward.D”, “ward.D2”, “single”, “complete”, “average”, “kmeans” and more. To compute NbClust() for hierarchical clustering, method should be one of c(“ward.D”, “ward.D2”, “single”, “complete”, “average”). nbc = NbClust(data = df, diss = NULL, distance = &quot;euclidean&quot;,min.nc = 2, max.nc = 15, method = &quot;kmeans&quot;) ## *** : The Hubert index is a graphical method of determining the number of clusters. ## In the plot of Hubert index, we seek a significant knee that corresponds to a ## significant increase of the value of the measure i.e the significant peak in Hubert ## index second differences plot. ## ## *** : The D index is a graphical method of determining the number of clusters. ## In the plot of D index, we seek a significant knee (the significant peak in Dindex ## second differences plot) that corresponds to a significant increase of the value of ## the measure. ## ## ******************************************************************* ## * Among all indices: ## * 12 proposed 2 as the best number of clusters ## * 8 proposed 3 as the best number of clusters ## * 1 proposed 4 as the best number of clusters ## * 1 proposed 7 as the best number of clusters ## * 1 proposed 10 as the best number of clusters ## * 1 proposed 15 as the best number of clusters ## ## ***** Conclusion ***** ## ## * According to the majority rule, the best number of clusters is 2 ## ## ## ******************************************************************* "],
["pca.html", "Chapter 12 PCA 12.1 About Principal Component Analysis (PCA 12.2 Data preparation 12.3 Perform PCA 12.4 Visualization and Interpretation 12.5 Eigenvalues / Variances / Number of PCs to consider 12.6 Graph of variables 12.7 Correlation circle 12.8 Quality of representation 12.9 Referece", " Chapter 12 PCA 12.1 About Principal Component Analysis (PCA The central idea of principal component analysis (PCA) is to reduce the dimensionality of a data set consisting of a large number of interrelated variables, while retaining as much as possible of the variation present in the data set. This is achieved by transforming to a new set of variables, the principal components (PCs), which are uncorrelated ordered so that the first few retain most of the variation present in all of the original variables. To begin with PCA analysis our data must be in 2 dimensional form (data frame or matrix) where individuals or observations are represented in rows while variables or features are represented in columns. It is important to note that for PCA to work well, there must be some degree of correlation among variables. In that case PCA will try to detect such correlated variables and reduce the dimension by giving you new set of variables that are not correlated to each other. These new variables correspond to a linear combination of the originals. In simple term, PCA reduces the dimesnion by identifying correlated variables and giving you a new set of uncorrelated variables (Princical components). PCA method is particularly useful when the variables within the data set are highly correlated Lets begin with analysis by taking gene expression dataset from TCGA dataset for breast cancer. 12.2 Data preparation library(dplyr) library(data.table) library(&quot;factoextra&quot;) 12.2.1 Load Gene expression data from TCGA Breast cancer df = fread(&quot;./data/stat/BRCA_TCGA_exp.tsv&quot;, header=T) %&gt;% data.frame() dim(df); ## [1] 413 49 # Genes in columns and samples in rows print(df[1:3,1:5]); ## Sample UBE2T BIRC5 NUF2 CDC6 ## 1 TCGA-5T-A9QA-01 1.9323 0.2744 1.7735 1.3728 ## 2 TCGA-A1-A0SE-01 0.7931 -0.1335 -0.0023 -0.1102 ## 3 TCGA-A1-A0SH-01 -0.6785 -0.4435 -0.9456 -0.7541 rownames(df) = df$Sample; df$Sample = NULL; dim(df); ## [1] 413 48 print(df[1:3,1:5]); ## UBE2T BIRC5 NUF2 CDC6 CCNB1 ## TCGA-5T-A9QA-01 1.9323 0.2744 1.7735 1.3728 0.1060 ## TCGA-A1-A0SE-01 0.7931 -0.1335 -0.0023 -0.1102 0.1857 ## TCGA-A1-A0SH-01 -0.6785 -0.4435 -0.9456 -0.7541 -0.8197 12.2.2 Data standardization In principal component analysis, variables are often scaled (i.e. standardized). This is particularly recommended when variables are measured in different scales (e.g: kilograms, kilometers, centimeters, …); otherwise, the PCA outputs obtained will be severely affected. The goal is to make the variables comparable. Generally variables are scaled to have i) standard deviation one and ii) mean zero. The standardization of data is an approach widely used in the context of gene expression data analysis before PCA and clustering analysis. We might also want to scale the data when the mean and/or the standard deviation of variables are largely different. When scaling variables, the data can be transformed as follow: xi−mean(x)/sd(x) Where mean(x) is the mean of x values, and sd(x) is the standard deviation (SD). The R base function scale() can be used to standardize the data. It takes a numeric matrix as an input and performs the scaling on the columns. Note that, by default, the function PCA() [in FactoMineR], standardizes the data automatically during the PCA; so you don’t need do this transformation before the PCA. 12.3 Perform PCA library(&quot;FactoMineR&quot;) res.pca &lt;- PCA(df, graph = FALSE); print(res.pca); ## **Results for the Principal Component Analysis (PCA)** ## The analysis was performed on 413 individuals, described by 48 variables ## *The results are available in the following objects: ## ## name description ## 1 &quot;$eig&quot; &quot;eigenvalues&quot; ## 2 &quot;$var&quot; &quot;results for the variables&quot; ## 3 &quot;$var$coord&quot; &quot;coord. for the variables&quot; ## 4 &quot;$var$cor&quot; &quot;correlations variables - dimensions&quot; ## 5 &quot;$var$cos2&quot; &quot;cos2 for the variables&quot; ## 6 &quot;$var$contrib&quot; &quot;contributions of the variables&quot; ## 7 &quot;$ind&quot; &quot;results for the individuals&quot; ## 8 &quot;$ind$coord&quot; &quot;coord. for the individuals&quot; ## 9 &quot;$ind$cos2&quot; &quot;cos2 for the individuals&quot; ## 10 &quot;$ind$contrib&quot; &quot;contributions of the individuals&quot; ## 11 &quot;$call&quot; &quot;summary statistics&quot; ## 12 &quot;$call$centre&quot; &quot;mean of the variables&quot; ## 13 &quot;$call$ecart.type&quot; &quot;standard error of the variables&quot; ## 14 &quot;$call$row.w&quot; &quot;weights for the individuals&quot; ## 15 &quot;$call$col.w&quot; &quot;weights for the variables&quot; 12.4 Visualization and Interpretation We’ll use the factoextra R package to help in the interpretation of PCA. No matter what function you decide to use [stats::prcomp(), FactoMiner::PCA(), ade4::dudi.pca(), ExPosition::epPCA()], you can easily extract and visualize the results of PCA using R functions provided in the factoextra R package. These functions include: get_eigenvalue(res.pca): Extract the eigenvalues/variances of principal components fviz_eig(res.pca): Visualize the eigenvalues get_pca_ind(res.pca), get_pca_var(res.pca): Extract the results for individuals and variables, respectively. fviz_pca_ind(res.pca), fviz_pca_var(res.pca): Visualize the results individuals and variables, respectively. fviz_pca_biplot(res.pca): Make a biplot of individuals and variables. 12.5 Eigenvalues / Variances / Number of PCs to consider library(&quot;factoextra&quot;) eig.val &lt;- get_eigenvalue(res.pca) eig.val ## eigenvalue variance.percent cumulative.variance.percent ## Dim.1 14.14791842 29.4748300 29.47483 ## Dim.2 3.94971231 8.2285673 37.70340 ## Dim.3 3.14962824 6.5617255 44.26512 ## Dim.4 1.94797974 4.0582911 48.32341 ## Dim.5 1.72929760 3.6027033 51.92612 ## Dim.6 1.44630087 3.0131268 54.93924 ## Dim.7 1.39375810 2.9036627 57.84291 ## Dim.8 1.23543483 2.5738226 60.41673 ## Dim.9 1.18112455 2.4606761 62.87741 ## Dim.10 1.14208359 2.3793408 65.25675 ## Dim.11 1.04262060 2.1721263 67.42887 ## Dim.12 0.96778667 2.0162222 69.44509 ## Dim.13 0.89097953 1.8562074 71.30130 ## Dim.14 0.84246903 1.7551438 73.05645 ## Dim.15 0.82614443 1.7211342 74.77758 ## Dim.16 0.77973076 1.6244391 76.40202 ## Dim.17 0.74045143 1.5426071 77.94463 ## Dim.18 0.69874753 1.4557240 79.40035 ## Dim.19 0.64832720 1.3506817 80.75103 ## Dim.20 0.62876820 1.3099337 82.06097 ## Dim.21 0.59805408 1.2459460 83.30691 ## Dim.22 0.56207691 1.1709936 84.47791 ## Dim.23 0.55446717 1.1551399 85.63305 ## Dim.24 0.54943762 1.1446617 86.77771 ## Dim.25 0.50047278 1.0426516 87.82036 ## Dim.26 0.46999305 0.9791522 88.79951 ## Dim.27 0.44726751 0.9318073 89.73132 ## Dim.28 0.44451805 0.9260793 90.65740 ## Dim.29 0.41449796 0.8635374 91.52093 ## Dim.30 0.38835714 0.8090774 92.33001 ## Dim.31 0.37813713 0.7877857 93.11780 ## Dim.32 0.34982619 0.7288046 93.84660 ## Dim.33 0.33271124 0.6931484 94.53975 ## Dim.34 0.30820183 0.6420872 95.18184 ## Dim.35 0.28832408 0.6006752 95.78251 ## Dim.36 0.26472387 0.5515081 96.33402 ## Dim.37 0.23075267 0.4807347 96.81476 ## Dim.38 0.22028177 0.4589204 97.27368 ## Dim.39 0.20299552 0.4229073 97.69658 ## Dim.40 0.18797839 0.3916216 98.08821 ## Dim.41 0.16527540 0.3443237 98.43253 ## Dim.42 0.14317163 0.2982742 98.73080 ## Dim.43 0.14014861 0.2919763 99.02278 ## Dim.44 0.11948342 0.2489238 99.27170 ## Dim.45 0.11157799 0.2324541 99.50416 ## Dim.46 0.09824474 0.2046765 99.70883 ## Dim.47 0.08201146 0.1708572 99.87969 ## Dim.48 0.05774817 0.1203087 100.00000 PC1 explains 29.47% variation in the data while PC2 explains 8.22% variation. Together they explain 37.70% of variation Eigenvalues can be used to determine the number of principal components to retain after PCA An eigenvalue &gt; 1 indicates that PCs account for more variance than accounted by one of the original variables in standardized data. This is commonly used as a cutoff point for which PCs are retained. This holds true only when the data are standardized. You can also limit the number of component to that number that accounts for a certain fraction of the total variance. For example, if you are satisfied with 70% of the total variance explained then use the number of components to achieve that. Unfortunately, there is no well-accepted objective way to decide how many principal components are enough. This will depend on the specific field of application and the specific data set. In practice, we tend to look at the first few principal components in order to find interesting patterns in the data. An alternative method to determine the number of principal components is to look at a Scree Plot, which is the plot of eigenvalues ordered from largest to the smallest. The number of component is determined at the point, beyond which the remaining eigenvalues are all relatively small and of comparable size (Jollife 2002, Peres-Neto, Jackson, and Somers (2005)). The scree plot can be produced using the function fviz_eig() or fviz_screeplot() [factoextra package]. fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 40)) 12.6 Graph of variables A simple method to extract the results, for variables, from a PCA output is to use the function get_pca_var() [factoextra package]. This function provides a list of matrices containing all the results for the active variables (coordinates, correlation between variables and axes, squared cosine and contributions) var &lt;- get_pca_var(res.pca) var ## Principal Component Analysis Results for variables ## =================================================== ## Name Description ## 1 &quot;$coord&quot; &quot;Coordinates for the variables&quot; ## 2 &quot;$cor&quot; &quot;Correlations between variables and dimensions&quot; ## 3 &quot;$cos2&quot; &quot;Cos2 for the variables&quot; ## 4 &quot;$contrib&quot; &quot;contributions of the variables&quot; The components of the get_pca_var() can be used in the plot of variables as follow: var$coord: coordinates of variables to create a scatter plot var$cos2: represents the quality of representation for variables on the factor map. It’s calculated as the squared coordinates: var.cos2 = var.coord * var.coord. var$contrib: contains the contributions (in percentage) of the variables to the principal components. The contribution of a variable (var) to a given principal component is (in percentage) : (var.cos2 * 100) / (total cos2 of the component). We can plot variables on factor map using var\\(coord and colour them using either var\\)cos2(Quality) or var$contrib (contribution) # Coordinates head(var$coord) ## Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 ## UBE2T 0.7253340 0.2277836 0.05089143 0.1303429090 -0.02312285 ## BIRC5 0.7207480 0.1672497 0.06828535 0.3021446496 -0.22747635 ## NUF2 0.6668279 0.1828370 0.18492054 0.0002209955 0.08668259 ## CDC6 0.3065962 0.3628674 -0.42996927 -0.0201999332 0.27329481 ## CCNB1 0.7365610 0.3673432 0.05506443 0.2036965058 0.08426123 ## TYMS 0.6756032 0.1873181 0.15157941 -0.0439218609 -0.05554614 # Cos2: quality on the factore map head(var$cos2) ## Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 ## UBE2T 0.52610945 0.05188535 0.002589938 1.698927e-02 0.0005346662 ## BIRC5 0.51947763 0.02797247 0.004662889 9.129139e-02 0.0517454883 ## NUF2 0.44465946 0.03342935 0.034195607 4.883902e-08 0.0075138715 ## CDC6 0.09400125 0.13167275 0.184873574 4.080373e-04 0.0746900536 ## CCNB1 0.54252209 0.13494102 0.003032091 4.149227e-02 0.0070999541 ## TYMS 0.45643969 0.03508808 0.022976319 1.929130e-03 0.0030853732 # Contributions to the principal components head(var$contrib) ## Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 ## UBE2T 3.7186350 1.3136487 0.08222996 8.721484e-01 0.03091811 ## BIRC5 3.6717602 0.7082153 0.14804569 4.686465e+00 2.99228359 ## NUF2 3.1429320 0.8463743 1.08570296 2.507162e-06 0.43450425 ## CDC6 0.6644176 3.3337302 5.86969509 2.094669e-02 4.31909774 ## CCNB1 3.8346425 3.4164771 0.09626822 2.130015e+00 0.41056866 ## TYMS 3.2261968 0.8883706 0.72949304 9.903234e-02 0.17841771 Lets plot variables 12.7 Correlation circle head(var$coord, 4) ## Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 ## UBE2T 0.7253340 0.2277836 0.05089143 0.1303429090 -0.02312285 ## BIRC5 0.7207480 0.1672497 0.06828535 0.3021446496 -0.22747635 ## NUF2 0.6668279 0.1828370 0.18492054 0.0002209955 0.08668259 ## CDC6 0.3065962 0.3628674 -0.42996927 -0.0201999332 0.27329481 # To plot variables, type this: fviz_pca_var(res.pca, col.var = &quot;black&quot;) The plot above is also known as variable correlation plots. It shows the relationships between all variables. It can be interpreted as follow: Positively correlated variables are grouped together. Negatively correlated variables are positioned on opposite sides of the plot origin (opposed quadrants). The distance between variables and the origin measures the quality of the variables on the factor map. Variables that are away from the origin are well represented on the factor map. 12.8 Quality of representation The quality of representation of the variables on factor map is called cos2 (square cosine, squared coordinates) . You can access to the cos2 as follow: head(var$cos2, 4) ## Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 ## UBE2T 0.52610945 0.05188535 0.002589938 1.698927e-02 0.0005346662 ## BIRC5 0.51947763 0.02797247 0.004662889 9.129139e-02 0.0517454883 ## NUF2 0.44465946 0.03342935 0.034195607 4.883902e-08 0.0075138715 ## CDC6 0.09400125 0.13167275 0.184873574 4.080373e-04 0.0746900536 You can visualize the cos2 of variables on all the dimensions using the corrplot package: library(&quot;corrplot&quot;) ## corrplot 0.84 loaded corrplot(t(var$cos2), is.corr=FALSE) It’s also possible to create a bar plot of variables cos2 using the function fviz_cos2()[in factoextra]: # Total cos2 of variables on Dim.1 and Dim.2 fviz_cos2(res.pca, choice = &quot;var&quot;, axes = 1:2) Note that, A high cos2 indicates a good representation of the variable on the principal component. In this case the variable is positioned close to the circumference of the correlation circle. A low cos2 indicates that the variable is not perfectly represented by the PCs. In this case the variable is close to the center of the circle. For a given variable, the sum of the cos2 on all the principal components is equal to one. The cos2 values are used to estimate the quality of the representation The closer a variable is to the circle of correlations, the better its representation on the factor map (and the more important it is to interpret these components) Variables that are closed to the center of the plot are less important for the first components. It’s possible to color variables by their cos2 values using the argument col.var = “cos2”. This produces a gradient colors. In this case, the argument gradient.cols can be used to provide a custom color. For instance, gradient.cols = c(“white”, “blue”, “red”) means that: variables with low cos2 values will be colored in “white” variables with mid cos2 values will be colored in “blue” variables with high cos2 values will be colored in red # Color by cos2 values: quality on the factor map fviz_pca_var(res.pca, col.var = &quot;cos2&quot;, gradient.cols = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), repel = TRUE # Avoid text overlapping ) 12.9 Referece Jollife, I.T. 2002. Principal Component Analysis. 2nd ed. New York: Springer-Verlag. https://goo.gl/SB86SR. "],
["network-analysis.html", "Chapter 13 Network analysis 13.1 Data processing 13.2 Convert data frame to graph 13.3 Node and Edge details 13.4 Plot Parameters 13.5 Network layouts 13.6 Network and node descriptives 13.7 Centrality &amp; centralization 13.8 Hubs and authorities 13.9 Distances and paths 13.10 Cliques 13.11 Community detection 13.12 Interative network", " Chapter 13 Network analysis 13.1 Data processing 13.1.1 Load iGraph Library library(igraph) 13.1.2 Load data df = read.table(&quot;./data/stat/networkdata.tsv&quot;, header = T) head(df) ## node1 node2 ## 1 POX1 FAA2 ## 2 FAA1 POX1 ## 3 TGL3 YJU3 ## 4 TGL4 YJU3 ## 5 TGL3 TGL4 ## 6 FAA4 POX1 13.2 Convert data frame to graph g = graph_from_data_frame(df) # Plot graph plot(g) # We can specify directed = T/F parameter if it is a directed/undirected graph respectively # Default is directed graph # Undirected graph g1 = graph_from_data_frame(df, directed = F); plot(g1) # Print graph print(g) ## IGRAPH c7d8800 DN-- 11 32 -- ## + attr: name (v/c) ## + edges from c7d8800 (vertex names): ## [1] POX1-&gt;FAA2 FAA1-&gt;POX1 TGL3-&gt;YJU3 TGL4-&gt;YJU3 TGL3-&gt;TGL4 FAA4-&gt;POX1 ## [7] POX1-&gt;FAT1 FAA1-&gt;FAT1 FAA4-&gt;FAS1 FAA1-&gt;FAS1 FAA4-&gt;FAT1 FAS1-&gt;FAA2 ## [13] FAA4-&gt;OLE1 FAA1-&gt;FAA4 FAA1-&gt;OLE1 FAA2-&gt;FAT1 FAA1-&gt;TGL4 TGL3-&gt;FAA4 ## [19] FAA1-&gt;TGL3 FAS1-&gt;OLE1 FAA1-&gt;YJU3 YJU3-&gt;FAA2 FAA4-&gt;YJU3 POX1-&gt;OLE1 ## [25] FAA4-&gt;INA1 FAA1-&gt;FAA2 FAA4-&gt;FAA2 FAA4-&gt;TGL4 OLE1-&gt;FAA2 TGL3-&gt;FAT1 ## [31] TGL4-&gt;FAA2 TGL3-&gt;FAA2 # DN-B # The description of an igraph object starts with up to four letters: # D or U, for a directed or undirected graph # N for a named graph (where nodes have a name attribute) # W for a weighted graph (where edges have a weight attribute) # B for a bipartite (two-mode) graph (where nodes have a type attribute) # The description also lists node &amp; edge attributes, for example: # (g/c) - graph-level character attribute # (v/c) - vertex-level character attribute # (e/n) - edge-level numeric attribute 13.3 Node and Edge details # Get nodes V(g) ## + 11/11 vertices, named, from c7d8800: ## [1] POX1 FAA1 TGL3 TGL4 FAA4 FAS1 FAA2 YJU3 OLE1 FAT1 INA1 # Total nodes vcount(g) ## [1] 11 # Get vertices name V(g)$name ## [1] &quot;POX1&quot; &quot;FAA1&quot; &quot;TGL3&quot; &quot;TGL4&quot; &quot;FAA4&quot; &quot;FAS1&quot; &quot;FAA2&quot; &quot;YJU3&quot; &quot;OLE1&quot; &quot;FAT1&quot; ## [11] &quot;INA1&quot; # Get edges E(g) ## + 32/32 edges from c7d8800 (vertex names): ## [1] POX1-&gt;FAA2 FAA1-&gt;POX1 TGL3-&gt;YJU3 TGL4-&gt;YJU3 TGL3-&gt;TGL4 FAA4-&gt;POX1 ## [7] POX1-&gt;FAT1 FAA1-&gt;FAT1 FAA4-&gt;FAS1 FAA1-&gt;FAS1 FAA4-&gt;FAT1 FAS1-&gt;FAA2 ## [13] FAA4-&gt;OLE1 FAA1-&gt;FAA4 FAA1-&gt;OLE1 FAA2-&gt;FAT1 FAA1-&gt;TGL4 TGL3-&gt;FAA4 ## [19] FAA1-&gt;TGL3 FAS1-&gt;OLE1 FAA1-&gt;YJU3 YJU3-&gt;FAA2 FAA4-&gt;YJU3 POX1-&gt;OLE1 ## [25] FAA4-&gt;INA1 FAA1-&gt;FAA2 FAA4-&gt;FAA2 FAA4-&gt;TGL4 OLE1-&gt;FAA2 TGL3-&gt;FAT1 ## [31] TGL4-&gt;FAA2 TGL3-&gt;FAA2 # Edge count ecount(g) ## [1] 32 # Network matrix g[] ## 11 x 11 sparse Matrix of class &quot;dgCMatrix&quot; ## [[ suppressing 11 column names &#39;POX1&#39;, &#39;FAA1&#39;, &#39;TGL3&#39; ... ]] ## ## POX1 . . . . . . 1 . 1 1 . ## FAA1 1 . 1 1 1 1 1 1 1 1 . ## TGL3 . . . 1 1 . 1 1 . 1 . ## TGL4 . . . . . . 1 1 . . . ## FAA4 1 . . 1 . 1 1 1 1 1 1 ## FAS1 . . . . . . 1 . 1 . . ## FAA2 . . . . . . . . . 1 . ## YJU3 . . . . . . 1 . . . . ## OLE1 . . . . . . 1 . . . . ## FAT1 . . . . . . . . . . . ## INA1 . . . . . . . . . . . 13.4 Plot Parameters # Vertexx param # vertex.color Node color # vertex.frame.color Node border color # vertex.shape One of “none”, “circle”, “square”, “csquare”, “rectangle”, “crectangle”, “vrectangle”, “pie”, “raster”, or “sphere” # vertex.size Size of the node (default is 15) # vertex.size2 The second size of the node (e.g. for a rectangle) # vertex.label Character vector used to label the nodes # vertex.label.family Font family of the label (e.g.“Times”, “Helvetica”) # vertex.label.font Font: 1 plain, 2 bold, 3, italic, 4 bold italic, 5 symbol # vertex.label.cex Font size (multiplication factor, device-dependent) # vertex.label.dist Distance between the label and the vertex # vertex.label.degree The position of the label in relation to the vertex,where 0 right, “pi” is left, “pi/2” is below, and “-pi/2” is above # edge.color Edge color # edge.width Edge width, defaults to 1 # edge.arrow.size Arrow size, defaults to 1 # edge.arrow.width Arrow width, defaults to 1 # edge.lty Line type, could be 0 or “blank”, 1 or “solid”, 2 or “dashed”,3 or “dotted”, 4 or “dotdash”, 5 or “longdash”, 6 or “twodash” # edge.label Character vector used to label edges # edge.label.family Font family of the label (e.g.“Times”, “Helvetica”) # edge.label.font Font: 1 plain, 2 bold, 3, italic, 4 bold italic, 5 symbol # edge.label.cex Font size for edge labels # edge.curved Edge curvature, range 0-1 (FALSE sets it to 0, TRUE to 0.5) # arrow.mode Vector specifying whether edges should have arrows, # possible values: 0 no arrow, 1 back, 2 forward, 3 both plot(g, edge.arrow.size=0.1, vertex.color=&quot;gold&quot;, vertex.size=20,vertex.frame.color=&quot;gray&quot;,vertex.label.color=&quot;black&quot;,vertex.label.cex=0.8,vertex.label.dist=3,edge.curved=0.2) # Add property # Color the vertices veccol = c(rep(&quot;pink&quot;,5), rep(&quot;light blue&quot;,6)) plot(g,edge.arrow.size=0.1, vertex.color=veccol, vertex.size=20,vertex.frame.color=&quot;gray&quot;,vertex.label.color=&quot;black&quot;,vertex.label.cex=0.8,vertex.label.dist=3,edge.curved=0.2) # Node size V(g)$size = sample(c(30:50),11, replace = T) plot(g,edge.arrow.size=0.1, vertex.color=veccol, vertex.size=V(g)$size,vertex.frame.color=&quot;gray&quot;,vertex.label.color=&quot;black&quot;,vertex.label.cex=0.8,vertex.label.dist=3,edge.curved=0.2) 13.5 Network layouts plot(g, layout=layout_randomly,edge.arrow.size=0.1, vertex.color=veccol, vertex.size=20,vertex.frame.color=&quot;gray&quot;,vertex.label.color=&quot;black&quot;,vertex.label.cex=0.8,vertex.label.dist=3,edge.curved=0.2) plot(g, layout=layout_as_star,edge.arrow.size=0.1, vertex.color=veccol, vertex.size=20,vertex.frame.color=&quot;gray&quot;,vertex.label.color=&quot;black&quot;,vertex.label.cex=0.8,vertex.label.dist=3,edge.curved=0.2) plot(g, layout=layout_as_tree,edge.arrow.size=0.1, vertex.color=veccol, vertex.size=20,vertex.frame.color=&quot;gray&quot;,vertex.label.color=&quot;black&quot;,vertex.label.cex=0.8,vertex.label.dist=3,edge.curved=0.2) plot(g, layout=layout_in_circle,edge.arrow.size=0.1, vertex.color=veccol, vertex.size=20,vertex.frame.color=&quot;gray&quot;,vertex.label.color=&quot;black&quot;,vertex.label.cex=0.8,vertex.label.dist=3,edge.curved=0.2) plot(g, layout=layout_on_sphere,edge.arrow.size=0.1, vertex.color=veccol, vertex.size=20,vertex.frame.color=&quot;gray&quot;,vertex.label.color=&quot;black&quot;,vertex.label.cex=0.8,vertex.label.dist=3,edge.curved=0.2) plot(g, layout=layout_on_grid,edge.arrow.size=0.1, vertex.color=veccol, vertex.size=20,vertex.frame.color=&quot;gray&quot;,vertex.label.color=&quot;black&quot;,vertex.label.cex=0.8,vertex.label.dist=3,edge.curved=0.2) # Force-directed layouts plot(g, layout=layout_with_fr,edge.arrow.size=0.1, vertex.color=veccol, vertex.size=20,vertex.frame.color=&quot;gray&quot;,vertex.label.color=&quot;black&quot;,vertex.label.cex=0.8,vertex.label.dist=3,edge.curved=0.2) # Another popular force-directed algorithm that produces nice results for connected graphs is Kamada Kawai plot(g, layout=layout_with_kk,edge.arrow.size=0.1, vertex.color=veccol, vertex.size=20,vertex.frame.color=&quot;gray&quot;,vertex.label.color=&quot;black&quot;,vertex.label.cex=0.8,vertex.label.dist=3,edge.curved=0.2) # On single plot layouts &lt;- grep(&quot;^layout_&quot;, ls(&quot;package:igraph&quot;), value=TRUE)[-1] layouts &lt;- layouts[!grepl(&quot;bipartite|merge|norm|sugiyama|tree&quot;, layouts)] par(mfrow=c(3,3), mar=c(1,1,1,1)) for (layout in layouts) { print(layout) l &lt;- do.call(layout, list(g)) plot(g, edge.arrow.mode=0, layout=l, main=layout) } ## [1] &quot;layout_as_star&quot; ## [1] &quot;layout_components&quot; ## [1] &quot;layout_in_circle&quot; ## [1] &quot;layout_nicely&quot; ## [1] &quot;layout_on_grid&quot; ## [1] &quot;layout_on_sphere&quot; ## [1] &quot;layout_randomly&quot; ## [1] &quot;layout_with_dh&quot; ## [1] &quot;layout_with_drl&quot; ## [1] &quot;layout_with_fr&quot; ## [1] &quot;layout_with_gem&quot; ## [1] &quot;layout_with_graphopt&quot; ## [1] &quot;layout_with_kk&quot; ## [1] &quot;layout_with_lgl&quot; ## [1] &quot;layout_with_mds&quot; par(mfrow=c(1,1)) 13.6 Network and node descriptives 13.6.1 Edge density The proportion of present edges from all possible edges in the network. net = g; edge_density(net, loops=F) ## [1] 0.2909091 edge_density(net, loops=T) ## [1] 0.2644628 ecount(net)/(vcount(net)*(vcount(net)-1)) ## [1] 0.2909091 13.6.2 Diameter A network diameter is the longest geodesic distance (length of the shortest path between two nodes) in the network. In igraph, diameter() returns the distance, while get_diameter() returns the nodes along the first found path of that distance. diameter(net, directed=F, weights=NA) ## [1] 2 diameter(net, directed=F) ## [1] 2 diam &lt;- get_diameter(net, directed=T) diam ## + 3/11 vertices, named, from c7d8800: ## [1] FAA1 FAA4 INA1 # Color nodes along the diameter: vcol &lt;- rep(&quot;gray40&quot;, vcount(net)) vcol[diam] &lt;- &quot;gold&quot; ecol &lt;- rep(&quot;gray80&quot;, ecount(net)) ecol[E(net, path=diam)] &lt;- &quot;orange&quot; plot(net, vertex.color=vcol, edge.color=ecol, edge.arrow.mode=0) ### Node degrees The function degree() has a mode of in for in-degree, out for out-degree, and all or total for total degree deg &lt;- degree(net, mode=&quot;all&quot;) print(sort(deg)) ## INA1 FAS1 POX1 TGL4 YJU3 OLE1 FAT1 TGL3 FAA1 FAA2 FAA4 ## 1 4 5 5 5 5 5 6 9 9 10 plot(net, vertex.size=deg*3) hist(deg, breaks=1:vcount(net)-1, main=&quot;Histogram of node degree&quot;) 13.7 Centrality &amp; centralization Centrality applies to node level while Centralization applies to graph level 13.7.1 Degree centrality # mode: in/out/all or total degree(net, mode=&quot;in&quot;) ## POX1 FAA1 TGL3 TGL4 FAA4 FAS1 FAA2 YJU3 OLE1 FAT1 INA1 ## 2 0 1 3 2 2 8 4 4 5 1 # Returns res - vertex centrality, centralization, and theoretical_max - maximum centralization score for a graph of that size. centr_degree(net, mode=&quot;in&quot;, normalized=T) ## $res ## [1] 2 0 1 3 2 2 8 4 4 5 1 ## ## $centralization ## [1] 0.5090909 ## ## $theoretical_max ## [1] 110 13.7.2 Closeness centrality based on distance to others in the graph. Inverse of the node’s average geodesic distance to others in the network. closeness(net, mode=&quot;all&quot;, weights=NA) ## POX1 FAA1 TGL3 TGL4 FAA4 FAS1 ## 0.06666667 0.09090909 0.07142857 0.06666667 0.10000000 0.06250000 ## FAA2 YJU3 OLE1 FAT1 INA1 ## 0.09090909 0.06666667 0.06666667 0.06666667 0.05263158 centr_clo(net, mode=&quot;all&quot;, normalized=T) ## $res ## [1] 0.6666667 0.9090909 0.7142857 0.6666667 1.0000000 0.6250000 0.9090909 ## [8] 0.6666667 0.6666667 0.6666667 0.5263158 ## ## $centralization ## [1] 0.6297198 ## ## $theoretical_max ## [1] 4.736842 13.7.3 Betweenness Centrality based on a broker position connecting others. Number of geodesics that pass through the node or the edge. The vertex and edge betweenness are (roughly) defined by the number of geodesics (shortest paths) going through a vertex or an edge. betweenness(net, directed=T, weights=NA) ## POX1 FAA1 TGL3 TGL4 FAA4 FAS1 FAA2 YJU3 OLE1 FAT1 INA1 ## 0 0 0 0 5 0 4 0 0 0 0 edge_betweenness(net, directed=T, weights=NA) ## [1] 1 1 1 1 1 2 1 1 2 1 1 2 2 2 1 5 1 5 1 1 1 2 1 1 3 1 1 1 2 1 2 1 centr_betw(net, directed=T, normalized=T) ## $res ## [1] 0 0 0 0 5 0 4 0 0 0 0 ## ## $centralization ## [1] 0.05111111 ## ## $theoretical_max ## [1] 900 13.8 Hubs and authorities Hubs: large number of outgoing links Authorities would get many incoming links from hubs hs &lt;- hub_score(net, weights=NA)$vector as &lt;- authority_score(net, weights=NA)$vector par(mfrow=c(1,2)) plot(net, vertex.size=hs*50, main=&quot;Hubs&quot;, edge.arrow.size=0.1, vertex.color=veccol, vertex.frame.color=&quot;gray&quot;,vertex.label.color=&quot;black&quot;,vertex.label.cex=0.8,vertex.label.dist=3,edge.curved=0.2) plot(net, vertex.size=as*30, main=&quot;Authorities&quot;,,edge.arrow.size=0.1, vertex.color=veccol,vertex.frame.color=&quot;gray&quot;,vertex.label.color=&quot;black&quot;,vertex.label.cex=0.8,vertex.label.dist=3,edge.curved=0.2) 13.9 Distances and paths # Average path length # Mean of the shortest distance between each pair of nodes in the network mean_distance(net, directed=F) ## [1] 1.418182 mean_distance(net, directed=T) ## [1] 1.219512 # We can also find the length of all shortest paths in the graph: distances(net) ## POX1 FAA1 TGL3 TGL4 FAA4 FAS1 FAA2 YJU3 OLE1 FAT1 INA1 ## POX1 0 1 2 2 1 2 1 2 1 1 2 ## FAA1 1 0 1 1 1 1 1 1 1 1 2 ## TGL3 2 1 0 1 1 2 1 1 2 1 2 ## TGL4 2 1 1 0 1 2 1 1 2 2 2 ## FAA4 1 1 1 1 0 1 1 1 1 1 1 ## FAS1 2 1 2 2 1 0 1 2 1 2 2 ## FAA2 1 1 1 1 1 1 0 1 1 1 2 ## YJU3 2 1 1 1 1 2 1 0 2 2 2 ## OLE1 1 1 2 2 1 1 1 2 0 2 2 ## FAT1 1 1 1 2 1 2 1 2 2 0 2 ## INA1 2 2 2 2 1 2 2 2 2 2 0 # Extract the distances to a node or set of nodes we are interested in distances(net, v = c(&#39;POX1&#39;,&#39;FAA1&#39;), to = c(&#39;TGL3&#39;,&#39;TGL4&#39;)) ## TGL3 TGL4 ## POX1 2 2 ## FAA1 1 1 # Find the shortest path between specific nodes. shortest_paths(net, from = &quot;POX1&quot;, to = &quot;TGL4&quot;, output = &quot;both&quot;) ## Warning in shortest_paths(net, from = &quot;POX1&quot;, to = &quot;TGL4&quot;, output = ## &quot;both&quot;): At structural_properties.c:745 :Couldn&#39;t reach some vertices ## $vpath ## $vpath[[1]] ## + 0/11 vertices, named, from c7d8800: ## ## ## $epath ## $epath[[1]] ## + 0/32 edges from c7d8800 (vertex names): ## ## ## $predecessors ## NULL ## ## $inbound_edges ## NULL # Identify the edges going into or out of a vertex incident(net,v = &quot;OLE1&quot;,mode = &#39;in&#39;) ## + 4/32 edges from c7d8800 (vertex names): ## [1] POX1-&gt;OLE1 FAA1-&gt;OLE1 FAA4-&gt;OLE1 FAS1-&gt;OLE1 incident(net,v = &quot;OLE1&quot;,mode = &#39;out&#39;) ## + 1/32 edge from c7d8800 (vertex names): ## [1] OLE1-&gt;FAA2 incident(net,v = &quot;OLE1&quot;,mode = &#39;all&#39;) ## + 5/32 edges from c7d8800 (vertex names): ## [1] OLE1-&gt;FAA2 POX1-&gt;OLE1 FAA1-&gt;OLE1 FAA4-&gt;OLE1 FAS1-&gt;OLE1 # For a single node, use incident(), for multiple nodes use incident_edges() incident_edges(net, v=c(&quot;OLE1&quot;,&quot;FAA4&quot;), mode=&quot;in&quot;); ## $OLE1 ## + 4/32 edges from c7d8800 (vertex names): ## [1] POX1-&gt;OLE1 FAA1-&gt;OLE1 FAA4-&gt;OLE1 FAS1-&gt;OLE1 ## ## $FAA4 ## + 2/32 edges from c7d8800 (vertex names): ## [1] FAA1-&gt;FAA4 TGL3-&gt;FAA4 # immediate neighbors of a vertex neighbors(net,v = &quot;OLE1&quot;) ## + 1/11 vertex, named, from c7d8800: ## [1] FAA2 13.10 Cliques # Find cliques (complete subgraphs of an undirected graph) net.sym &lt;- as.undirected(net, mode= &quot;collapse&quot;) head(cliques(net.sym)) # list of cliques ## [[1]] ## + 1/11 vertex, named, from 22214eb: ## [1] FAA4 ## ## [[2]] ## + 1/11 vertex, named, from 22214eb: ## [1] FAA2 ## ## [[3]] ## + 2/11 vertices, named, from 22214eb: ## [1] FAA4 FAA2 ## ## [[4]] ## + 1/11 vertex, named, from 22214eb: ## [1] INA1 ## ## [[5]] ## + 2/11 vertices, named, from 22214eb: ## [1] FAA4 INA1 ## ## [[6]] ## + 1/11 vertex, named, from 22214eb: ## [1] FAA1 sapply(cliques(net.sym), length) # clique sizes ## [1] 1 1 2 1 2 1 2 3 2 1 2 3 4 3 2 3 2 1 2 3 4 3 2 3 2 1 2 3 4 5 4 3 4 3 2 ## [36] 3 4 3 2 3 2 1 2 3 4 5 4 3 4 3 2 3 4 3 2 3 2 1 2 3 4 5 4 3 4 3 2 3 4 3 ## [71] 2 3 2 1 2 3 4 5 6 5 4 5 4 3 4 5 4 3 4 3 2 3 4 5 4 3 4 3 2 3 4 3 2 3 2 ## [106] 1 2 3 4 5 4 3 4 3 2 3 4 5 4 3 4 3 2 3 4 3 2 3 2 largest_cliques(net.sym) # cliques with max number of nodes ## [[1]] ## + 6/11 vertices, named, from 22214eb: ## [1] FAA4 FAA1 FAA2 TGL3 TGL4 YJU3 # plot vcol &lt;- rep(&quot;grey80&quot;, vcount(net.sym)) vcol[unlist(largest_cliques(net.sym))] &lt;- &quot;gold&quot; plot(as.undirected(net.sym), vertex.label=V(net.sym)$name, vertex.color=vcol) 13.11 Community detection A number of algorithms aim to detect groups that consist of densely connected nodes with fewer connections across groups. #Community detection based on edge betweenness (Newman-Girvan) # High-betweenness edges are removed sequentially (recalculating at each step) and the best partitioning of the network is selected. ceb &lt;- cluster_edge_betweenness(net) plot(ceb, net) # Community detection based on based on propagating labels # Assigns node labels, randomizes, than replaces each vertex’s label with the label that appears most frequently among neighbors. Those steps are repeated until each vertex has the most common label of its neighbors. clp &lt;- cluster_label_prop(net) plot(clp, net) #Community detection based on greedy optimization of modularity cfg &lt;- cluster_fast_greedy(as.undirected(net)) plot(cfg, as.undirected(net)) #We can also plot the communities without relying on their built-in plot: V(net)$community &lt;- cfg$membership colrs &lt;- adjustcolor( c(&quot;gray50&quot;, &quot;tomato&quot;, &quot;gold&quot;, &quot;yellowgreen&quot;), alpha=.6) plot(net, vertex.color=colrs[V(net)$community]) 13.12 Interative network library(visNetwork) library(networkD3) nodes = data.frame(id = V(g)$name) nodes$label = nodes$id edges = data.frame(get.edgelist(g)) colnames(edges) = c(&#39;from&#39;,&#39;to&#39;) visNetwork(nodes = nodes, edges = edges); nodes$group = c(rep(&quot;a&quot;,6),rep(&quot;b&quot;,5)) visNetwork(nodes = nodes, edges = edges) %&gt;% visOptions(selectedBy = &quot;group&quot;) # Collapse / Uncollapse Nodes visNetwork(nodes = nodes, edges = edges) %&gt;% visOptions(collapse = TRUE) # Highlight nearest visNetwork(nodes = nodes, edges = edges) %&gt;% visOptions(highlightNearest = TRUE) "]
]
